% !TEX TS-program = pdflatex 
% !TEX encoding = UTF-8 Unicode
\documentclass[conference, 11pt]{IEEEtran} % use larger type; default would be 10pt
%%% BASIC DISPLAY PACKAGES
%\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
%\usepackage{setspace}
%\doublespacing
%\usepackage{graphicx}
%\usepackage{listings}
%\usepackage{color}
%\usepackage{pdflscape}
%\usepackage{caption}
%\usepackage{pifont}
\usepackage{multirow}
\usepackage{balance}
\usepackage{float}



%%% PAGE DIMENSIONS
%\usepackage{geometry} % to change the page dimensions
%\geometry{letterpaper} % or letterpaper (US) or a5paper or....
% \geometry{margins=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
% read geometry.pdf for detailed page layout information
%\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent
%%% PACKAGES
%\usepackage{booktabs} % for much better looking tables
%\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
%\usepackage{enumerate} %for better lists
%Package and command for creating field symbol such as Q, R etc...
\usepackage{amsfonts}
\usepackage{amsmath}
%\usepackage{cite}
\usepackage{nopageno}
%\usepackage{MnSymbol}%allows usage of symbol of three dots in a diagonal bottom left to top right (and other dots)

\linespread{1.1}

%%%STRUCTURE BUILDER
\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Propostion}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}


%%% HEADERS AND FOOTERS
%\usepackage{fancyhdr}
%\pagestyle{plain}
%\lhead{}
%\rhead{}


%%MACROS
\newcommand{\pd}[2]{\dfrac{\partial #1}{\partial #2}}
\newcommand{\pref}[1]{(\ref{#1})}
\newcommand{\mm}[1]{\mathbf{#1}}

%=========================yz7210==================================================%

\title{Tackling skewed data in online fake review detection}
\date{\today}
\author{\IEEEauthorblockN{Satheesh Joseph}
\IEEEauthorblockA{satheeshrishi@berkeley.edu}
\and
\IEEEauthorblockN{Catherine Mou}
\IEEEauthorblockA{catherine041616@berkeley.edu}
\and
\IEEEauthorblockN{Yi Zhang}
\IEEEauthorblockA{yizhang7210@berkeley.edu}
}

\begin{document}
\maketitle



\begin{abstract}
The increasing need and value of the digital text and the trustworthiness behind it inspired our imagination to handle a niche problem within the space of opinion spam analysis. Recently many researches have been conducted to increase the detection accuracy. To the best of our knowledge, an important issue that has been less studied is to tackle heavily skewed data in online fake review detection. In this paper, we study a methodology to tackle the imbalanced data issue and the accuracy effects on different state-of-the-art models. For this research, we use publicly available Yelp review data for hotels and restaurants for our experiments.
\end{abstract}

\section{Introduction}
\label{intro}
Online fake review detection is a relatively well-studied subject, especially in recent years, given its outsized impact on consumers engaging in e-commerce activities online. Positive reviews bring a meaningful increase in sales volume to the products~\cite{ho2013effects}, and vice versa for negative reviews.

As a result, there has been an increase in opinion spamming activities, and detecting fake reviews has become an essential requirement for online marketplaces to maintain the integrity and fairness of their platform.

However, there has been one persisting challenge~\cite{stanton2019gans, Tang2020, wang2020fake, yuan2019learning} in this area of research -- the lack of a substantial body of actually proven fake reviews, directly leading to significantly imbalanced datasets.

Our work aims to tackle this problem of data imbalance by borrowing ideas from the Generative Adversarial Network (GAN). Our \textbf{hypothesis} is that it's possible to make up the data imbalance by generating fake reviews from a \textbf{language model} trained and/or fine-tuned on actual fake reviews. We will look to validate this approach by then training a review detection model on a balanced dataset that includes the generated fake reviews and achieving comparable results to state-of-the-art research~\cite{Tang2020}.

Section \ref{bg} provides the background on the existing research in fake review detection. Section \ref{methods} lays out our methods of constructing the fake review generator. Section \ref{exp} discusses the experiments we run to validate the usefulness of the generated fake reviews in training a detection model. And we draw our final conclusions in section \ref{conclusion}.


\section{Background}
\label{bg}
There is no shortage of research tackling the problem of fake review detection. A recent survey~\cite{Mohawesh2021} does a great job laying out the landscape of the various techniques and data sets used for fake review detection.

However, most of the publicly available data sets are very skewed with many much real review examples than fake ones. According to this survey, all large datasets ($>$20k reviews) from Yelp~\cite{rayana2015collective} contain less than $15\%$ actual fake reviews. There are a few other widely used public datasets crawled from TripAdvisor, but they are of a much smaller scale, with the fake review training set generated via a manual process from Amazon Mechanical Turk.

The only balanced dataset of moderate volume is crawled from Yelp by Barbado et. al.~\cite{barbado2019framework}, however it has not been widely adopted in the research community as a benchmark for detecting fake reviews.

This lack of trusted labeled data can apply a significant limit on the performance of models that try to detect fake reviews. Moreover, the unbalanced datasets tend to encourage the model to produce biased predictions. Given this state of the related work, and inspired by Stanton et. al.~\cite{stanton2019gans} who used GAN techniques to generate behavioral features (e.g. number of reviews, percentage of positive reviews) for online Yelp reviewers, we believe that similar techniques can be used to generate the reviews themselves.

With sufficient representativeness, we believe the generated fake reviews can serve as additional training examples that can help with the detection model to distinguish between genuine reviews and fake ones. To paraphrase Tolstoy --  genuine reviews are all alike; every fake review is fake in its own way.


\section{Methods}
\label{methods}
Generative Adversarial Network (GAN) was originally used for image data augmentation, but the development of Transformer-based models has enabled coherent and human-like \textit{text} generation, and those models had demonstrated to be effective for NLP data augmentation to overcome the data scarcity problem.

The general structure of a Generative Adversarial Network consists of a \textit{generative} network that generates candidates as well as a \textit{discriminative} network that evaluates them. Here we apply this technique to generate fake review texts.

For the \textit{generative} network, we here use the well-established, pre-trained GPT-2 language model.

GPT-2 was pre-trained on web scraped industrial-scale corpus, it was trained with a batch size of 512, well-defined sentence length, vocabulary size of 50,000, and can be used for various NLP tasks including text generation. It is a statistical tool to generate the next words in sequence based on preceding words, at every stage, it will take the previously generated data as additional input when generating the next output. GPT-2 has outperformed other language models when it comes to generating text based on small input contents like hotel/restaurant reviews. GPT-2 has the ability to adapt to the context of the text, so it can generate realistic and coherent output. 

To generate domain-specific fake Yelp reviews, we fined-tuned the pre-trained GPT-2 model by adding layers on top and training with our raw data set. GPT-2 text generation pipeline predicts words that will follow a specified text prompt, so we gave it a simple prompt such as ``the hotel is", or ``the restaurant is".

However, this led to low-quality generated text that was very repetitive at the end. Furthermore, the generated text was frequently not full sentences. With multiple trials and errors, we eventually made a few improvements that led to higher quality generated fake reviews.
\begin{itemize}
\item We sampled some of the original actual fake reviews as the prompt supplied to GPT-2 for text generation, instead of the short static prompt. This is to give GPT-2 more context to generate longer and more realistic-looking reviews.

\item We trained a simple Neural Network using ELMo embedding with LSTM and 2 dense layers on the original data set as the \textit{discriminative} network. Even though this Network itself has not performed well in distinguishing genuine and fake reviews, it does do a good job distinguishing coherent, relevant reviews about hotels/restaurants and irrelevant sentences, making it a good candidate for the discriminative network in the GAN. And finally, we only picked reviews that sufficiently confused this network (with a predicted probability of more than 80\%) to be included in the final generated fake review set.
\end{itemize}

\section{Experiment \& Discussion}
\label{exp}

\subsection{Experimental Setup}
For our experiments, we use the publicly available data set originally obtained by \cite{mukherjee2013fake} and \cite{mukherjee2013yelp}.
This data set, containing 5858 reviews for hotels and 67019 reviews for restaurants on Yelp, is also used by a number of prior research papers for benchmarking, notably~\cite{wang2017handling} and~\cite{Tang2020}.
 A more detailed statistics of the raw data set is in Table \ref{original-data}. As mentioned above, it is indeed highly imbalanced with a much smaller number of fake reviews.

\begin{table}[h!]
\small
\caption{Summary of Experimental Data}
\centering
\begin{tabular}{|c|c|c|}
\hline
Subject & Hotels & Restaurants \\ \hline
Total \# Reviews & 5858 & 67019 \\ \hline
Total \# Genuine Reviews & 5078 & 58716 \\ \hline
Total \# Fake Reviews & 780 &  8303 \\ \hline
\% Fake Reviews & 13.3\% & 12.4\%  \\ 
\hline
\end{tabular}
\label{original-data}

\end{table}

To validate our hypothesis on the usefulness of the generated fake reviews, we set up a 2-stage experiment.

Firstly, we use the methods laid out in section \ref{methods} to generate fake reviews for both hotels and restaurants. Secondly, we add the generated fake reviews to the training data to obtain a balanced training set, then run a number of classification models on the mixed training set and compare it against our benchmark results.

We construct the data sets in the following ways to be comparable with the prior research papers~\cite{wang2017handling}, \cite{Tang2020}. A summary is given in Table \ref{trainining-data}.

For a balanced test set:
\begin{itemize}
\setlength\itemsep{0em}
\item we first limit the pool of reviews to the first review per reviewer after 2012-01-01
\item we take all the fake reviews (because there are fewer)
\item we sample the same number of reviews from the genuine reviews
\item this gives us a balanced, non-duplicated test set
\end{itemize}

For a balanced training set:
\begin{itemize}
\setlength\itemsep{0em}
\item we first limit the pool of reviews to be the ones prior to 2012-01-01
\item we take all the actual fake reviews
\item we include all generated fake reviews
\item we sample the same number of reviews from the genuine reviews
\item this gives us a balanced, non-duplicated training set
\end{itemize}


\begin{table}[h!]
\small
\caption{Summary of Training/Test Data}
\centering
\begin{tabular}{|c|c|c|}
\hline
Subject & Hotels & Restaurants \\ \hline
Training set size & 5070 & 56115 \\ \hline
\# Genuine Reviews & 2535  & 49189 \\ \hline
\# Actual Fake Reviews & 561  &  6926\\ \hline
\# Generated Reviews & 1974 & 42263 \\ \hline
\% Fake Reviews in training set & 50\% & 50\%  \\ \hline
Test set size & 432 & 2474 \\ \hline
\% Fake Reviews in test set & 50\% & 50\% \\ 
\hline
\end{tabular}
\label{trainining-data}

\end{table}

\subsection{Models}
We established a number of models all based on Neural Networks to compare our results with the benchmark.

\textbf{Model 1}: Our baseline model with GloVe embedding and 1 layer of LSTM.

\textbf{Model 2}: Our main model with GloVe embedding, 1 layer of Bidirectional LSTM, and 3 dense layers.

\textbf{Model 3}: A BERT-based model.

For each model, we'll be training on 4 different training sets for comparison. Each model has a different mix of genuine v.s. fake v.s. generated fake reviews, so we can test the effectiveness of generated fake reviews.

 \textbf{Set 1}: raw, imbalanced training set
 
 \textbf{Set 2}: balanced training set by under-sampling genuine reviews to the number of fake reviews
 
 \textbf{Set 3}: balanced training set by over-sampling fake reviews with replacement to the number of genuine reviews
 
 \textbf{Set 4}: balanced training set by including generated fake reviews per Table \ref{trainining-data}

\subsection{Results}
We report the best results of each of our models trained on each training set listed above after hyperparameter tuning via grid search. We will also report the results of a few state-of-the-art classification algorithms from the benchmark research~\cite{Tang2020}.

Their brief descriptions are as follows:

\textbf{LF}: uses linguistic features from the review content only, by extracting bigrams from the reviews data.

\textbf{CNN}: uses the same bigram features but is trained using a Convolutional Neural Network.

\textbf{LF+BF}: is a concatenation of linguistic as well as \textit{behavioral} features from the review, including its length, rating, and other reviews by the same reviewer.

\textbf{bfGAN}: is the state-of-the-art algorithm from~\cite{Tang2020} using GAN generated behavioral features (BF) as well as the review content.

We've selected classification \textit{accuracy} as well as \textit{f1-score} as the reporting metrics to be compatible with prior research. A summary of them all the experimental results is presented in Table \ref{exp-hotels} for the Hotels data set and Table \ref{exp-restaurants} for the restaurant data set.

\begin{table}[H]
\small
\caption{Experimental Results - Hotels}
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
 accuracy/f1 & Set 1 & Set 2 & Set 3 & Set 4 \\ \hline
 
Model 1 & 0.51/0.35 & 0.61/0.61 & 0.58/0.56 & 0.59/0.59 \\ \hline
Model 2 & 0.56/0.62 & 0.60/0.61 & 0.57/0.62 & 0.59/0.60 \\ \hline
Model 3* & 0.5/0.34 & 0.57/0.57 & 0.53/0.54 & 0.52/0.56 \\ \hline
LF~\cite{Tang2020} & \multicolumn{4}{c|}{0.56/0.62} \\ \hline
CNN~\cite{Tang2020} & \multicolumn{4}{c|}{0.59/0.56} \\ \hline
LF+BF~\cite{Tang2020} & \multicolumn{4}{c|}{0.61/0.58} \\ \hline
bfGAN~\cite{Tang2020} & \multicolumn{4}{c|}{0.83/0.83} \\
\hline
\end{tabular}
\label{exp-hotels}
\end{table}

\begin{table}[H]
\small
\caption{Experimental Results - Restaurants}
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
 accuracy/f1 & Set 1 & Set 2 & Set 3 & Set 4 \\ \hline
Model 1 & 0.57/0.53 & 0.63/0.62 & 0.62/0.61 & 0.60/0.60 \\ \hline
Model 2 & 0.57/0.50 & 0.63/0.62 & 0.62/0.61 & 0.59/0.58 \\ \hline
Model 3* & 0.5/0.33 & 0.57/0.55 & 0.55/0.55 & 0.56/0.56 \\ \hline
LF~\cite{Tang2020} & \multicolumn{4}{c|}{0.56/0.65} \\ \hline
CNN~\cite{Tang2020} & \multicolumn{4}{c|}{0.57/0.58} \\ \hline
LF+BF~\cite{Tang2020} & \multicolumn{4}{c|}{0.59/0.60} \\ \hline
bfGAN\cite{Tang2020}& \multicolumn{4}{c|}{0.76/0.75} \\
\hline
\end{tabular}
\label{exp-restaurants}
\end{table}

\vspace{-1.5em}

{\footnotesize * With limited hyper-parameter tuning.}


\subsection{Discussion \& Future Work}
Synthesizing the results, we can see a few trends:
\begin{itemize}
\item Non-repeated, balanced training set matters. Across the models, the test accuracy is generally higher when trained on Set 2 or 4 compared to trained on Set 1 (skewed) or Set 3 (over-sampled).
\item Non-linguistic features matter. Even though our models mostly out-performed purely linguistically based baselines (i.e. LF and CNN) and even sometimes LF+BF (in the case of the restaurant data set), more sophisticated use of behavioral features seems to be able to boot the model accuracy much further.
\item Generated fake review can be useful but has not proved to be a significant difference-maker. Comparing models trained on Set 2 versus Set 4, even though the latter did not perform better than the former as we had hoped, it held up well and produced accuracy and f1 scores that are mostly on par.
\end{itemize}

Going through this exercise, we also took away a few learnings for future improvement.
\begin{enumerate}
\item Fidelity of the generated review really matters. It's not obvious looking at the results, but we've made multiple attempts and have gone through multiple iterations to optimize for the quality and fidelity of the generated fake reviews, and with each iteration, the ultimate accuracy and f1 scores improve. Unfortunately, we eventually ran out of time, but we believe focusing more on the fake review generation in the future would be a fruitful pursuit.
\item Model tuning matters. With different data set sizes, different sized models and hyper-parameter combinations can perform very differently. With the large number of hyper-parameters (e.g. number of layers, units, training epochs, text vectorizers, sequence lengths, etc.), as well as the long training time of BERT-based models, we came up short on time in getting the best out of them. If we had more time in the future, we believe the results still have much room for improvement, especially for the BERT-based Model 3.
\end{enumerate}


\section{Conclusion}
\label{conclusion}
Through our literature review, we identified a common challenge of skewed training data in the domain of online fake review detection. In this research, we've attempted to tackle it by using a Generative Adversarial Network to generate high fidelity fake reviews based on the existing fake review data to complement it for model training.

With the experiments we've conducted, it seems that training on generated fake reviews can indeed improve the model accuracy compared to a skewed or an over-sampled training set, especially on smaller raw data sets. Whether it can out-performed under-sampled training set still requires further work.

Furthermore, we've found the network architecture of Bidirectional LSTM with a few dense layers reasonably effective in this particular natural language task.


\bibliographystyle{plain}
\balance
\nocite{*}
\bibliography{ref}












\end{document}