% !TEX TS-program = pdflatex 
% !TEX encoding = UTF-8 Unicode
\documentclass[conference]{IEEEtran} % use larger type; default would be 10pt
%%% BASIC DISPLAY PACKAGES
%\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
%\usepackage{setspace}
%\doublespacing
%\usepackage{graphicx}
%\usepackage{listings}
%\usepackage{color}
%\usepackage{pdflscape}
%\usepackage{caption}
%\usepackage{pifont}
\usepackage{multirow}
\usepackage{balance}



%%% PAGE DIMENSIONS
%\usepackage{geometry} % to change the page dimensions
%\geometry{letterpaper} % or letterpaper (US) or a5paper or....
% \geometry{margins=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
% read geometry.pdf for detailed page layout information
%\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent
%%% PACKAGES
%\usepackage{booktabs} % for much better looking tables
%\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
%\usepackage{enumerate} %for better lists
%Package and command for creating field symbol such as Q, R etc...
\usepackage{amsfonts}
\usepackage{amsmath}
%\usepackage{cite}
\usepackage{nopageno}
%\usepackage{MnSymbol}%allows usage of symbol of three dots in a diagonal bottom left to top right (and other dots)

\linespread{1.1}

%%%STRUCTURE BUILDER
\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Propostion}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}


%%% HEADERS AND FOOTERS
%\usepackage{fancyhdr}
%\pagestyle{plain}
%\lhead{}
%\rhead{}


%%MACROS
\newcommand{\pd}[2]{\dfrac{\partial #1}{\partial #2}}
\newcommand{\pref}[1]{(\ref{#1})}
\newcommand{\mm}[1]{\mathbf{#1}}

%=========================yz7210==================================================%

\title{Tackling imbalanced data in on-line fake review detection}
\date{\today}
\author{\IEEEauthorblockN{Satheesh Joseph}
\and
\IEEEauthorblockN{Catherine Mou}
\and
\IEEEauthorblockN{Yi Zhang}
}

\begin{document}
\maketitle



\begin{abstract}
Abstract
\end{abstract}

\section{Introduction}
\label{intro}
On-line fake review detection is a relatively well studies subject, especially in recent years, given its outsized impact on consumers engaging in e-commerce activities online. Positive reviews bring a meaningful increase in sales volume to the products\cite{ho2013effects}, and vice versa for negative reviews.

As a result, there has been an increase in opinion spamming activity, and detecting fake reviews has become an essential requirement for on-line marketplaces to maintain the integrity and fairness of their platform.

However, there has been one persisting challenge \cite{stanton2019gans, Tang2020, wang2020fake, yuan2019learning} in this area of research -- the lack of substantial body of actual, proven fake reviews, directly leading to significantly imbalanced datasets.

Our work aims to tackle this problem of data imbalance by borrowing ideas from Generative Adversarial Network (GAN). Our \textbf{hypothesis} is that it's possible to make up the data imbalance by generating fake reviews from a language model trained/fine-tuned on actual fake reviews. We will validate this approach by then training a review detection model on a balanced dataset that includes the generated negative reviews, and achieving comparable results to state-of-the-art research \cite{Tang2020}.


\section{Background}
\label{bg}
There is no shortage of research tackling the problem of fake review detection. A recent survey \cite{Mohawesh2021} does a great job laying out the landscape of the various techniques and data sets used for fake review detection.

According to this survey, all large datasets ($>$20k reviews) from Yelp \cite{rayana2015collective} contain less than $15\%$ actual fake reviews. There are a few other widely used public datasets crawled from TripAdvisor, but they are of much smaller scale, with the fake review training set generated via a manual process from Amazon Mechanical Turk.

The only balanced dataset of moderate volume is crawled from Yelp by Barbado et. al. \cite{barbado2019framework}, however it has not been widely adopted in the research community as a benchmark for detecting fake reviews.

Given this state of the related work, and inspired by Stanton et. al. \cite{stanton2019gans} who used GAN techniques to generate behavioral features (e.g. number of reviews, percentage of positive reviews) of on-line Yelp reviewers, we believe that similar techniques can be used to generate the reviews themselves.

With sufficient representativeness, we believe the generated fake reviews can serve as additional training examples that helps with the detection model to distinguish between genuine reviews and fake ones -- "Happy families are all alike; every unhappy family is unhappy in its own way."


WIP:

- Benchmark control group paper \cite{Tang2020}


- Data description \cite{wang2017handling}

- GAN Paper \cite{stanton2019gans}

- Original data comes from \cite{mukherjee2013fake} \cite{mukherjee2013yelp}


\section{Methods}
\label{methods}

Methods

\section{Results \& Discussion}
\label{results}

Results and Discussion

\section{Conclusion}
\label{conclusion}

Example table
\begin{table}[h]
\normalsize
\caption{Summary of Experimental Results}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
System & $n$ &  $\gamma$ & Samples & mean & max \\ \hline
\multirow{3}{*}{A} & \multirow{3}{*}{21} & 0.2 & 24236 (11\%) & 0.083 & 0.084\\
 && 0.15 & 43307 (20\%) & 0.081 & 0.081\\
  && 0.1 & 97440 (44\%)& 0.074 & 0.074\\ \hline
\multirow{3}{*}{B} & \multirow{3}{*}{23}  & 0.2 & 26332 (2.2\%) & 0.035 & 0.036\\
&& 0.15 & 46812 (4.0\%)& 0.026 & 0.026\\
&& 0.1 & 105326 (8.9\%)& 0.0068& 0.0069\\ \hline
\multirow{3}{*}{C} & \multirow{3}{*}{26}&0.2& 29289 (2.2\%) & 0.084 & 0.085\\
& & 0.15 & 52070 (3.9\%)& 0.084 & 0.084\\
 &  & 0.1 & 117156 (8.8\%)& 0.080 & 0.082\\ \hline
 \multirow{3}{*}{D} & \multirow{3}{*}{20} & 0.2 & 23375 (2.2\%)& 0.074 & 0.080\\
&  & 0.15 & 41555 (4.0\%)& 0.034 & 0.037\\
&  & 0.1 & 93497 (8.9\%)& 0.024 & 0.024\\

\hline
\end{tabular}
\label{expone}

\vspace{1em}

\begin{center}
$n$ = Number of features of system.\\
$\gamma$ = User specified maximum error.\\
Samples = Number \& proportion of samples used.\\
mean = Average actual error from the 10 runs.\\
max = Maximum actual error from the 10 runs.
\end{center}

\end{table}
\bibliographystyle{plain}
\balance
\nocite{*}
\bibliography{ref}












\end{document}