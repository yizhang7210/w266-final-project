{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W266 Final Project\n",
    "\n",
    "Authors: Satheesh Joseph, Catherine Mou, Yi Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Downloading and preparing the data\n",
    "\n",
    "We acquired the dataset from the researchers in the form of Sqlite `.db` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow_text as text \n",
    "import os, sys, re, json, time, unittest\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import unicodedata\n",
    "import nltk\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Lambda, Bidirectional, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, InputLayer, Embedding\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import tensorflow_text as text  # Registers the ops.\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded data\n"
     ]
    }
   ],
   "source": [
    "# Download the files if they're not here\n",
    "if 'data' not in os.listdir('.') or not os.listdir('data'):\n",
    "    os.system('wget https://storage.googleapis.com/mids-w266-final-project-data/yelpHotelData.db -P data/')\n",
    "    os.system('wget https://storage.googleapis.com/mids-w266-final-project-data/yelpResData.db -P data/')\n",
    "    print('Data downloaded successfully!')\n",
    "else:\n",
    "    print('Already downloaded data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('review',), ('sqlite_stat1',), ('sqlite_stat2',), ('reviewer',), ('hotel',)]\n"
     ]
    }
   ],
   "source": [
    "# Load data from the database\n",
    "con = sqlite3.connect('data/yelpHotelData.db')\n",
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set contains 5858 reviews, and 5123 reviewers\n"
     ]
    }
   ],
   "source": [
    "# Reading from the hotels database\n",
    "hotels_db = sqlite3.connect(\"data/yelpHotelData.db\")\n",
    "hotels = pd.read_sql_query(\"SELECT * FROM hotel\", hotels_db)\n",
    "hotel_reviews = pd.read_sql_query(\"SELECT * FROM review WHERE flagged in ('Y', 'N')\", hotels_db)\n",
    "hotel_reviewers = pd.read_sql_query(\"SELECT * FROM reviewer\", hotels_db)\n",
    "\n",
    "print(f'The data set contains {len(hotel_reviews)} reviews, and {len(hotel_reviewers)} reviewers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "hotel_reviews['reviewContent'] = hotel_reviews['reviewContent'].apply(lambda x: unicodedata.normalize('NFKD', x))\n",
    "hotel_reviews['date'] = hotel_reviews['date'].apply(lambda x: datetime.datetime.strptime(x.strip().split(' ')[-1], '%m/%d/%Y'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split data according to the research paper, i.e. balanced new reviews after 2012-01-01\n",
    "hotel_X_test = hotel_reviews[hotel_reviews['date'] >= datetime.datetime(2012, 1, 1)]\n",
    "hotel_X_test = hotel_X_test.sort_values('date', ignore_index=True).groupby('reviewerID', as_index=False).first()\n",
    "hotel_X_test_positive = hotel_X_test[hotel_X_test['flagged'] == 'Y']\n",
    "hotel_X_test_negative = hotel_X_test[hotel_X_test['flagged'] == 'N']\n",
    "hotel_X_test_balanced = pd.concat([hotel_X_test_positive, hotel_X_test_negative.sample(n=len(hotel_X_test_positive))], ignore_index=True)\n",
    "hotel_X_test = hotel_X_test_balanced.sample(frac=1)\n",
    "hotel_y_test = hotel_X_test['flagged'] == 'Y'\n",
    "hotel_X_train = hotel_reviews[hotel_reviews['date'] < datetime.datetime(2012, 1, 1)]\n",
    "hotel_y_train = hotel_X_train['flagged'] == 'Y'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4536 entries, 0 to 5857\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   date           4536 non-null   datetime64[ns]\n",
      " 1   reviewID       4536 non-null   object        \n",
      " 2   reviewerID     4536 non-null   object        \n",
      " 3   reviewContent  4536 non-null   object        \n",
      " 4   rating         4536 non-null   int64         \n",
      " 5   usefulCount    4536 non-null   int64         \n",
      " 6   coolCount      4536 non-null   int64         \n",
      " 7   funnyCount     4536 non-null   int64         \n",
      " 8   flagged        4536 non-null   object        \n",
      " 9   hotelID        4536 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(5)\n",
      "memory usage: 389.8+ KB\n"
     ]
    }
   ],
   "source": [
    "hotel_X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***While the rooms are small, Hotel Felix is a nice hotel with modern and fresh decor, comfortable beds, clean rooms, good room temperature, and good showers; all these advantages plus their very good location make this one to definitely consider if you can get a competitive room rate*** Hotel Felix is an eco-friendly (Silver LEED certification) boutique hotel that has a convenient location in River North.  It is close to one of the subway lines as well as many well-known Chicago restaurants (Ria, Graham Elliot, Rick Bayless' spots) and The Magnificent Mile.  A lot of Chicago is walk-able and staying at Hotel Felix makes the walking part even easier. The hotel exterior (an older, renovated building) stands out with its huge (but not garish) sign.  The inside of the hotel is small--from the elevators to the lobby to the rooms.  I thought my room, which was on the top floor was actually not too small (maybe bigger than what some of the other reviewers had) and provided a decent view of some of the nearby big buildings. The room was very modern with modern but still comfortable furniture and kind of a minimalist approach.  The room was very clean and the bed was nice and comfortable (good linens too).  The bathroom was also nice though the sink was very shallow (you are likely to touch the sink basin as you wash your hands).  The shampoo and soap were provided by a local company (H2O, which you will also see on some United flights). The room featured your standard stuff like TV, room service, iron, ironing board, and ice bucket; complimentary internet access was also provided. In terms of amenities, there was a spa as well as a decent (though small) 24-hour fitness center. Service was good.  The front desk was pleasant and polite.  The bellhops were really good--friendly and very helpful. Room rates are high here though it is about what you would expect to pay for a nice boutique hotel with a good location (though the rooms here might be smaller than other boutique hotels).  You can get deals here though.  I think they did a Yelp discount here once and you can find pretty good room rates on the online sites like Expedia. Hotel Felix is a nice and modern hotel with a very good location.  It also meets my key needs of comfortable bed, comfortable room temperature, clean room, and a good shower.  While the rooms are not huge, the pros far outweigh that one negative and I would definitely consider returning here if I could find a competitive rate. For parking, I think it is pretty expensive--probably $35 or more.  Though to continue with their eco-friendly theme, Hotel Felix provides free parking to guests who drive hybrids.\n"
     ]
    }
   ],
   "source": [
    "reviews = hotel_X_train\n",
    "reviews.groupby('reviewerID').agg({\"usefulCount\": np.sum, \n",
    "                                   \"coolCount\": np.sum, \n",
    "                                   \"funnyCount\": np.sum}).sort_values(by=['usefulCount'], ascending=False)\n",
    "print(reviews[reviews['reviewerID'] == 'w-w-k-QXosIKQ8HQVwU6IQ']['reviewContent'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>coolCount</th>\n",
       "      <th>funnyCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flagged</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>14188</td>\n",
       "      <td>5020</td>\n",
       "      <td>2641</td>\n",
       "      <td>2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>1817</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating  usefulCount  coolCount  funnyCount\n",
       "flagged                                            \n",
       "N         14188         5020       2641        2254\n",
       "Y          1817            0          0           0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.groupby('flagged').agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reviewID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewContent</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>coolCount</th>\n",
       "      <th>funnyCount</th>\n",
       "      <th>flagged</th>\n",
       "      <th>hotelID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>802</td>\n",
       "      <td>802</td>\n",
       "      <td>802</td>\n",
       "      <td>802</td>\n",
       "      <td>802</td>\n",
       "      <td>802</td>\n",
       "      <td>802</td>\n",
       "      <td>802</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1574</td>\n",
       "      <td>1574</td>\n",
       "      <td>1574</td>\n",
       "      <td>1574</td>\n",
       "      <td>1574</td>\n",
       "      <td>1574</td>\n",
       "      <td>1574</td>\n",
       "      <td>1574</td>\n",
       "      <td>1574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>857</td>\n",
       "      <td>857</td>\n",
       "      <td>857</td>\n",
       "      <td>857</td>\n",
       "      <td>857</td>\n",
       "      <td>857</td>\n",
       "      <td>857</td>\n",
       "      <td>857</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  reviewID  reviewerID  reviewContent  usefulCount  coolCount  \\\n",
       "rating                                                                      \n",
       "1        283       283         283            283          283        283   \n",
       "2        459       459         459            459          459        459   \n",
       "3        802       802         802            802          802        802   \n",
       "4       1574      1574        1574           1574         1574       1574   \n",
       "5        857       857         857            857          857        857   \n",
       "\n",
       "        funnyCount  flagged  hotelID  \n",
       "rating                                \n",
       "1              283      283      283  \n",
       "2              459      459      459  \n",
       "3              802      802      802  \n",
       "4             1574     1574     1574  \n",
       "5              857      857      857  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([ 283.,    0.,  459.,    0.,    0.,  802.,    0., 1574.,    0.,\n",
       "         857.]),\n",
       " array([1. , 1.4, 1.8, 2.2, 2.6, 3. , 3.4, 3.8, 4.2, 4.6, 5. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAATqElEQVR4nO3df4yl1X3f8fcnLODYTs2PnRCyu+6gZOMKW3FNt3gjWouYBi9gsUgl1qLGrF2iVRKcOCWqA65UVEeWSFvFCYlLtDVbQ+OAEbHD1l4Hb4EUVSqYBdv8tMMIY++uwDs2GKclsbv2t3/cs/XNMLPz487cWXzeL+lqnuecc+/53gfmM8+e+9x7U1VIkvrwI6tdgCRpfAx9SeqIoS9JHTH0Jakjhr4kdWTNahdwNGvXrq3JycnVLkOSXlYefPDBb1TVxGx9x3ToT05Osm/fvtUuQ5JeVpJ8da4+l3ckqSOGviR1ZN7QT7IryaEkj85o//UkX0ryWJJ/P9R+TZKpJF9O8rah9i2tbSrJ1cv7NCRJC7GQNf2PAn8E3HykIcnPA1uBN1bVd5L8eGs/E9gGvB74SeC/J/mZdrcPA78AHAAeSLK7qh5friciSZrfvKFfVfcmmZzR/KvAdVX1nTbmUGvfCtza2r+SZAo4u/VNVdVTAElubWMNfUkao6Wu6f8M8E+T3J/kfyT5x619HbB/aNyB1jZX+0sk2ZFkX5J909PTSyxPkjSbpYb+GuAUYDPwr4HbkmQ5CqqqnVW1qao2TUzMepmpJGmJlnqd/gHgEzX4XObPJfk+sBY4CGwYGre+tXGUdknSmCz1TP/PgZ8HaC/UngB8A9gNbEtyYpIzgI3A54AHgI1JzkhyAoMXe3ePWLskaZHmPdNPcgtwLrA2yQHgWmAXsKtdxvldYHs7638syW0MXqA9DFxZVd9rj/Me4E7gOGBXVT22As9H0gqavPrTqzLv09ddtCrz/jBayNU7l83R9UtzjP8g8MFZ2vcAexZVnSRpWfmOXEnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIvKGfZFeSQ+2rEWf2/VaSSrK27SfJ9Ummkjyc5KyhsduTPNlu25f3aUiSFmIhZ/ofBbbMbEyyATgf+NpQ8wUMvgx9I7ADuKGNPYXBd+u+GTgbuDbJyaMULklavHlDv6ruBZ6bpetDwPuAGmrbCtxcA/cBJyU5HXgbsLeqnquq54G9zPKHRJK0spa0pp9kK3Cwqr44o2sdsH9o/0Brm6tdkjRGaxZ7hySvBN7PYGln2SXZwWBpiNe+9rUrMYUkdWspZ/o/BZwBfDHJ08B64KEkPwEcBDYMjV3f2uZqf4mq2llVm6pq08TExBLKkyTNZdGhX1WPVNWPV9VkVU0yWKo5q6qeBXYDl7ereDYDL1TVM8CdwPlJTm4v4J7f2iRJY7SQSzZvAf4X8LokB5JccZThe4CngCngPwO/BlBVzwG/AzzQbh9obZKkMZp3Tb+qLpunf3Jou4Ar5xi3C9i1yPokScvId+RKUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIQr4jd1eSQ0keHWr7D0m+lOThJJ9MctJQ3zVJppJ8Ocnbhtq3tLapJFcv+zORJM1rIWf6HwW2zGjbC7yhqn4W+CvgGoAkZwLbgNe3+/ynJMclOQ74MHABcCZwWRsrSRqjeUO/qu4FnpvR9tmqOtx27wPWt+2twK1V9Z2q+gowBZzdblNV9VRVfRe4tY2VJI3Rcqzp/0vgM217HbB/qO9Aa5ur/SWS7EiyL8m+6enpZShPknTESKGf5N8Ah4GPLU85UFU7q2pTVW2amJhYroeVJAFrlnrHJO8C3g6cV1XVmg8CG4aGrW9tHKVdkjQmSzrTT7IFeB9wcVW9ONS1G9iW5MQkZwAbgc8BDwAbk5yR5AQGL/buHq10SdJizXumn+QW4FxgbZIDwLUMrtY5EdibBOC+qvqVqnosyW3A4wyWfa6squ+1x3kPcCdwHLCrqh5bgecjSTqKeUO/qi6bpfnGo4z/IPDBWdr3AHsWVZ0kaVn5jlxJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyLyhn2RXkkNJHh1qOyXJ3iRPtp8nt/YkuT7JVJKHk5w1dJ/tbfyTSbavzNORJB3NQs70PwpsmdF2NXBXVW0E7mr7ABcw+DL0jcAO4AYY/JFg8N26bwbOBq498odCkjQ+84Z+Vd0LPDejeStwU9u+CbhkqP3mGrgPOCnJ6cDbgL1V9VxVPQ/s5aV/SCRJK2ypa/qnVdUzbftZ4LS2vQ7YPzTuQGubq/0lkuxIsi/Jvunp6SWWJ0mazcgv5FZVAbUMtRx5vJ1VtamqNk1MTCzXw0qSWHrof70t29B+HmrtB4ENQ+PWt7a52iVJY7TU0N8NHLkCZztwx1D75e0qns3AC20Z6E7g/CQntxdwz29tkqQxWjPfgCS3AOcCa5McYHAVznXAbUmuAL4KvKMN3wNcCEwBLwLvBqiq55L8DvBAG/eBqpr54rAkaYXNG/pVddkcXefNMraAK+d4nF3ArkVVJ0laVr4jV5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSPzfsqmJPVs8upPr8q8T1930Yo8rmf6ktQRQ1+SOmLoS1JHRgr9JP8qyWNJHk1yS5JXJDkjyf1JppJ8PMkJbeyJbX+q9U8uyzOQJC3YkkM/yTrgN4BNVfUG4DhgG/C7wIeq6qeB54Er2l2uAJ5v7R9q4yRJYzTq8s4a4EeTrAFeCTwDvBW4vfXfBFzStre2fVr/eUky4vySpEVY8iWbVXUwyX8Evgb8DfBZ4EHgW1V1uA07AKxr2+uA/e2+h5O8AJwKfGOpNUir6YftUj71YZTlnZMZnL2fAfwk8Cpgy6gFJdmRZF+SfdPT06M+nCRpyCjLO/8M+EpVTVfV/wU+AZwDnNSWewDWAwfb9kFgA0Drfw3wzZkPWlU7q2pTVW2amJgYoTxJ0kyjhP7XgM1JXtnW5s8DHgfuAS5tY7YDd7Tt3W2f1n93VdUI80uSFmnJoV9V9zN4QfYh4JH2WDuB3wauSjLFYM3+xnaXG4FTW/tVwNUj1C1JWoKRPnunqq4Frp3R/BRw9ixj/xb4xVHmkySNxnfkSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyEihn+SkJLcn+VKSJ5L8XJJTkuxN8mT7eXIbmyTXJ5lK8nCSs5bnKUiSFmrUM/0/AP6iqv4B8EbgCQZfeH5XVW0E7uIHX4B+AbCx3XYAN4w4tyRpkZYc+kleA7wFuBGgqr5bVd8CtgI3tWE3AZe07a3AzTVwH3BSktOXOr8kafFGOdM/A5gG/kuSzyf5SJJXAadV1TNtzLPAaW17HbB/6P4HWtvfkWRHkn1J9k1PT49QniRpplFCfw1wFnBDVb0J+D/8YCkHgKoqoBbzoFW1s6o2VdWmiYmJEcqTJM00SugfAA5U1f1t/3YGfwS+fmTZpv081PoPAhuG7r++tUmSxmTJoV9VzwL7k7yuNZ0HPA7sBra3tu3AHW17N3B5u4pnM/DC0DKQJGkM1ox4/18HPpbkBOAp4N0M/pDcluQK4KvAO9rYPcCFwBTwYhsrSRqjkUK/qr4AbJql67xZxhZw5SjzSZJG4ztyJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRUT9lU8eYyas/vSrzPn3dRasyr6TF8Uxfkjpi6EtSRwx9SeqIoS9JHRk59JMcl+TzST7V9s9Icn+SqSQfb1+lSJIT2/5U658cdW5J0uIsx5n+e4EnhvZ/F/hQVf008DxwRWu/Ani+tX+ojZMkjdFIoZ9kPXAR8JG2H+CtwO1tyE3AJW17a9un9Z/XxkuSxmTUM/3fB94HfL/tnwp8q6oOt/0DwLq2vQ7YD9D6X2jj/44kO5LsS7Jvenp6xPIkScOWHPpJ3g4cqqoHl7EeqmpnVW2qqk0TExPL+dCS1L1R3pF7DnBxkguBVwB/D/gD4KQka9rZ/HrgYBt/ENgAHEiyBngN8M0R5pckLdKSz/Sr6pqqWl9Vk8A24O6q+hfAPcClbdh24I62vbvt0/rvrqpa6vySpMVbiev0fxu4KskUgzX7G1v7jcCprf0q4OoVmFuSdBTL8oFrVfWXwF+27aeAs2cZ87fALy7HfJKkpfEduZLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6siwfw3Csmrz606sy79PXXbQq80rSfDzTl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR1Zcugn2ZDkniSPJ3ksyXtb+ylJ9iZ5sv08ubUnyfVJppI8nOSs5XoSkqSFGeVM/zDwW1V1JrAZuDLJmQy++/auqtoI3MUPvgv3AmBju+0AbhhhbknSEiw59Kvqmap6qG3/NfAEsA7YCtzUht0EXNK2twI318B9wElJTl/q/JKkxVuWNf0kk8CbgPuB06rqmdb1LHBa214H7B+624HWNvOxdiTZl2Tf9PT0cpQnSWpGDv0krwb+DPjNqvr2cF9VFVCLebyq2llVm6pq08TExKjlSZKGjBT6SY5nEPgfq6pPtOavH1m2aT8PtfaDwIahu69vbZKkMRnl6p0ANwJPVNXvDXXtBra37e3AHUPtl7ereDYDLwwtA0mSxmCUT9k8B3gn8EiSL7S29wPXAbcluQL4KvCO1rcHuBCYAl4E3j3C3JKkJVhy6FfV/wQyR/d5s4wv4MqlzidJGp3vyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JGxh36SLUm+nGQqydXjnl+SejbW0E9yHPBh4ALgTOCyJGeOswZJ6tm4z/TPBqaq6qmq+i5wK7B1zDVIUrdSVeObLLkU2FJVv9z23wm8uareMzRmB7Cj7b4O+PIIU64FvjHC/VeKdS2OdS2OdS3OD2Ndf7+qJmbrWLP0elZGVe0Edi7HYyXZV1WbluOxlpN1LY51LY51LU5vdY17eecgsGFof31rkySNwbhD/wFgY5IzkpwAbAN2j7kGSerWWJd3qupwkvcAdwLHAbuq6rEVnHJZlolWgHUtjnUtjnUtTld1jfWFXEnS6vIduZLUEUNfkjrysg/9JLuSHEry6Bz9SXJ9+9iHh5OcdYzUdW6SF5J8od3+7Zjq2pDkniSPJ3ksyXtnGTP2Y7bAusZ+zJK8Isnnknyx1fXvZhlzYpKPt+N1f5LJY6SudyWZHjpev7zSdQ3NfVySzyf51Cx9Yz9eC6hpNY/V00keafPum6V/eX8fq+plfQPeApwFPDpH/4XAZ4AAm4H7j5G6zgU+tQrH63TgrLb9Y8BfAWeu9jFbYF1jP2btGLy6bR8P3A9snjHm14A/btvbgI8fI3W9C/ijcf8/1ua+CvjT2f57rcbxWkBNq3msngbWHqV/WX8fX/Zn+lV1L/DcUYZsBW6ugfuAk5KcfgzUtSqq6pmqeqht/zXwBLBuxrCxH7MF1jV27Rj877Z7fLvNvPphK3BT274dOC9JjoG6VkWS9cBFwEfmGDL247WAmo5ly/r7+LIP/QVYB+wf2j/AMRAmzc+1f55/Jsnrxz15+2f1mxicJQ5b1WN2lLpgFY5ZWxb4AnAI2FtVcx6vqjoMvACcegzUBfDP25LA7Uk2zNK/En4feB/w/Tn6V+N4zVcTrM6xgsEf688meTCDj6GZaVl/H3sI/WPVQww+H+ONwB8Cfz7OyZO8Gvgz4Der6tvjnPto5qlrVY5ZVX2vqv4hg3eQn53kDeOYdz4LqOu/AZNV9bPAXn5wdr1ikrwdOFRVD670XAu1wJrGfqyG/JOqOovBpw9fmeQtKzlZD6F/TH70Q1V9+8g/z6tqD3B8krXjmDvJ8QyC9WNV9YlZhqzKMZuvrtU8Zm3ObwH3AFtmdP3/45VkDfAa4JurXVdVfbOqvtN2PwL8ozGUcw5wcZKnGXyK7luT/MmMMeM+XvPWtErH6sjcB9vPQ8AnGXwa8bBl/X3sIfR3A5e3V8A3Ay9U1TOrXVSSnziyjpnkbAb/LVY8KNqcNwJPVNXvzTFs7MdsIXWtxjFLMpHkpLb9o8AvAF+aMWw3sL1tXwrcXe0VuNWsa8a678UMXidZUVV1TVWtr6pJBi/S3l1VvzRj2FiP10JqWo1j1eZ9VZIfO7INnA/MvOJvWX8fj7lP2VysJLcwuKpjbZIDwLUMXtSiqv4Y2MPg1e8p4EXg3cdIXZcCv5rkMPA3wLaVDormHOCdwCNtPRjg/cBrh2pbjWO2kLpW45idDtyUwRcA/QhwW1V9KskHgH1VtZvBH6v/mmSKwYv321a4poXW9RtJLgYOt7reNYa6ZnUMHK/5alqtY3Ua8Ml2LrMG+NOq+oskvwIr8/voxzBIUkd6WN6RJDWGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerI/wMSgAVUk9lTUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trueReviews = reviews[reviews['flagged'] == 'N']\n",
    "fakeReviews = reviews[reviews['flagged'] == 'Y']\n",
    "display(trueReviews.groupby('rating').agg('count'))\n",
    "plt.hist(x=trueReviews.rating, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reviewID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewContent</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>coolCount</th>\n",
       "      <th>funnyCount</th>\n",
       "      <th>flagged</th>\n",
       "      <th>hotelID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  reviewID  reviewerID  reviewContent  usefulCount  coolCount  \\\n",
       "rating                                                                      \n",
       "1        125       125         125            125          125        125   \n",
       "2         82        82          82             82           82         82   \n",
       "3         58        58          58             58           58         58   \n",
       "4        126       126         126            126          126        126   \n",
       "5        170       170         170            170          170        170   \n",
       "\n",
       "        funnyCount  flagged  hotelID  \n",
       "rating                                \n",
       "1              125      125      125  \n",
       "2               82       82       82  \n",
       "3               58       58       58  \n",
       "4              126      126      126  \n",
       "5              170      170      170  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([125.,   0.,  82.,   0.,   0.,  58.,   0., 126.,   0., 170.]),\n",
       " array([1. , 1.4, 1.8, 2.2, 2.6, 3. , 3.4, 3.8, 4.2, 4.6, 5. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAARX0lEQVR4nO3de4yldX3H8fdHFvFaEXek6+62Q1q0QaOVTinG1qC0imJYkhKzxMtqMRsVb9VUwSaSNjGhl3irrWYrlKVFlOCFLV4qRSxpUtYOeOHmZYMou1ncUSraarCr3/5xHuzJMLszc545c4af71eymef5/X7P+X3z2z2ffeY5lydVhSSpLQ+ZdAGSpJVnuEtSgwx3SWqQ4S5JDTLcJalB6yZdAMD69etrenp60mVI0oPKjTfe+N2qmlqob02E+/T0NLOzs5MuQ5IeVJJ861B9XpaRpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGrYlPqErSJE2f98mJzX3nhaeP5XE9c5ekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aNFwT3JxkgNJbpnX/rokX01ya5K/HGo/P8meJF9L8rxxFC1JOrylfEL1EuB9wKX3NyR5NrAFeFpV3Zfk8V37CcBW4MnAE4B/TfLEqvrpShcuSTq0Rc/cq+p64J55za8GLqyq+7oxB7r2LcCHq+q+qvomsAc4aQXrlSQtwajX3J8I/F6S3Un+Lclvd+0bgbuGxu3t2h4gyfYks0lm5+bmRixDkrSQUcN9HXAMcDLwJ8AVSbKcB6iqHVU1U1UzU1NTI5YhSVrIqOG+F/hYDXwB+BmwHtgHbB4at6lrkyStolHD/RPAswGSPBF4KPBdYBewNclRSY4Djge+sAJ1SpKWYdF3yyS5HDgFWJ9kL3ABcDFwcff2yJ8A26qqgFuTXAHcBhwEzvWdMpK0+hYN96o6+xBdLznE+HcA7+hTlCSpHz+hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMWDfckFyc50N2YY37fm5NUkvXdfpK8N8meJF9JcuI4ipYkHd5SztwvAU6b35hkM/Bc4NtDzc9ncGu944HtwPv7lyhJWq5Fw72qrgfuWaDrXcBbgBpq2wJc2t04+wbg6CQbVqRSSdKSjXTNPckWYF9VfXle10bgrqH9vV3bQo+xPclsktm5ublRypAkHcKywz3JI4C3AW/vM3FV7aiqmaqamZqa6vNQkqR5Fr1B9gJ+DTgO+HISgE3ATUlOAvYBm4fGburaJEmraNln7lV1c1U9vqqmq2qawaWXE6vqbmAX8LLuXTMnA/dW1f6VLVmStJilvBXycuA/gCcl2ZvknMMM/xRwB7AH+HvgNStSpSRpWRa9LFNVZy/SPz20XcC5/cuSJPXhJ1QlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGjfKVv5IaNn3eJyc2950Xnj6xuVvjmbskNehBf+buWYYkPZBn7pLUoKXcrOPiJAeS3DLU9ldJvprkK0k+nuToob7zk+xJ8rUkzxtT3ZKkw1jKmfslwGnz2q4BnlJVTwW+DpwPkOQEYCvw5O6Yv0tyxIpVK0lakkXDvaquB+6Z1/bZqjrY7d7A4EbYAFuAD1fVfVX1TQa32ztpBeuVJC3BSlxz/yPg0932RuCuob69XZskaRX1CvckfwocBC4b4djtSWaTzM7NzfUpQ5I0z8jhnuTlwAuBF3c3xgbYB2weGrapa3uAqtpRVTNVNTM1NTVqGZKkBYwU7klOA94CnFFVPxrq2gVsTXJUkuOA44Ev9C9TkrQci36IKcnlwCnA+iR7gQsYvDvmKOCaJAA3VNWrqurWJFcAtzG4XHNuVf10XMVLkha2aLhX1dkLNF90mPHvAN7RpyhJUj9+QlWSGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KBFwz3JxUkOJLllqO2YJNck+Ub387Fde5K8N8meJF9JcuI4i5ckLWwpZ+6XAKfNazsPuLaqjgeu7fYBns/gvqnHA9uB969MmZKk5Vg03KvqeuCeec1bgJ3d9k7gzKH2S2vgBuDoJBtWqFZJ0hKNes392Kra323fDRzbbW8E7hoat7dre4Ak25PMJpmdm5sbsQxJ0kJ6v6BaVQXUCMftqKqZqpqZmprqW4Ykacio4f6d+y+3dD8PdO37gM1D4zZ1bZKkVTRquO8CtnXb24Crhtpf1r1r5mTg3qHLN5KkVbJusQFJLgdOAdYn2QtcAFwIXJHkHOBbwIu64Z8CXgDsAX4EvGIMNUuSFrFouFfV2YfoOnWBsQWc27coSVI/fkJVkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBvUK9yR/nOTWJLckuTzJw5Icl2R3kj1JPpLkoStVrCRpaRa9WcehJNkIvB44oap+nOQKYCuDOzG9q6o+nOQDwDnA+1ekWgEwfd4nJzb3nReePrG5JS1d38sy64CHJ1kHPALYDzwHuLLr3wmc2XMOSdIyjRzuVbUP+Gvg2wxC/V7gRuD7VXWwG7YX2LjQ8Um2J5lNMjs3NzdqGZKkBYwc7kkeC2wBjgOeADwSOG2px1fVjqqaqaqZqampUcuQJC2gz2WZ3we+WVVzVfW/wMeAZwJHd5dpADYB+3rWKElapj7h/m3g5CSPSBLgVOA24DrgrG7MNuCqfiVKkparzzX33QxeOL0JuLl7rB3AW4E3JdkDPA64aAXqlCQtw8hvhQSoqguAC+Y13wGc1OdxJUn9+AlVSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDeoV7kqOTXJnkq0luT/KMJMckuSbJN7qfj12pYiVJS9P3zP09wGeq6jeApwG3A+cB11bV8cC13b4kaRWNHO5JHgM8i+4eqVX1k6r6PrAF2NkN2wmc2a9ESdJy9TlzPw6YA/4hyReTfDDJI4Fjq2p/N+Zu4NiFDk6yPclsktm5ubkeZUiS5usT7uuAE4H3V9XTgf9h3iWYqiqgFjq4qnZU1UxVzUxNTfUoQ5I037oex+4F9lbV7m7/Sgbh/p0kG6pqf5INwIG+RUqTNH3eJycy750Xnj6RedWGkc/cq+pu4K4kT+qaTgVuA3YB27q2bcBVvSqUJC1bnzN3gNcBlyV5KHAH8AoG/2FckeQc4FvAi3rOIUlapl7hXlVfAmYW6Dq1z+NKkvrxE6qS1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1qHe4Jzmiu0H21d3+cUl2J9mT5CPdjTwkSatoJc7c3wDcPrT/F8C7qurXgf8CzlmBOSRJy9Ar3JNsAk4HPtjtB3gOg5tlA+wEzuwzhyRp+fqeub8beAvws27/ccD3q+pgt78X2LjQgUm2J5lNMjs3N9ezDEnSsJHDPckLgQNVdeMox1fVjqqaqaqZqampUcuQJC2gzw2ynwmckeQFwMOAXwLeAxydZF139r4J2Ne/TEnScox85l5V51fVpqqaBrYCn6uqFwPXAWd1w7YBV/WuUpK0LON4n/tbgTcl2cPgGvxFY5hDknQYfS7L/FxVfR74fLd9B3DSSjyuJGk0fkJVkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBvW5h+rmJNcluS3JrUne0LUfk+SaJN/ofj525cqVJC1FnzP3g8Cbq+oE4GTg3CQnAOcB11bV8cC13b4kaRX1uYfq/qq6qdv+IXA7sBHYAuzshu0EzuxZoyRpmVbkmnuSaeDpwG7g2Kra33XdDRx7iGO2J5lNMjs3N7cSZUiSOr3DPcmjgI8Cb6yqHwz3VVUBtdBxVbWjqmaqamZqaqpvGZKkIb3CPcmRDIL9sqr6WNf8nSQbuv4NwIF+JUqSlqvPu2UCXATcXlXvHOraBWzrtrcBV41eniRpFOt6HPtM4KXAzUm+1LW9DbgQuCLJOcC3gBf1qlCStGwjh3tV/TuQQ3SfOurjSpL68xOqktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGjS3ck5yW5GtJ9iQ5b1zzSJIeaCzhnuQI4G+B5wMnAGcnOWEcc0mSHmhcZ+4nAXuq6o6q+gnwYWDLmOaSJM2Tqlr5B03OAk6rqld2+y8FfqeqXjs0Zjuwvdt9EvC1EadbD3y3R7njslbrgrVbm3Utj3UtT4t1/WpVTS3UMfINsvuqqh3Ajr6Pk2S2qmZWoKQVtVbrgrVbm3Utj3Utzy9aXeO6LLMP2Dy0v6lrkyStgnGF+38Cxyc5LslDga3ArjHNJUmaZyyXZarqYJLXAv8CHAFcXFW3jmMuVuDSzpis1bpg7dZmXctjXcvzC1XXWF5QlSRNlp9QlaQGGe6S1KAHTbgnuTjJgSS3HKI/Sd7bfd3BV5KcuEbqOiXJvUm+1P15+yrUtDnJdUluS3JrkjcsMGbV12uJdU1ivR6W5AtJvtzV9WcLjDkqyUe69dqdZHqN1PXyJHND6/XKcdc1NPcRSb6Y5OoF+lZ9vZZY1yTX684kN3fzzi7Qv7LPyap6UPwBngWcCNxyiP4XAJ8GApwM7F4jdZ0CXL3Ka7UBOLHbfjTwdeCESa/XEuuaxHoFeFS3fSSwGzh53pjXAB/otrcCH1kjdb0ceN9qrtfQ3G8CPrTQ39ck1muJdU1yve4E1h+mf0Wfkw+aM/equh645zBDtgCX1sANwNFJNqyBulZdVe2vqpu67R8CtwMb5w1b9fVaYl2rrluD/+52j+z+zH+nwRZgZ7d9JXBqkqyBuiYiySbgdOCDhxiy6uu1xLrWshV9Tj5own0JNgJ3De3vZQ0ER+cZ3a/Wn07y5NWcuPt1+OkMzvqGTXS9DlMXTGC9ul/lvwQcAK6pqkOuV1UdBO4FHrcG6gL4w+7X+CuTbF6gfxzeDbwF+Nkh+ieyXkuoCyazXjD4j/mzSW7M4OtX5lvR52RL4b5W3cTg+x+eBvwN8InVmjjJo4CPAm+sqh+s1ryLWaSuiaxXVf20qn6TwaepT0rylNWYdzFLqOufgemqeipwDf9/tjw2SV4IHKiqG8c913Issa5VX68hv1tVJzL4ttxzkzxrnJO1FO5r8isPquoH9/9qXVWfAo5Msn7c8yY5kkGAXlZVH1tgyETWa7G6JrVeQ/N/H7gOOG1e18/XK8k64DHA9yZdV1V9r6ru63Y/CPzWKpTzTOCMJHcy+MbX5yT5p3ljJrFei9Y1ofW6f+593c8DwMcZfHvusBV9TrYU7ruAl3WvOJ8M3FtV+yddVJJfvv9aY5KTGKz5WP+Rd/NdBNxeVe88xLBVX6+l1DWh9ZpKcnS3/XDgD4Cvzhu2C9jWbZ8FfK66V8EmWde8a7JnMHgdY6yq6vyq2lRV0wxeLP1cVb1k3rBVX6+l1DWJ9ermfWSSR9+/DTwXmP8OuxV9Tk7sWyGXK8nlDN5JsT7JXuACBi8wUVUfAD7F4NXmPcCPgFeskbrOAl6d5CDwY2DruP+RMziDeSlwc3e9FuBtwK8M1TWJ9VpKXZNYrw3AzgxuMvMQ4IqqujrJnwOzVbWLwX9K/5hkD4MX0LeOuaal1vX6JGcAB7u6Xr4KdS1oDazXUuqa1HodC3y8O29ZB3yoqj6T5FUwnuekXz8gSQ1q6bKMJKljuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QG/R+4cwlWYMnx5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(fakeReviews.groupby('rating').agg('count'))\n",
    "plt.hist(x=fakeReviews.rating, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(x = trueReviews['reviewContent'].str.count(' ') + 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(x = fakeReviews['reviewContent'].str.count(' ') + 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(x = trueReviews['reviewContent'].str.count('.') + 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(x = fakeReviews['reviewContent'].str.count('.') + 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trueReviewerCounts = trueReviews.groupby(['reviewerID']).size().reset_index(name='counts')\n",
    "fakeReviewerCounts = fakeReviews.groupby(['reviewerID']).size().reset_index(name='counts')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(x = trueReviewerCounts['counts'], bins=10)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(x = fakeReviewerCounts['counts'], bins=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trueRestReviewCounts = trueReviews.groupby(['hotelID']).size().reset_index(name='counts')\n",
    "fakeRestReviewCounts = fakeReviews.groupby(['hotelID']).size().reset_index(name='counts')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(x = trueRestReviewCounts['counts'], bins=10)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(x = fakeRestReviewCounts['counts'], bins=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD6CAYAAABNu5eFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYsElEQVR4nO3df7BcZX3H8feniaCiNQnonUyS9oaa6oBoDBnE8cekpsUQGKKdlpJxNEim0QrWlsxoop1qZTqDPyhCtUiUNDBDEQSRDEYxjaTaGYkYiEn4EXOJQXInJMqPIFKtsd/+cZ4r5252c/ee3eyec8/nNbNzz3nOs7vfJ/fZb8599pznUURgZmb18Hv9DsDMzHrHSd/MrEac9M3MasRJ38ysRpz0zcxqxEnfzKxGxkz6ktZKOihpZ5NjKyWFpJPSviRdLWlI0nZJ83J1l0nanR7LutsMMzNrx+Q26qwDPg/ckC+UNAs4C/hprvhsYE56vAG4BniDpGnAx4H5QABbJa2PiKeO9sYnnXRSDA4ONj32y1/+khNOOKGN8KtpIrevTG3bunXrzyPi5b1+36r1bcfUnrLEdNR+HRFjPoBBYGdD2a3A64C9wEmp7Fpgaa7OLmA6sBS4Nlc+ql6rx+mnnx6t3H333S2PTQQTuX1lahvww2jjM9DtR9X6tmNqT1liOlq/LjSmL2kJMBwRP2o4NAN4LLe/L5W1Kjczsx5qZ3hnFEkvBj5KNrTTdZJWACsABgYG2Lx5c9N6zz77bMtjE8FEbt9EbptZ2Y076QN/BMwGfiQJYCZwn6QzgGFgVq7uzFQ2DCxoKN/c7MUjYg2wBmD+/PmxYMGCZtXYvHkzrY5NBBO5fRO5bWZlN+7hnYjYERGviIjBiBgkG6qZFxGPA+uB96SreM4EDkXEfuAu4CxJUyVNJfsr4a7uNcPMzNrRziWbNwHfB14laZ+k5UepvgHYAwwBXwI+ABARTwKXAfemxydTmZmZ9dCYwzsRsXSM44O57QAublFvLbB2nPGZmVkX+Y5cM7MacdI3M6sRJ30zsxopcslmKewYPsSFq74x7uftvfycYxCNWf8NFvg8gD8TdeMzfTOzGqnsmX5RPhsyszrzmb6ZWY046ZuZ1YiTvplZjTjpm5nViJO+mVmNOOmbmdVI7S7ZNBuLpLXAucDBiHhNKrsZeFWqMgV4OiLmShoEHiJbGhTgnoh4fyfvX/TGQ7N2OOmbHWkd8HnghpGCiPirkW1JVwCHcvUfiYi5vQrOrBNO+mYNIuK76Qz+CMqWizsfeFtPgzLrEo/pm43PW4ADEbE7VzZb0v2S/kvSW/oVmFk7fKZvNj5LgZty+/uBP4iIJySdDnxd0qkR8UzjEyWtAFYADAwMtFwcfuBFsPK0w10PvJV2Fqkv42L2jqkYJ32zNkmaDPw5cPpIWUT8Gvh12t4q6RHgj4EfNj4/ItYAawDmz58frRaH/9cb7+CKHb37aO59V/M48sq4mL1jKsbDO2bt+1Pg4YjYN1Ig6eWSJqXtk4E5ZOtEm5WSk75ZA0k3Ad8HXiVpn6Tl6dAFjB7aAXgrsF3SNuBW4P0R8WTPgjUbJw/vmDWIiKUtyi9sUnYbcNuxjsmsW3ymb2ZWI2MmfUlrJR2UtDNX9hlJD0vaLul2SVNyx1ZLGpK0S9Lbc+WLUtmQpFVdb4mZmY2pnTP9dcCihrKNwGsi4rXAj4HVAJJOIRv3PDU9598kTUpfdH0BOBs4BVia6pqZWQ+NmfQj4rvAkw1l346IkQuJ7wFmpu0lwFci4tcR8RNgCDgjPYYiYk9E/C/wlVTXzMx6qBtj+hcB30zbM4DHcsf2pbJW5WZm1kMdXb0j6WPAYeDG7oRT7bsWu6kKd/YVNZHbZlZ2hZO+pAvJpp9dGBGRioeBWblqM1MZRykfpcp3LXZTFe7sK2oit82s7AoN70haBHwYOC8inssdWg9cIOl4SbPJ7k78AXAvMEfSbEnHkX3Zu76z0M3MbLzGPFVOdycuAE6StA/4ONnVOscDG7OZZrOFIyLiAUm3AA+SDftcHBG/Ta9zCXAXMAlYGxEPHIP2mJnZUYyZ9FvcnXjdUer/M/DPTco3ABvGFZ2ZmXWV78g1M6sRJ30zsxpx0jczqxEnfTOzGnHSNzOrESd9M7MacdI3M6sRJ30zsxpx0jczqxEnfbMGLVaL+4SkYUnb0mNx7ljT1eLMyshJ3+xI6zhytTiAKyNibnpsgNarxfUsUrNxctI3a9BstbijaLVanFkpOembte8SSdvT8M/UVOZV4axSercKiVm1XQNcBkT6eQXZUqFtq/KqcGVc7cwxFeOkb9aGiDgwsi3pS8Cdafdoq8U1vkZlV4Ur42pnjqkYD++YtUHS9NzuO4GRK3tarRZnVko+0zdr0GK1uAWS5pIN7+wF3gdwtNXizMrISd+sQbdWizMrIw/vmJnViJO+mVmNOOmbmdWIk76ZWY2MmfRbTD41TdJGSbvTz6mpXJKuTpNPbZc0L/ecZan+bknLjk1zzMzsaNo501/HkZNPrQI2RcQcYFPaBzib7DrlOWR3Hl4D2X8SZJe9vYFsXpKP525jNzOzHhkz6beYfGoJcH3avh54R678hsjcA0xJN7W8HdgYEU9GxFPARprPYmhmZsdQ0ev0ByJif9p+HBhI260mn2p7Uqoqz0/STVWYw6Ooidw2s7Lr+OasiAhJ0Y1g0utVdn6SbqrCHB5FTeS2mZVd0at3DozMRZJ+HkzlrSafantSKjMzO3aKJv31wMgVOMuAO3Ll70lX8ZwJHErDQHcBZ0mamr7APSuVmZlZD405PtJi8qnLgVskLQceBc5P1TcAi8lWD3oOeC9ARDwp6TLg3lTvkxHR7spEZmbWJWMm/RaTTwEsbFI3gItbvM5aYO24ojMzs67yHblmZjXipG9mViNO+mZmNeKkb2ZWI076ZmY14qRvZlYjTvpmDVpMJ/4ZSQ+nKcNvlzQllQ9K+h9J29Lji30L3KwNTvpmR1rHkbPAbgReExGvBX4MrM4deyQi5qbH+3sUo1khTvpmDZpNJx4R346IkWld7yGbP8qscno3TaXZxHERcHNuf7ak+4FngH+IiO81e1KVpw0v43TYjqkYJ32zcZD0MeAwcGMq2g/8QUQ8Iel04OuSTo2IZxqfW+Vpw8s4HbZjKsbDO2ZtknQhcC7wrjTPFBHx64h4Im1vBR4B/rhvQZqNwUnfrA2SFgEfBs6LiOdy5S+XNCltn0y2PvSe/kRpNjYP75g1aDGd+GrgeGCjJIB70pU6bwU+Kek3wP8B7/e04VZmTvpmDVpMJ35di7q3Abcd24jMusfDO2ZmNeKkb2ZWI076ZmY14qRvZlYjTvpmZjXipG9mViMdJX1Jfy/pAUk7Jd0k6YWSZkvaImlI0s2Sjkt1j0/7Q+n4YFdaYGZmbSuc9CXNAP4WmB8RrwEmARcAnwKujIhXAk8By9NTlgNPpfIrUz0zM+uhTod3JgMvkjQZeDHZ5FNvA25Nx68H3pG2l6R90vGFSrc2mplZbxRO+hExDHwW+ClZsj8EbAWezs07vg+YkbZnAI+l5x5O9U8s+v5mZjZ+hadhkDSV7Ox9NvA08FWOXG2oyOtWds7xbqrCvNxFTeS2mZVdJ3Pv/Cnwk4j4GYCkrwFvAqZImpzO5mcCw6n+MDAL2JeGg14GPNH4olWec7ybqjAvd1ETuW1mZdfJmP5PgTMlvTiNzS8EHgTuBv4i1VkG3JG216d90vHvjMxJbmZmvdHJmP4Wsi9k7wN2pNdaA3wEuFTSENmY/cjshNcBJ6byS4FVHcRtZmYFdDQ+EhEfJ5trPG8PcEaTur8C/rKT9zMzs874jlwzsxpx0jczqxEnfTOzGnHSN2sgaa2kg5J25sqmSdooaXf6OTWVS9LVaU6p7ZLm9S9ys7E56ZsdaR1H3mi4CtgUEXOATTx/9dnZwJz0WAFc06MYzQpx0jdrEBHfBZ5sKM7PHdU4p9QNkbmH7ObE6T0J1KwAJ32z9gxExP60/TgwkLZ/N6dUkp9vyqx0ejePgdkEEREhadx3k1d5XqkyzpfkmIpx0jdrzwFJ0yNifxq+OZjKR+aUGpGfb2qUKs8rVcb5khxTMR7eMWtPfu6oxjml3pOu4jkTOJQbBjIrHZ/pmzWQdBOwADhJ0j6yqUYuB26RtBx4FDg/Vd8ALAaGgOeA9/Y8YLNxcNI3axARS1scWtikbgAXH9uIzLrHwztmZjXiM/02Da76RqHn7b38nC5HYmZWnM/0zcxqxEnfzKxGnPTNzGrESd/MrEac9M3MasRJ38ysRpz0zcxqxEnfzKxGOkr6kqZIulXSw5IekvRGLytnZlZenZ7pXwV8KyJeDbwOeAgvK2dmVlqFk76klwFvBa4DiIj/jYin8bJyZmal1cmZ/mzgZ8C/S7pf0pclnYCXlTMzK61OJlybDMwDPhgRWyRdxfNDOUCxZeXKuqRcUUWXTqvCsmtFTeS2VVE7kwmuPO0wF+bqeSLB6uok6e8D9kXElrR/K1nS72hZubIuKVdUO0vRNVOFZdeKmshtMyu7wsM7EfE48JikV6WihcCDeFk5M7PS6vRU+YPAjZKOA/aQLRX3e3hZOTOzUuoo6UfENmB+k0NeVs7MrITKPyhuVhJpKPPmXNHJwD8CU4C/JruaDeCjEbGht9GZtcdJ36xNEbELmAsgaRLZhQi3kw1VXhkRn+1fdGbt8dw7ZsUsBB6JiEf7HYjZeDjpmxVzAXBTbv+SNKfU2pH5pszKyMM7ZuOUrlY7D1idiq4BLgMi/bwCuKjJ8yp742FjTGW4ua6MN/mVMaZGTvpm43c2cF9EHAAY+Qkg6UvAnc2eVOUbD1eednhUTEVvOuymMt7kV8aYGnl4x2z8lpIb2mmYOPCdwM6eR2TWpnKdTpiVXJpU8M+A9+WKPy1pLtnwzt6GY2al4qRvNg4R8UvgxIayd/cpHLNx8/COmVmNOOmbmdWIk76ZWY046ZuZ1YiTvplZjTjpm5nViJO+mVmNOOmbmdWIk76ZWY046ZuZ1YiTvplZjTjpm5nViJO+mVmNdJz0JU2SdL+kO9P+bElbJA1JujmtMoSk49P+UDo+2Ol7m5nZ+HTjTP9DwEO5/U8BV0bEK4GngOWpfDnwVCq/MtUzM7Me6ijpS5oJnAN8Oe0LeBtwa6pyPfCOtL0k7ZOOL0z1zcysRzpdROVzwIeBl6b9E4GnI2JkBeV9wIy0PQN4DCAiDks6lOr/PP+CVV48upmiiyRXYYHloiZy28zKrnDSl3QucDAitkpa0K2Aqrx4dDNFF5CuwgLLRU3ktpmVXSdZ803AeZIWAy8Efh+4CpgiaXI6258JDKf6w8AsYJ+kycDLgCc6eH8zMxunwmP6EbE6ImZGxCBwAfCdiHgXcDfwF6naMuCOtL0+7ZOOfyciouj7m/WDpL2SdkjaJumHqWyapI2SdqefU/sdp1krx+I6/Y8Al0oaIhuzvy6VXwecmMovBVYdg/c264U/iYi5ETE/7a8CNkXEHGAT7ttWYl0ZFI+IzcDmtL0HOKNJnV8Bf9mN9zMrmSXAgrR9Pdln4SP9CsbsaMr/TahZuQTwbUkBXJsuPBiIiP3p+OPAQLMnVvnKtMaYynD1VRmvAitjTI2c9M3G580RMSzpFcBGSQ/nD0ZEpP8QjlDlK9NWnnZ4VExFr0rrpjJeBVbGmBqVq2eZlVxEDKefByXdTjaUeUDS9IjYL2k6cLCvQfbA4KpvFHre3svP6XIkNl6ecM2sTZJOkPTSkW3gLGAno69My1+xZlY6PtM3a98AcHuaPWQy8B8R8S1J9wK3SFoOPAqc38cYzY7KSd+sTenKtNc1KX8CWNj7iMzGz0n/GCs69rlu0QldjsTMzGP6Zma14qRvZlYjTvpmZjXipG9mViNO+mZmNeKkb2ZWI076ZmY14qRvZlYjTvpmZjXipG9mViNO+mZmNeKkb2ZWI076ZmY14qRvZlYjhZO+pFmS7pb0oKQHJH0olU+TtFHS7vRzaiqXpKslDUnaLmletxphZmbt6eRM/zCwMiJOAc4ELpZ0CrAK2BQRc4BNaR/gbGBOeqwArungvc3MrIDCST8i9kfEfWn7F8BDwAxgCXB9qnY98I60vQS4ITL3AFPSItJmZtYjXRnTlzQIvB7YAgxExP506HGydUUh+w/hsdzT9qUys0o4ypDmJyQNS9qWHov7HatZKx0vlyjpJcBtwN9FxDNp0WgAIiIkxThfbwXZ8A8DAwNs3ry5ab2BF8HK0w4XDbv0nn322ZZtr7oKt21kSPM+SS8FtkramI5dGRGf7WNsZm3pKOlLegFZwr8xIr6Wig9Imh4R+9PwzcFUPgzMyj19ZiobJSLWAGsA5s+fHwsWLGj63v964x1csWPiLvG7btEJtGp71W3evLmSbUt/we5P27+QNDKkaVYZnVy9I+A64KGI+JfcofXAsrS9DLgjV/6edBXPmcCh3DCQWaU0DGkCXJKuSls7csWaWRl1cqr8JuDdwA5J21LZR4HLgVskLQceBc5PxzYAi4Eh4DngvR28t1nfNBnSvAa4DIj08wrgoibPq+zQZbdi6uawXhmHCcsYU6PCST8i/htQi8MLm9QP4OKi72dWBs2GNCPiQO74l4A7mz23ykOXK0873JWY9r5rQefBJGUcJixjTI18R65Zm1oNaTZcevxOYGevYzNrV7lOJ8zKrdWQ5lJJc8mGd/YC7+tHcFUwuOobhZ639/JzuhxJfTnpl9SO4UNcWOAD4g/HsXOUIc0NvY7FrCgP75iZ1YiTvplZjXh4x8xKr9l3AStPOzzmEKiHO4/kM30zsxpx0jczqxEnfTOzGnHSNzOrESd9M7MacdI3M6sRJ30zsxpx0jczqxEnfTOzGvEduWY2YXlWzyM56U8wRTr5RO7gZjaah3fMzGrESd/MrEY8vGNm1qDodwHrFp3Q5Ui6z2f6ZmY14qRvZlYjPR/ekbQIuAqYBHw5Ii7vdQw2mi9r65z7tUHxta2LKPr562nSlzQJ+ALwZ8A+4F5J6yPiwV7GYdVU1v+c3K+tSnp9pn8GMBQRewAkfQVYAvjDUUFFk3A7y9xVjPu1VUavx/RnAI/l9velMrMqc7+2yijdJZuSVgAr0u6zkna1qHoS8PPeRNV7fzuB29frtulTRz38hz0Ko9J9u4z9se4xFe3XvU76w8Cs3P7MVPY7EbEGWDPWC0n6YUTM72545TGR2zcB2zZmv4Zq923H1J4yxtSo18M79wJzJM2WdBxwAbC+xzGYdZv7tVVGT8/0I+KwpEuAu8gubVsbEQ/0MgazbnO/tirp+Zh+RGwANnThpcb8M7niJnL7JlzbutivoZz/Po6pPWWMaRRFRL9jMDOzHvE0DGZmNVLJpC9pkaRdkoYkrep3PO2QNEvS3ZIelPSApA+l8mmSNkranX5OTeWSdHVq43ZJ83KvtSzV3y1pWb/a1EjSJEn3S7oz7c+WtCW14eb0JSeSjk/7Q+n4YO41VqfyXZLe3qem9EUv+7WktZIOStqZK+trXyzjZ0TSCyX9QNKPUkz/lMqr27cjolIPsi/KHgFOBo4DfgSc0u+42oh7OjAvbb8U+DFwCvBpYFUqXwV8Km0vBr4JCDgT2JLKpwF70s+paXtqv9uXYrsU+A/gzrR/C3BB2v4i8Ddp+wPAF9P2BcDNafuU9Ps8Hpidfs+T+t2uHv3b9bRfA28F5gE7c2V97Ytl/Iyk135J2n4BsCW9V2X7dt87e4FfwhuBu3L7q4HV/Y6rQDvuIJurZRcwPZVNB3al7WuBpbn6u9LxpcC1ufJR9frYnpnAJuBtwJ3pw/JzYHLj743sKpc3pu3JqZ4af5f5ehP90Y9+DQw2JP1S9cWyfUaAFwP3AW+oct+u4vBO5W95T3/yvZ7srGEgIvanQ48DA2m7VTvL2v7PAR8G/i/tnwg8HRGH034+zt+1IR0/lOqXtW29UIa2l6YvlukzkoYttwEHgY1kZ+mV7dtVTPqVJuklwG3A30XEM/ljkZ0CVO5yKknnAgcjYmu/Y7Hu6GdfLNtnJCJ+GxFzyf6aPQN4dS/fv9uqmPTbuuW9jCS9gKwz3xgRX0vFByRNT8enk51NQOt2lrH9bwLOk7QX+ArZEM9VwBRJI/eC5OP8XRvS8ZcBT1DOtvVKGdre975Y5s9IRDwN3E02nFPdvt2PMaUOx9Umk30xM5vnv/A6td9xtRG3gBuAzzWUf4bRX1J9Om2fw+gvqX6QyqcBPyH7gmpq2p7W7/bl2rOA57/I/Sqjv+z6QNq+mNFfdt2Stk9l9Jdde6jPF7k979ccOabf175Yxs8I8HJgStp+EfA94Nwq9+2+d/aCv4jFZN/sPwJ8rN/xtBnzm8n+LN0ObEuPxWTjfZuA3cB/jnTO1JG/kNq4A5ife62LgKH0eG+/29bQzgU8n/RPBn6Q4vwqcHwqf2HaH0rHT849/2OpzbuAs/vdnh7/2/WsXwM3AfuB35CNLy/vd18s42cEeC1wf4ppJ/CPVe/bviPXzKxGqjimb2ZmBTnpm5nViJO+mVmNOOmbmdWIk76ZWY046ZuZ1YiTvplZjTjpm5nVyP8DZcAieqTzTqcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "trueReviews['reviewContent'].str.len().hist()\n",
    "plt.subplot(1, 2, 2)\n",
    "fakeReviews['reviewContent'].str.len().hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yizhang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code Snippet for Top N-grams Barchart\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import  Counter\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def plot_top_ngrams_barchart(text, n=2):\n",
    "    synthetic = {'gmail', 'they', 'http', 'www'}\n",
    "    stop=set(stopwords.words('english')) | synthetic\n",
    "    new= text.str.split()\n",
    "    new= new.values.tolist()\n",
    "    corpus=[word for i in new for word in i if word.lower() not in stop]\n",
    "\n",
    "    def _get_top_ngram(corpus, n=None):\n",
    "        vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) \n",
    "                      for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq[:20]\n",
    "\n",
    "    top_n_bigrams=_get_top_ngram(corpus,n)[:20]\n",
    "    x,y=map(list,zip(*top_n_bigrams))\n",
    "    sns.barplot(x=y,y=x)\n",
    "    \n",
    "\n",
    "plot_top_ngrams_barchart(trueReviews['reviewContent'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_top_ngrams_barchart(fakeReviews['reviewContent'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake Reviewers 751\n",
      "True Reviewers 4277\n",
      "True and Fake Reviewers 0\n"
     ]
    }
   ],
   "source": [
    "fake_df = hotel_reviews[hotel_reviews['flagged'] == 'Y'][\"reviewerID\"].to_frame()\n",
    "true_df = hotel_reviews[hotel_reviews['flagged'] == 'N'][\"reviewerID\"].to_frame()\n",
    "print(\"Fake Reviewers \" + str(len(fake_df[\"reviewerID\"].unique())))\n",
    "print(\"True Reviewers \" + str(len(true_df[\"reviewerID\"].unique())))\n",
    "print(\"True and Fake Reviewers \" + str(len(list(set(fake_df[\"reviewerID\"].unique()) & set(true_df[\"reviewerID\"].unique())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake stats Counts 777 Sum 486\n",
      "True stats Counts 5072 Sum 144161\n"
     ]
    }
   ],
   "source": [
    "full_rest_df = pd.merge(hotel_reviews, hotel_reviewers, on=\"reviewerID\")\n",
    "fake_df = full_rest_df[full_rest_df['flagged'] == 'Y'][\"firstCount\"]\n",
    "true_df = full_rest_df[full_rest_df['flagged'] == 'N'][\"firstCount\"]\n",
    "print(\"Fake stats Counts \" + str(fake_df.count()) + str(\" Sum \") + str(fake_df.sum()))\n",
    "print(\"True stats Counts \" + str(true_df.count()) + str(\" Sum \") + str(true_df.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded the embedding\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# GloVe Embeddings\n",
    "# Download the GloVe embeddings\n",
    "if 'embedding' not in os.listdir('.') or not os.listdir('embedding'):\n",
    "    os.system('wget http://nlp.stanford.edu/data/glove.6B.zip -P embedding/')\n",
    "    os.system('cd embedding && unzip glove.6B.zip')\n",
    "    print('Data the GloVe embedding successfully!')\n",
    "else:\n",
    "    print('Already downloaded the embedding')\n",
    "    \n",
    "# Use the 100 dimensional GloVe embedding\n",
    "path_to_glove_file = \"./embedding/glove.6B.300d.txt\"\n",
    "\n",
    "glove_dimension = 300\n",
    "glove_embedding_map = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        glove_embedding_map[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(glove_embedding_map))\n",
    "\n",
    "def get_glove_embedding(word):\n",
    "    return glove_embedding_map.get(word.strip(), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 21:51:56.593776: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Pre-trained Elmo\n",
    "elmo = hub.load(\"./elmo_3\")\n",
    "\n",
    "def get_elmo_embedding(words):\n",
    "    return elmo.signatures['default'](tf.constant(words))['elmo']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for the different training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set 1 value counts:\n",
      "N    3975\n",
      "Y     561\n",
      "Name: flagged, dtype: int64\n",
      "training set 2 value counts:\n",
      "Y    561\n",
      "N    561\n",
      "Name: flagged, dtype: int64\n",
      "training set 3 value counts:\n",
      "Y    3975\n",
      "N    3975\n",
      "Name: flagged, dtype: int64\n",
      "training set 4 value counts:\n",
      "Y    2535\n",
      "N    2535\n",
      "Name: flagged, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set 1: original imbalanced set\n",
    "hotel_X_train_1 = hotel_X_train.copy()\n",
    "hotel_y_train_1 = hotel_X_train_1['flagged'] == 'Y'\n",
    "print('training set 1 value counts:')\n",
    "print(hotel_X_train_1['flagged'].value_counts())\n",
    "\n",
    "# Prepping for data balancing\n",
    "hotel_X_train_positive = hotel_X_train[hotel_X_train['flagged'] == 'Y']\n",
    "hotel_X_train_negative = hotel_X_train[hotel_X_train['flagged'] == 'N']\n",
    "\n",
    "hotel_num_positive_samples = len(hotel_X_train_positive)\n",
    "hotel_num_negative_samples = len(hotel_X_train_negative)\n",
    "\n",
    "# Train set 2: Under sampling some negative training samples\n",
    "hotel_X_sampled_negatives = hotel_X_train_negative.sample(n=hotel_num_positive_samples).reset_index(drop=True)\n",
    "\n",
    "hotel_X_train_2 = pd.concat([hotel_X_train_positive, hotel_X_sampled_negatives], ignore_index=True).sample(frac=1)\n",
    "hotel_y_train_2 = hotel_X_train_2['flagged'] == 'Y'\n",
    "print('training set 2 value counts:')\n",
    "print(hotel_X_train_2['flagged'].value_counts())\n",
    "\n",
    "# Train set 3: Over sampling some positive training samples\n",
    "hotel_X_sampled_positives = hotel_X_train_positive.sample(n=hotel_num_negative_samples, replace=True).reset_index(drop=True)\n",
    "\n",
    "hotel_X_train_3 = pd.concat([hotel_X_sampled_positives, hotel_X_train_negative], ignore_index=True).sample(frac=1)\n",
    "hotel_y_train_3 = hotel_X_train_3['flagged'] == 'Y'\n",
    "print('training set 3 value counts:')\n",
    "print(hotel_X_train_3['flagged'].value_counts())\n",
    "\n",
    "\n",
    "# Train set 4: Including generated fake reviews\n",
    "# Load in previous generated fake reviews\n",
    "with open('final_GAN.txt') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    lines = [l for l in lines if l]\n",
    "    hotel_X_train_positive_generated = pd.DataFrame({'reviewContent':lines, 'flagged': 'Y'})\n",
    "\n",
    "# Add generated fake reviews into the training set\n",
    "\n",
    "hotel_X_train_all_positive = pd.concat([hotel_X_train_positive, hotel_X_train_positive_generated], ignore_index=True)\n",
    "\n",
    "num_samples = min(len(hotel_X_train_all_positive), len(hotel_X_train_negative))\n",
    "hotel_X_train_all_positive_sampled = hotel_X_train_all_positive.sample(n=num_samples)\n",
    "hotel_X_train_negative_sampled = hotel_X_train_negative.sample(n=num_samples)\n",
    "\n",
    "hotel_X_train_4 = pd.concat([hotel_X_train_all_positive_sampled, hotel_X_train_negative_sampled], ignore_index=True).sample(frac=1)\n",
    "hotel_y_train_4 = hotel_X_train_4['flagged'] == 'Y'\n",
    "print('training set 4 value counts:')\n",
    "print(hotel_X_train_4['flagged'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: GloVe Embedding + Plain LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_1(X_train, y_train, X_test, y_test, num_units, num_epochs, sequence_length):\n",
    "    \n",
    "    # First layer, vectorizing the word input\n",
    "    m1_vectorizer = TextVectorization(output_sequence_length=sequence_length)\n",
    "    m1_vectorizer.adapt(X_train['reviewContent'].to_numpy())\n",
    "    m1_voc = m1_vectorizer.get_vocabulary()\n",
    "\n",
    "    print(f\"Model 1: vocabulary size is {len(m1_voc)}\")\n",
    "\n",
    "    # Build + Lock in the Embedding layer from GloVe\n",
    "    # Ref: https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    num_words = len(m1_voc)\n",
    "\n",
    "    # Prepare embedding matrix\n",
    "    m1_embedding_matrix = np.zeros((num_words, glove_dimension))\n",
    "    for i, word in enumerate(m1_voc):\n",
    "        embedding_vector = get_glove_embedding(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            # This includes the representation for \"padding\" and \"OOV\"\n",
    "            m1_embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "\n",
    "    m1_embedding_layer = Embedding(\n",
    "        num_words,\n",
    "        glove_dimension,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(m1_embedding_matrix),\n",
    "        trainable=False,\n",
    "    )\n",
    "\n",
    "    # Vectorize the input\n",
    "    X_train_ready = m1_vectorizer(X_train['reviewContent']).numpy()\n",
    "    X_test_ready = m1_vectorizer(X_test['reviewContent']).numpy()\n",
    "    print(f'training set shape: {X_train_ready.shape}')\n",
    "\n",
    "    # Build and train the model with \n",
    "    model = Sequential(name='model_1')\n",
    "    model.add(m1_embedding_layer)\n",
    "    model.add(LSTM(num_units))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    model.fit(X_train_ready, y_train, epochs=num_epochs)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_predicted = model.predict(X_test_ready)\n",
    "    print(classification_report(y_predicted > 0.5, y_test))\n",
    "    print('Test set class distribution')\n",
    "    print(X_test['flagged'].value_counts() / len(X_test))\n",
    "    return model.evaluate(X_test_ready, y_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++training on data set 1+++++++++++++\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=100\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,719,097\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 5s 23ms/step - loss: 0.4273 - accuracy: 0.8754\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3688 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3664 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3641 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3632 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3593 - accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3573 - accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.3533 - accuracy: 0.8763\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3499 - accuracy: 0.8763\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 3s 25ms/step - loss: 0.3460 - accuracy: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 9ms/step - loss: 1.1107 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=200\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,719,097\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 8s 46ms/step - loss: 0.4917 - accuracy: 0.8763\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 7s 47ms/step - loss: 0.3729 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 0.3717 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 0.3707 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 0.3697 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 0.3689 - accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 7s 48ms/step - loss: 0.3679 - accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 0.3676 - accuracy: 0.8763\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 7s 46ms/step - loss: 0.3665 - accuracy: 0.8763\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 0.3660 - accuracy: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 18ms/step - loss: 1.0988 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=350\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,719,097\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 13s 77ms/step - loss: 0.4785 - accuracy: 0.8761\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 16s 113ms/step - loss: 0.3734 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 11s 79ms/step - loss: 0.3720 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 11s 78ms/step - loss: 0.3704 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 11s 77ms/step - loss: 0.3692 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 11s 76ms/step - loss: 0.3679 - accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 0.3664 - accuracy: 0.8770\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 11s 75ms/step - loss: 0.3649 - accuracy: 0.8781\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 11s 78ms/step - loss: 0.3635 - accuracy: 0.8783\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 11s 79ms/step - loss: 0.3617 - accuracy: 0.8794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 27ms/step - loss: 1.1259 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=100\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,505\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 4s 21ms/step - loss: 0.3992 - accuracy: 0.8719\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3682 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3651 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3609 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3573 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3518 - accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3427 - accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3351 - accuracy: 0.8776\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3231 - accuracy: 0.8790\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 0.3109 - accuracy: 0.8836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       431\n",
      "        True       0.00      1.00      0.01         1\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.75      0.34       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.1172 - accuracy: 0.5023\n",
      "Accuracy for this run is: 0.5023148059844971\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=200\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,505\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 8s 46ms/step - loss: 0.4391 - accuracy: 0.8728\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 7s 46ms/step - loss: 0.3722 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 6s 46ms/step - loss: 0.3699 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 7s 47ms/step - loss: 0.3677 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 7s 48ms/step - loss: 0.3649 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 7s 46ms/step - loss: 0.3619 - accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 7s 47ms/step - loss: 0.3581 - accuracy: 0.8765\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 6s 46ms/step - loss: 0.3553 - accuracy: 0.8770\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 7s 47ms/step - loss: 0.3509 - accuracy: 0.8785\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 7s 50ms/step - loss: 0.3465 - accuracy: 0.8785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 17ms/step - loss: 1.1753 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=350\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,505\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 14s 86ms/step - loss: 0.4403 - accuracy: 0.8763\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 14s 96ms/step - loss: 0.3733 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 12s 86ms/step - loss: 0.3724 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 12s 87ms/step - loss: 0.3706 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 13s 93ms/step - loss: 0.3686 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 14s 101ms/step - loss: 0.3667 - accuracy: 0.8768\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 13s 92ms/step - loss: 0.3646 - accuracy: 0.8770\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 13s 88ms/step - loss: 0.3626 - accuracy: 0.8781\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 12s 86ms/step - loss: 0.3606 - accuracy: 0.8785\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 12s 85ms/step - loss: 0.3586 - accuracy: 0.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 29ms/step - loss: 1.1048 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=100\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,751,857\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 6s 27ms/step - loss: 0.4026 - accuracy: 0.8704\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 0.3658 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.3615 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.3578 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.3502 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.3417 - accuracy: 0.8765\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 0.3294 - accuracy: 0.8779\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.3146 - accuracy: 0.8825\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.2966 - accuracy: 0.8884\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 0.2770 - accuracy: 0.8984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.50      0.67       427\n",
      "        True       0.01      0.60      0.03         5\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.55      0.35       432\n",
      "weighted avg       0.98      0.50      0.66       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 11ms/step - loss: 1.1334 - accuracy: 0.5023\n",
      "Accuracy for this run is: 0.5023148059844971\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=200\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,751,857\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 10s 58ms/step - loss: 0.4196 - accuracy: 0.8728\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 8s 58ms/step - loss: 0.3722 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 8s 59ms/step - loss: 0.3701 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 8s 58ms/step - loss: 0.3671 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 8s 58ms/step - loss: 0.3629 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 8s 58ms/step - loss: 0.3592 - accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 8s 57ms/step - loss: 0.3547 - accuracy: 0.8770\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 8s 58ms/step - loss: 0.3472 - accuracy: 0.8792\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 8s 59ms/step - loss: 0.3389 - accuracy: 0.8821\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.3297 - accuracy: 0.8849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 21ms/step - loss: 1.4091 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=350\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,751,857\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 17s 105ms/step - loss: 0.4115 - accuracy: 0.8757\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 14s 101ms/step - loss: 0.3726 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 14s 100ms/step - loss: 0.3716 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 14s 101ms/step - loss: 0.3690 - accuracy: 0.8765\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 15s 105ms/step - loss: 0.3667 - accuracy: 0.8772\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 15s 106ms/step - loss: 0.3643 - accuracy: 0.8779\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 15s 107ms/step - loss: 0.3619 - accuracy: 0.8794\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 15s 108ms/step - loss: 0.3584 - accuracy: 0.8799\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 15s 106ms/step - loss: 0.3561 - accuracy: 0.8827\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 18s 124ms/step - loss: 0.3587 - accuracy: 0.8794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.66       431\n",
      "        True       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       0.99      0.50      0.66       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 1.1201 - accuracy: 0.4977\n",
      "Accuracy for this run is: 0.49768519401550293\n",
      "!!!!!!!!!! Best result for data set 1 is 0.5023148059844971\n",
      "+++++++++++training on data set 2+++++++++++++\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=100\n",
      "Model 1: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,203,097\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 3s 33ms/step - loss: 0.6931 - accuracy: 0.4955\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.6832 - accuracy: 0.5927\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.6754 - accuracy: 0.6070\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.6653 - accuracy: 0.6150\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.6578 - accuracy: 0.6239\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.6504 - accuracy: 0.6275\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.6395 - accuracy: 0.6346\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.6240 - accuracy: 0.6613\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.6116 - accuracy: 0.6640\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.5976 - accuracy: 0.6774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.58      0.55       191\n",
      "        True       0.63      0.56      0.60       241\n",
      "\n",
      "    accuracy                           0.57       432\n",
      "   macro avg       0.57      0.57      0.57       432\n",
      "weighted avg       0.58      0.57      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 10ms/step - loss: 0.7136 - accuracy: 0.5718\n",
      "Accuracy for this run is: 0.5717592835426331\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=200\n",
      "Model 1: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,203,097\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 5s 58ms/step - loss: 0.6924 - accuracy: 0.5089\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.6876 - accuracy: 0.5535\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.6830 - accuracy: 0.5410\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.6829 - accuracy: 0.5579\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.6765 - accuracy: 0.5588\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.6711 - accuracy: 0.5722\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 0.6666 - accuracy: 0.5740\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 0.6604 - accuracy: 0.5784\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 0.6526 - accuracy: 0.5918\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 0.6478 - accuracy: 0.5882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.24      0.51      0.32       100\n",
      "        True       0.77      0.50      0.61       332\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.51      0.47       432\n",
      "weighted avg       0.65      0.50      0.54       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 18ms/step - loss: 0.7194 - accuracy: 0.5046\n",
      "Accuracy for this run is: 0.5046296119689941\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=350\n",
      "Model 1: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,203,097\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 5s 92ms/step - loss: 0.6943 - accuracy: 0.4759\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.6911 - accuracy: 0.5098\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.6889 - accuracy: 0.5098\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.6875 - accuracy: 0.5134\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.6851 - accuracy: 0.5187\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.6823 - accuracy: 0.5285\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.6783 - accuracy: 0.5339\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.6757 - accuracy: 0.5392\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.6711 - accuracy: 0.5357\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.6655 - accuracy: 0.5410\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.08      0.71      0.14        24\n",
      "        True       0.97      0.51      0.67       408\n",
      "\n",
      "    accuracy                           0.52       432\n",
      "   macro avg       0.52      0.61      0.41       432\n",
      "weighted avg       0.92      0.52      0.64       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 30ms/step - loss: 0.6902 - accuracy: 0.5231\n",
      "Accuracy for this run is: 0.5231481194496155\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=100\n",
      "Model 1: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,213,505\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 3s 27ms/step - loss: 0.6925 - accuracy: 0.5143\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.6756 - accuracy: 0.5918\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.6653 - accuracy: 0.5989\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.6555 - accuracy: 0.6194\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.6445 - accuracy: 0.6292\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.6492 - accuracy: 0.6230\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.6266 - accuracy: 0.6586\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.6090 - accuracy: 0.6765\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.6563 - accuracy: 0.6230\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.6291 - accuracy: 0.6640\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.40      0.57      0.47       153\n",
      "        True       0.69      0.54      0.61       279\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.55      0.54       432\n",
      "weighted avg       0.59      0.55      0.56       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 9ms/step - loss: 0.6974 - accuracy: 0.5486\n",
      "Accuracy for this run is: 0.5486111044883728\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=200\n",
      "Model 1: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,213,505\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 4s 53ms/step - loss: 0.6928 - accuracy: 0.5098\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 0.6827 - accuracy: 0.5570\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 0.6792 - accuracy: 0.5588\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 0.6697 - accuracy: 0.5758\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 0.6587 - accuracy: 0.5909\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 0.6498 - accuracy: 0.5873\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.6358 - accuracy: 0.6061\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.6335 - accuracy: 0.6043\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.6138 - accuracy: 0.6266\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 2s 63ms/step - loss: 0.6054 - accuracy: 0.6275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.27      0.56      0.36       103\n",
      "        True       0.79      0.52      0.63       329\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.54      0.50       432\n",
      "weighted avg       0.67      0.53      0.56       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 19ms/step - loss: 0.7395 - accuracy: 0.5301\n",
      "Accuracy for this run is: 0.5300925970077515\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=350\n",
      "Model 1: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,213,505\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 6s 98ms/step - loss: 0.6927 - accuracy: 0.4973\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.6891 - accuracy: 0.5205\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.6857 - accuracy: 0.5205\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.6806 - accuracy: 0.5267\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 3s 97ms/step - loss: 0.6811 - accuracy: 0.5214\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 3s 97ms/step - loss: 0.6720 - accuracy: 0.5357\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.6658 - accuracy: 0.5089\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 3s 97ms/step - loss: 0.6648 - accuracy: 0.5187\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.6593 - accuracy: 0.5419\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.6562 - accuracy: 0.5428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.06      0.61      0.12        23\n",
      "        True       0.96      0.51      0.66       409\n",
      "\n",
      "    accuracy                           0.51       432\n",
      "   macro avg       0.51      0.56      0.39       432\n",
      "weighted avg       0.91      0.51      0.63       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 31ms/step - loss: 0.6953 - accuracy: 0.5116\n",
      "Accuracy for this run is: 0.5115740895271301\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=100\n",
      "Model 1: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,235,857\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 3s 28ms/step - loss: 0.6906 - accuracy: 0.5668\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.6681 - accuracy: 0.6087\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.6586 - accuracy: 0.6248\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.6417 - accuracy: 0.6542\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.6167 - accuracy: 0.6524\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.5813 - accuracy: 0.6907\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.5865 - accuracy: 0.6889\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 0.5881 - accuracy: 0.6925\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.5230 - accuracy: 0.7362\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.4819 - accuracy: 0.7638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.60      0.62       225\n",
      "        True       0.59      0.61      0.60       207\n",
      "\n",
      "    accuracy                           0.61       432\n",
      "   macro avg       0.61      0.61      0.61       432\n",
      "weighted avg       0.61      0.61      0.61       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 10ms/step - loss: 0.7244 - accuracy: 0.6088\n",
      "Accuracy for this run is: 0.6087962985038757\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=200\n",
      "Model 1: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,235,857\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 4s 59ms/step - loss: 0.6944 - accuracy: 0.5267\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.6802 - accuracy: 0.5561\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 63ms/step - loss: 0.6735 - accuracy: 0.5642\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.6601 - accuracy: 0.5918\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.6444 - accuracy: 0.5954\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 2s 63ms/step - loss: 0.6310 - accuracy: 0.6194\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.6346 - accuracy: 0.5909\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.6043 - accuracy: 0.6239\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.5843 - accuracy: 0.6319\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.5656 - accuracy: 0.6488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.21      0.55      0.31        84\n",
      "        True       0.82      0.51      0.63       348\n",
      "\n",
      "    accuracy                           0.52       432\n",
      "   macro avg       0.52      0.53      0.47       432\n",
      "weighted avg       0.71      0.52      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 21ms/step - loss: 0.7691 - accuracy: 0.5185\n",
      "Accuracy for this run is: 0.5185185074806213\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=350\n",
      "Model 1: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_17 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,235,857\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 6s 103ms/step - loss: 0.6966 - accuracy: 0.4893\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.6903 - accuracy: 0.5027\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.6873 - accuracy: 0.5036\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.6818 - accuracy: 0.5339\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 4s 100ms/step - loss: 0.6722 - accuracy: 0.5374\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.6624 - accuracy: 0.5303\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.6510 - accuracy: 0.5481\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.6467 - accuracy: 0.5508\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.6450 - accuracy: 0.5321\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.6468 - accuracy: 0.5561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.09      0.62      0.16        32\n",
      "        True       0.94      0.51      0.66       400\n",
      "\n",
      "    accuracy                           0.52       432\n",
      "   macro avg       0.52      0.57      0.41       432\n",
      "weighted avg       0.88      0.52      0.63       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.7039 - accuracy: 0.5185\n",
      "Accuracy for this run is: 0.5185185074806213\n",
      "!!!!!!!!!! Best result for data set 2 is 0.6087962985038757\n",
      "+++++++++++training on data set 3+++++++++++++\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=100\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,719,097\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 9s 27ms/step - loss: 0.6735 - accuracy: 0.5867\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 0.6262 - accuracy: 0.6460\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 0.5608 - accuracy: 0.7042\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 0.4900 - accuracy: 0.7531\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 0.4266 - accuracy: 0.7838\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 0.3891 - accuracy: 0.8030\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 0.3637 - accuracy: 0.8181\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 0.3437 - accuracy: 0.8275\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 0.3166 - accuracy: 0.8460\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 0.2899 - accuracy: 0.8606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.56      0.60       244\n",
      "        True       0.50      0.58      0.54       188\n",
      "\n",
      "    accuracy                           0.57       432\n",
      "   macro avg       0.57      0.57      0.57       432\n",
      "weighted avg       0.58      0.57      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 9ms/step - loss: 1.2748 - accuracy: 0.5694\n",
      "Accuracy for this run is: 0.5694444179534912\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=200\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_19 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,719,097\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 15s 53ms/step - loss: 0.6817 - accuracy: 0.5462\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 0.6492 - accuracy: 0.5918\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 13s 53ms/step - loss: 0.6100 - accuracy: 0.6156\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 13s 53ms/step - loss: 0.5723 - accuracy: 0.6355\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 14s 54ms/step - loss: 0.5453 - accuracy: 0.6486\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 14s 55ms/step - loss: 0.5290 - accuracy: 0.6580\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 14s 55ms/step - loss: 0.5225 - accuracy: 0.6670\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 14s 55ms/step - loss: 0.5129 - accuracy: 0.6810\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 13s 53ms/step - loss: 0.4999 - accuracy: 0.6898\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 13s 53ms/step - loss: 0.4902 - accuracy: 0.7069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.58      0.58       219\n",
      "        True       0.57      0.58      0.58       213\n",
      "\n",
      "    accuracy                           0.58       432\n",
      "   macro avg       0.58      0.58      0.58       432\n",
      "weighted avg       0.58      0.58      0.58       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 17ms/step - loss: 1.1398 - accuracy: 0.5810\n",
      "Accuracy for this run is: 0.5810185074806213\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=350\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,719,097\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 24s 89ms/step - loss: 0.6898 - accuracy: 0.5092\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 23s 91ms/step - loss: 0.6728 - accuracy: 0.5258\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 24s 97ms/step - loss: 0.6560 - accuracy: 0.5326\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 25s 99ms/step - loss: 0.6473 - accuracy: 0.5350\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 25s 102ms/step - loss: 0.6420 - accuracy: 0.5352\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 0.6385 - accuracy: 0.5358\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 25s 99ms/step - loss: 0.6364 - accuracy: 0.5366\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 24s 98ms/step - loss: 0.6353 - accuracy: 0.5481\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 25s 101ms/step - loss: 0.6318 - accuracy: 0.5528\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 25s 102ms/step - loss: 0.6292 - accuracy: 0.5555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.17      0.62      0.26        58\n",
      "        True       0.90      0.52      0.66       374\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.57      0.46       432\n",
      "weighted avg       0.80      0.53      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 33ms/step - loss: 0.7701 - accuracy: 0.5324\n",
      "Accuracy for this run is: 0.5324074029922485\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=100\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_21 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,505\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 9s 28ms/step - loss: 0.6676 - accuracy: 0.5873\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.5968 - accuracy: 0.6709\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 0.4926 - accuracy: 0.7508\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 0.3961 - accuracy: 0.8164\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 0.3124 - accuracy: 0.8692\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 0.2636 - accuracy: 0.8961\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 0.2321 - accuracy: 0.9123\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 0.1954 - accuracy: 0.9318\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 0.1715 - accuracy: 0.9404\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 0.1581 - accuracy: 0.9478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.56      0.65       302\n",
      "        True       0.38      0.63      0.47       130\n",
      "\n",
      "    accuracy                           0.58       432\n",
      "   macro avg       0.58      0.59      0.56       432\n",
      "weighted avg       0.66      0.58      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 10ms/step - loss: 1.5120 - accuracy: 0.5787\n",
      "Accuracy for this run is: 0.5787037014961243\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=200\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_22 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,505\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 16s 57ms/step - loss: 0.6785 - accuracy: 0.5550\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 14s 56ms/step - loss: 0.6350 - accuracy: 0.6004\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 14s 54ms/step - loss: 0.5838 - accuracy: 0.6326\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 14s 56ms/step - loss: 0.5386 - accuracy: 0.6653\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 14s 57ms/step - loss: 0.5142 - accuracy: 0.6859\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 15s 58ms/step - loss: 0.5016 - accuracy: 0.6940\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 15s 60ms/step - loss: 0.4769 - accuracy: 0.7108\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 15s 59ms/step - loss: 0.4554 - accuracy: 0.7406\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 14s 58ms/step - loss: 0.4303 - accuracy: 0.7689\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 15s 59ms/step - loss: 0.4060 - accuracy: 0.7932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.54      0.55       226\n",
      "        True       0.51      0.54      0.53       206\n",
      "\n",
      "    accuracy                           0.54       432\n",
      "   macro avg       0.54      0.54      0.54       432\n",
      "weighted avg       0.54      0.54      0.54       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 19ms/step - loss: 1.2655 - accuracy: 0.5370\n",
      "Accuracy for this run is: 0.5370370149612427\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=350\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,505\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 27s 98ms/step - loss: 0.6837 - accuracy: 0.5150\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 0.6599 - accuracy: 0.5258\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 29s 115ms/step - loss: 0.6461 - accuracy: 0.5387\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 27s 106ms/step - loss: 0.6388 - accuracy: 0.5478\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 25s 102ms/step - loss: 0.6373 - accuracy: 0.5498\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 25s 99ms/step - loss: 0.6384 - accuracy: 0.5367\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 24s 96ms/step - loss: 0.6349 - accuracy: 0.5464\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 24s 96ms/step - loss: 0.6388 - accuracy: 0.5429\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 26s 104ms/step - loss: 0.6340 - accuracy: 0.5497\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 25s 101ms/step - loss: 0.6328 - accuracy: 0.5418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.10      0.56      0.17        39\n",
      "        True       0.92      0.51      0.65       393\n",
      "\n",
      "    accuracy                           0.51       432\n",
      "   macro avg       0.51      0.54      0.41       432\n",
      "weighted avg       0.85      0.51      0.61       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 31ms/step - loss: 0.8286 - accuracy: 0.5116\n",
      "Accuracy for this run is: 0.5115740895271301\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=100\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_24 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,751,857\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 9s 30ms/step - loss: 0.6556 - accuracy: 0.6055\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.5471 - accuracy: 0.7216\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 0.3898 - accuracy: 0.8297\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 0.3023 - accuracy: 0.8701\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 0.2264 - accuracy: 0.9135\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 0.1922 - accuracy: 0.9293\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 0.1429 - accuracy: 0.9537\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 0.1245 - accuracy: 0.9611\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 0.1316 - accuracy: 0.9572\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 0.0960 - accuracy: 0.9721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.53      0.65       351\n",
      "        True       0.23      0.62      0.34        81\n",
      "\n",
      "    accuracy                           0.54       432\n",
      "   macro avg       0.54      0.57      0.49       432\n",
      "weighted avg       0.74      0.54      0.59       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 11ms/step - loss: 2.0502 - accuracy: 0.5440\n",
      "Accuracy for this run is: 0.5439814925193787\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=200\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_25 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,751,857\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 18s 64ms/step - loss: 0.6663 - accuracy: 0.5657\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 15s 62ms/step - loss: 0.5888 - accuracy: 0.6236\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 15s 61ms/step - loss: 0.5341 - accuracy: 0.6531\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 15s 61ms/step - loss: 0.5099 - accuracy: 0.6814\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 16s 64ms/step - loss: 0.4813 - accuracy: 0.7063\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 15s 62ms/step - loss: 0.4668 - accuracy: 0.7211\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 15s 62ms/step - loss: 0.4578 - accuracy: 0.7341\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 15s 62ms/step - loss: 0.4219 - accuracy: 0.7672\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 15s 62ms/step - loss: 0.3980 - accuracy: 0.7869\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 15s 62ms/step - loss: 0.3752 - accuracy: 0.8138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      0.50      0.60       320\n",
      "        True       0.26      0.50      0.34       112\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.50      0.47       432\n",
      "weighted avg       0.62      0.50      0.53       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 22ms/step - loss: 1.4534 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=350\n",
      "Model 1: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_26 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,751,857\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 26s 98ms/step - loss: 0.6822 - accuracy: 0.5176\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 24s 98ms/step - loss: 0.6564 - accuracy: 0.5380\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 25s 101ms/step - loss: 0.6451 - accuracy: 0.5470\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 26s 104ms/step - loss: 0.6373 - accuracy: 0.5508\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 26s 103ms/step - loss: 0.6327 - accuracy: 0.5506\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 26s 104ms/step - loss: 0.6337 - accuracy: 0.5552\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 26s 105ms/step - loss: 0.6240 - accuracy: 0.5592\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 27s 107ms/step - loss: 0.6207 - accuracy: 0.5628\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 26s 105ms/step - loss: 0.6196 - accuracy: 0.5745\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 26s 103ms/step - loss: 0.6145 - accuracy: 0.5745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.17      0.55      0.26        67\n",
      "        True       0.86      0.51      0.64       365\n",
      "\n",
      "    accuracy                           0.52       432\n",
      "   macro avg       0.52      0.53      0.45       432\n",
      "weighted avg       0.75      0.52      0.58       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 39ms/step - loss: 0.7918 - accuracy: 0.5162\n",
      "Accuracy for this run is: 0.5162037014961243\n",
      "!!!!!!!!!! Best result for data set 3 is 0.5810185074806213\n",
      "+++++++++++training on data set 4+++++++++++++\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=100\n",
      "Model 1: vocabulary size is 21015\n",
      "Converted 15322 words (5693 misses)\n",
      "training set shape: (5070, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_27 (Embedding)    (None, None, 300)         6304500   \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,314,397\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 6,304,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 7s 29ms/step - loss: 0.6911 - accuracy: 0.5341\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.6741 - accuracy: 0.5830\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.6507 - accuracy: 0.6134\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.6150 - accuracy: 0.6511\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.5785 - accuracy: 0.6826\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.5364 - accuracy: 0.7292\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 5s 28ms/step - loss: 0.5031 - accuracy: 0.7503\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.4737 - accuracy: 0.7759\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.4469 - accuracy: 0.7943\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.4266 - accuracy: 0.8037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.57      0.58       230\n",
      "        True       0.54      0.57      0.56       202\n",
      "\n",
      "    accuracy                           0.57       432\n",
      "   macro avg       0.57      0.57      0.57       432\n",
      "weighted avg       0.57      0.57      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 9ms/step - loss: 0.8547 - accuracy: 0.5694\n",
      "Accuracy for this run is: 0.5694444179534912\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=200\n",
      "Model 1: vocabulary size is 21015\n",
      "Converted 15322 words (5693 misses)\n",
      "training set shape: (5070, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_28 (Embedding)    (None, None, 300)         6304500   \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,314,397\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 6,304,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 11s 56ms/step - loss: 0.6927 - accuracy: 0.5069\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 9s 58ms/step - loss: 0.6823 - accuracy: 0.5373\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 9s 55ms/step - loss: 0.6687 - accuracy: 0.5538\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 9s 55ms/step - loss: 0.6476 - accuracy: 0.5748\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 9s 55ms/step - loss: 0.6275 - accuracy: 0.5892\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 9s 55ms/step - loss: 0.6047 - accuracy: 0.5998\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 9s 56ms/step - loss: 0.5905 - accuracy: 0.6065\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 9s 57ms/step - loss: 0.5721 - accuracy: 0.6223\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 9s 58ms/step - loss: 0.5582 - accuracy: 0.6197\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 9s 58ms/step - loss: 0.5497 - accuracy: 0.6359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.23      0.60      0.33        83\n",
      "        True       0.85      0.52      0.65       349\n",
      "\n",
      "    accuracy                           0.54       432\n",
      "   macro avg       0.54      0.56      0.49       432\n",
      "weighted avg       0.73      0.54      0.59       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 18ms/step - loss: 0.8004 - accuracy: 0.5394\n",
      "Accuracy for this run is: 0.5393518805503845\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=350\n",
      "Model 1: vocabulary size is 21015\n",
      "Converted 15322 words (5693 misses)\n",
      "training set shape: (5070, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_29 (Embedding)    (None, None, 300)         6304500   \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 8)                 9888      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,314,397\n",
      "Trainable params: 9,897\n",
      "Non-trainable params: 6,304,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 17s 95ms/step - loss: 0.6794 - accuracy: 0.5369\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 15s 94ms/step - loss: 0.6773 - accuracy: 0.5377\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 15s 95ms/step - loss: 0.6755 - accuracy: 0.5400\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 15s 96ms/step - loss: 0.6731 - accuracy: 0.5410\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 15s 96ms/step - loss: 0.6695 - accuracy: 0.5377\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 15s 97ms/step - loss: 0.6659 - accuracy: 0.5460\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 16s 99ms/step - loss: 0.6619 - accuracy: 0.5398\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 15s 95ms/step - loss: 0.6598 - accuracy: 0.5465\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 15s 93ms/step - loss: 0.6597 - accuracy: 0.5462\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 15s 94ms/step - loss: 0.6540 - accuracy: 0.5487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.50      0.65       389\n",
      "        True       0.11      0.53      0.18        43\n",
      "\n",
      "    accuracy                           0.51       432\n",
      "   macro avg       0.51      0.52      0.41       432\n",
      "weighted avg       0.83      0.51      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 31ms/step - loss: 0.7322 - accuracy: 0.5069\n",
      "Accuracy for this run is: 0.5069444179534912\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: vocabulary size is 21015\n",
      "Converted 15322 words (5693 misses)\n",
      "training set shape: (5070, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_30 (Embedding)    (None, None, 300)         6304500   \n",
      "                                                                 \n",
      " lstm_30 (LSTM)              (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,324,805\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 6,304,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 6s 28ms/step - loss: 0.6890 - accuracy: 0.5337\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.6682 - accuracy: 0.5862\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.6407 - accuracy: 0.6176\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.6011 - accuracy: 0.6702\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 5s 28ms/step - loss: 0.5588 - accuracy: 0.7051\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.5158 - accuracy: 0.7434\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.4702 - accuracy: 0.7753\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.4314 - accuracy: 0.7931\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 5s 30ms/step - loss: 0.4047 - accuracy: 0.8122\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 5s 31ms/step - loss: 0.3570 - accuracy: 0.8430\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      0.61      0.56       188\n",
      "        True       0.66      0.58      0.62       244\n",
      "\n",
      "    accuracy                           0.59       432\n",
      "   macro avg       0.59      0.59      0.59       432\n",
      "weighted avg       0.60      0.59      0.59       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 10ms/step - loss: 0.7842 - accuracy: 0.5926\n",
      "Accuracy for this run is: 0.5925925970077515\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=200\n",
      "Model 1: vocabulary size is 21015\n",
      "Converted 15322 words (5693 misses)\n",
      "training set shape: (5070, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_31 (Embedding)    (None, None, 300)         6304500   \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,324,805\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 6,304,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 12s 60ms/step - loss: 0.6912 - accuracy: 0.4978\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 9s 58ms/step - loss: 0.6765 - accuracy: 0.5456\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 9s 59ms/step - loss: 0.6585 - accuracy: 0.5663\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 9s 60ms/step - loss: 0.6367 - accuracy: 0.5880\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 9s 59ms/step - loss: 0.6139 - accuracy: 0.5911\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 10s 62ms/step - loss: 0.5918 - accuracy: 0.6260\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 10s 62ms/step - loss: 0.5685 - accuracy: 0.6418\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 10s 62ms/step - loss: 0.5412 - accuracy: 0.6787\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 11s 67ms/step - loss: 0.5156 - accuracy: 0.7105\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 10s 63ms/step - loss: 0.5030 - accuracy: 0.7256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.43      0.59      0.49       156\n",
      "        True       0.70      0.55      0.62       276\n",
      "\n",
      "    accuracy                           0.56       432\n",
      "   macro avg       0.56      0.57      0.56       432\n",
      "weighted avg       0.60      0.56      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 21ms/step - loss: 0.8015 - accuracy: 0.5648\n",
      "Accuracy for this run is: 0.5648148059844971\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=350\n",
      "Model 1: vocabulary size is 21015\n",
      "Converted 15322 words (5693 misses)\n",
      "training set shape: (5070, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_32 (Embedding)    (None, None, 300)         6304500   \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 16)                20288     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,324,805\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 6,304,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 19s 106ms/step - loss: 0.6803 - accuracy: 0.5361\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 17s 105ms/step - loss: 0.6763 - accuracy: 0.5404\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 17s 104ms/step - loss: 0.6737 - accuracy: 0.5391\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 16s 101ms/step - loss: 0.6700 - accuracy: 0.5410\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 16s 100ms/step - loss: 0.6674 - accuracy: 0.5440\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 17s 104ms/step - loss: 0.6636 - accuracy: 0.5450\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 16s 103ms/step - loss: 0.6609 - accuracy: 0.5471\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 17s 104ms/step - loss: 0.6576 - accuracy: 0.5471\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 16s 103ms/step - loss: 0.6547 - accuracy: 0.5424\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 17s 104ms/step - loss: 0.6510 - accuracy: 0.5383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.14      0.58      0.22        52\n",
      "        True       0.90      0.51      0.65       380\n",
      "\n",
      "    accuracy                           0.52       432\n",
      "   macro avg       0.52      0.54      0.44       432\n",
      "weighted avg       0.81      0.52      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 33ms/step - loss: 0.7319 - accuracy: 0.5185\n",
      "Accuracy for this run is: 0.5185185074806213\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=100\n",
      "Model 1: vocabulary size is 21015\n",
      "Converted 15322 words (5693 misses)\n",
      "training set shape: (5070, 100)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_33 (Embedding)    (None, None, 300)         6304500   \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,347,157\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 6,304,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 7s 30ms/step - loss: 0.6856 - accuracy: 0.5479\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.6589 - accuracy: 0.5941\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 5s 30ms/step - loss: 0.6207 - accuracy: 0.6446\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 5s 31ms/step - loss: 0.5719 - accuracy: 0.6897\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 5s 32ms/step - loss: 0.5157 - accuracy: 0.7497\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 5s 32ms/step - loss: 0.4570 - accuracy: 0.7809\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 5s 33ms/step - loss: 0.3982 - accuracy: 0.8144\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 5s 33ms/step - loss: 0.3574 - accuracy: 0.8373\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 5s 33ms/step - loss: 0.3333 - accuracy: 0.8465\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 5s 33ms/step - loss: 0.2727 - accuracy: 0.8830\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.57      0.63       262\n",
      "        True       0.48      0.61      0.54       170\n",
      "\n",
      "    accuracy                           0.59       432\n",
      "   macro avg       0.59      0.59      0.58       432\n",
      "weighted avg       0.61      0.59      0.59       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 12ms/step - loss: 0.8924 - accuracy: 0.5880\n",
      "Accuracy for this run is: 0.5879629850387573\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=200\n",
      "Model 1: vocabulary size is 21015\n",
      "Converted 15322 words (5693 misses)\n",
      "training set shape: (5070, 200)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_34 (Embedding)    (None, None, 300)         6304500   \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,347,157\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 6,304,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 12s 64ms/step - loss: 0.6900 - accuracy: 0.5174\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 10s 65ms/step - loss: 0.6725 - accuracy: 0.5501\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 0.6484 - accuracy: 0.5621\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 10s 65ms/step - loss: 0.6208 - accuracy: 0.5933\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 11s 67ms/step - loss: 0.5804 - accuracy: 0.6221\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 10s 65ms/step - loss: 0.5518 - accuracy: 0.6300\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 11s 66ms/step - loss: 0.5293 - accuracy: 0.6408\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 11s 68ms/step - loss: 0.5096 - accuracy: 0.6564\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 11s 66ms/step - loss: 0.4881 - accuracy: 0.6917\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 10s 66ms/step - loss: 0.4802 - accuracy: 0.7118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.54      0.61       278\n",
      "        True       0.41      0.58      0.48       154\n",
      "\n",
      "    accuracy                           0.56       432\n",
      "   macro avg       0.56      0.56      0.55       432\n",
      "weighted avg       0.60      0.56      0.56       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 23ms/step - loss: 0.9079 - accuracy: 0.5556\n",
      "Accuracy for this run is: 0.5555555820465088\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=350\n",
      "Model 1: vocabulary size is 21015\n",
      "Converted 15322 words (5693 misses)\n",
      "training set shape: (5070, 350)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_35 (Embedding)    (None, None, 300)         6304500   \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,347,157\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 6,304,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 20s 109ms/step - loss: 0.6797 - accuracy: 0.5286\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 17s 105ms/step - loss: 0.6753 - accuracy: 0.5373\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 17s 106ms/step - loss: 0.6694 - accuracy: 0.5396\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 17s 106ms/step - loss: 0.6668 - accuracy: 0.5377\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 17s 108ms/step - loss: 0.6627 - accuracy: 0.5460\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 18s 111ms/step - loss: 0.6597 - accuracy: 0.5345\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 18s 110ms/step - loss: 0.6543 - accuracy: 0.5434\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 18s 111ms/step - loss: 0.6565 - accuracy: 0.5546\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 17s 108ms/step - loss: 0.6490 - accuracy: 0.5430\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 17s 106ms/step - loss: 0.6486 - accuracy: 0.5394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.13      0.55      0.21        51\n",
      "        True       0.89      0.51      0.65       381\n",
      "\n",
      "    accuracy                           0.51       432\n",
      "   macro avg       0.51      0.53      0.43       432\n",
      "weighted avg       0.80      0.51      0.59       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.7313 - accuracy: 0.5116\n",
      "Accuracy for this run is: 0.5115740895271301\n",
      "!!!!!!!!!! Best result for data set 4 is 0.5925925970077515\n"
     ]
    }
   ],
   "source": [
    "# Grid search for evaluation\n",
    "for i in [1,2,3,4]:\n",
    "    print(f\"+++++++++++training on data set {i}+++++++++++++\")\n",
    "    X_train = eval(f'hotel_X_train_{i}')\n",
    "    y_train = eval(f'hotel_y_train_{i}')\n",
    "    best = 0\n",
    "    for num_units in [8, 16, 32, 64]:\n",
    "        for sequence_length in [100, 200, 350]:\n",
    "            for epochs in [10, 20]:\n",
    "                print('---------------------------------------------------------------------------')\n",
    "                print(f\"Start training with num_units={num_units} sequence_length={sequence_length}\")\n",
    "                acc = build_model_1(X_train, y_train, hotel_X_test, hotel_y_test, num_units, epochs, sequence_length)['accuracy']\n",
    "                print(f\"Accuracy for this run is: {acc}\")\n",
    "                best = max(best, acc)\n",
    "                \n",
    "    print(f\"!!!!!!!!!! Best result for data set {i} is {best}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Bidirectional LSTM + Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2(X_train, y_train, X_test, y_test, num_units, num_epochs, sequence_length):  \n",
    "    # For model 2, have to re-do the embedding again:\n",
    "    m2_vectorizer = TextVectorization(output_sequence_length=sequence_length)\n",
    "    m2_vectorizer.adapt(X_train['reviewContent'].to_numpy())\n",
    "    m2_voc = m2_vectorizer.get_vocabulary()\n",
    "    print(f\"Model 2: vocabulary size is {len(m2_voc)}\")\n",
    "\n",
    "    # Build + Lock in the Embedding layer from GloVe again\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    num_words = len(m2_voc)\n",
    "\n",
    "    # Prepare embedding matrix\n",
    "    m2_embedding_matrix = np.zeros((num_words, glove_dimension))\n",
    "    for i, word in enumerate(m2_voc):\n",
    "        embedding_vector = get_glove_embedding(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            # This includes the representation for \"padding\" and \"OOV\"\n",
    "            m2_embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "\n",
    "    m2_embedding_layer = Embedding(\n",
    "        num_words,\n",
    "        glove_dimension,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(m2_embedding_matrix),\n",
    "        trainable=False,\n",
    "    )\n",
    "\n",
    "    # Vectorize the input\n",
    "    X_train_ready = m2_vectorizer(X_train['reviewContent']).numpy()\n",
    "    X_test_ready = m2_vectorizer(X_test['reviewContent']).numpy()\n",
    "    print(f'training set shape: {X_train_ready.shape}')\n",
    "\n",
    "    # Build and train the model with \n",
    "    model = Sequential(name='model_2')\n",
    "    model.add(m2_embedding_layer)\n",
    "    model.add(Bidirectional(LSTM(num_units)))\n",
    "    model.add(Dense(num_units//2, activation='relu'))\n",
    "    model.add(Dense(num_units//4, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    model.fit(X_train_ready, y_train, epochs=num_epochs)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_predicted_test = model.predict(X_test_ready)\n",
    "    print(classification_report(y_predicted_test > 0.5, y_test))\n",
    "    print('Test set class distribution')\n",
    "    print(X_test['flagged'].value_counts() / len(X_test))\n",
    "    return model.evaluate(X_test_ready, y_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++training on data set 1+++++++++++++\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_72 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_36 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 9s 34ms/step - loss: 0.6679 - accuracy: 0.8646\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 0.6218 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 5s 35ms/step - loss: 0.5822 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 5s 36ms/step - loss: 0.5483 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 5s 36ms/step - loss: 0.5194 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 5s 35ms/step - loss: 0.4949 - accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 5s 36ms/step - loss: 0.4742 - accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 0.4567 - accuracy: 0.8763\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 0.4420 - accuracy: 0.8763\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 5s 32ms/step - loss: 0.4296 - accuracy: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 5s 14ms/step - loss: 0.8358 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_73 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_37 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 8s 35ms/step - loss: 0.4282 - accuracy: 0.8699\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 5s 36ms/step - loss: 0.3714 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 5s 35ms/step - loss: 0.3676 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 5s 35ms/step - loss: 0.3634 - accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 5s 36ms/step - loss: 0.3590 - accuracy: 0.8763\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 5s 35ms/step - loss: 0.3507 - accuracy: 0.8761\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 5s 35ms/step - loss: 0.3429 - accuracy: 0.8768\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 0.3328 - accuracy: 0.8779\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 0.3211 - accuracy: 0.8799\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 0.3089 - accuracy: 0.8823\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 0.2987 - accuracy: 0.8840\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 0.2869 - accuracy: 0.8869\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 0.2735 - accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 0.2601 - accuracy: 0.8926\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 0.2483 - accuracy: 0.8984\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 0.2332 - accuracy: 0.9034\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 0.2182 - accuracy: 0.9105\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 5s 36ms/step - loss: 0.2055 - accuracy: 0.9189\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 0.1901 - accuracy: 0.9242\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 0.1732 - accuracy: 0.9341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.53      0.67       380\n",
      "        True       0.17      0.71      0.28        52\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.62      0.48       432\n",
      "weighted avg       0.84      0.55      0.63       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 14ms/step - loss: 1.4175 - accuracy: 0.5509\n",
      "Accuracy for this run is: 0.5509259104728699\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_74 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_38 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 13s 64ms/step - loss: 0.6685 - accuracy: 0.8549\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 9s 64ms/step - loss: 0.6222 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 9s 64ms/step - loss: 0.5826 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 9s 64ms/step - loss: 0.5487 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 9s 66ms/step - loss: 0.5197 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 9s 66ms/step - loss: 0.4950 - accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 10s 67ms/step - loss: 0.4741 - accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 9s 66ms/step - loss: 0.4565 - accuracy: 0.8763\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 9s 66ms/step - loss: 0.4417 - accuracy: 0.8763\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 10s 68ms/step - loss: 0.4292 - accuracy: 0.8768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 28ms/step - loss: 0.8362 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_75 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_39 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 13s 68ms/step - loss: 0.6683 - accuracy: 0.8761\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 10s 69ms/step - loss: 0.6224 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 10s 71ms/step - loss: 0.5827 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 0.5488 - accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 0.5199 - accuracy: 0.8763\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 10s 74ms/step - loss: 0.4953 - accuracy: 0.8763\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 0.4744 - accuracy: 0.8763\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 10s 74ms/step - loss: 0.4568 - accuracy: 0.8763\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 11s 76ms/step - loss: 0.4420 - accuracy: 0.8763\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 11s 75ms/step - loss: 0.4296 - accuracy: 0.8763\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 11s 77ms/step - loss: 0.4193 - accuracy: 0.8763\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 0.4107 - accuracy: 0.8763\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 0.4036 - accuracy: 0.8763\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 10s 74ms/step - loss: 0.3977 - accuracy: 0.8763\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 11s 76ms/step - loss: 0.3928 - accuracy: 0.8763\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 11s 75ms/step - loss: 0.3888 - accuracy: 0.8763\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 11s 75ms/step - loss: 0.3857 - accuracy: 0.8763\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 11s 78ms/step - loss: 0.3831 - accuracy: 0.8763\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 11s 80ms/step - loss: 0.3810 - accuracy: 0.8763\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 11s 77ms/step - loss: 0.3794 - accuracy: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 30ms/step - loss: 1.0115 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_76 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_40 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 21s 122ms/step - loss: 0.6678 - accuracy: 0.8757\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 20s 138ms/step - loss: 0.6217 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 20s 140ms/step - loss: 0.5822 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 20s 138ms/step - loss: 0.5483 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 20s 138ms/step - loss: 0.5193 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 19s 134ms/step - loss: 0.4948 - accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 0.4740 - accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 20s 141ms/step - loss: 0.4565 - accuracy: 0.8763\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 20s 140ms/step - loss: 0.4417 - accuracy: 0.8763\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 20s 141ms/step - loss: 0.4294 - accuracy: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 56ms/step - loss: 0.8365 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_77 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_41 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 23s 132ms/step - loss: 0.6684 - accuracy: 0.8496\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 20s 137ms/step - loss: 0.6218 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 21s 145ms/step - loss: 0.5822 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 21s 149ms/step - loss: 0.5484 - accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 21s 151ms/step - loss: 0.5195 - accuracy: 0.8763\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 23s 160ms/step - loss: 0.4949 - accuracy: 0.8763\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 22s 155ms/step - loss: 0.4741 - accuracy: 0.8763\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 22s 152ms/step - loss: 0.4565 - accuracy: 0.8763\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 22s 151ms/step - loss: 0.4418 - accuracy: 0.8763\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 21s 146ms/step - loss: 0.4295 - accuracy: 0.8763\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 21s 147ms/step - loss: 0.4193 - accuracy: 0.8763\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 22s 153ms/step - loss: 0.4107 - accuracy: 0.8763\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 21s 151ms/step - loss: 0.4036 - accuracy: 0.8763\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 23s 163ms/step - loss: 0.3977 - accuracy: 0.8763\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 24s 170ms/step - loss: 0.3929 - accuracy: 0.8763\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 23s 163ms/step - loss: 0.3890 - accuracy: 0.8763\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 23s 163ms/step - loss: 0.3857 - accuracy: 0.8763\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 22s 156ms/step - loss: 0.3832 - accuracy: 0.8763\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 22s 154ms/step - loss: 0.3811 - accuracy: 0.8763\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 22s 156ms/step - loss: 0.3795 - accuracy: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 60ms/step - loss: 1.0100 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_78 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_42 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 11s 46ms/step - loss: 0.4018 - accuracy: 0.8752\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 0.3672 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 7s 46ms/step - loss: 0.3613 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 0.3510 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 7s 47ms/step - loss: 0.3390 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 7s 47ms/step - loss: 0.3266 - accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 7s 47ms/step - loss: 0.3081 - accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 7s 48ms/step - loss: 0.2878 - accuracy: 0.8858\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 7s 49ms/step - loss: 0.2641 - accuracy: 0.8929\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 7s 48ms/step - loss: 0.2411 - accuracy: 0.9048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.52      0.67       390\n",
      "        True       0.13      0.67      0.22        42\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.59      0.44       432\n",
      "weighted avg       0.86      0.53      0.62       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 18ms/step - loss: 1.0934 - accuracy: 0.5324\n",
      "Accuracy for this run is: 0.5324074029922485\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_79 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_43 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 11s 46ms/step - loss: 0.4060 - accuracy: 0.8726\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 7s 46ms/step - loss: 0.3659 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 7s 47ms/step - loss: 0.3595 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 7s 46ms/step - loss: 0.3496 - accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 7s 47ms/step - loss: 0.3347 - accuracy: 0.8763\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 7s 46ms/step - loss: 0.3124 - accuracy: 0.8774\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 7s 48ms/step - loss: 0.2929 - accuracy: 0.8845\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 7s 48ms/step - loss: 0.2656 - accuracy: 0.8975\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 7s 48ms/step - loss: 0.2385 - accuracy: 0.9076\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 7s 48ms/step - loss: 0.2092 - accuracy: 0.9213\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 7s 49ms/step - loss: 0.1759 - accuracy: 0.9372\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 7s 50ms/step - loss: 0.1460 - accuracy: 0.9484\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 7s 51ms/step - loss: 0.1173 - accuracy: 0.9632\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 7s 49ms/step - loss: 0.0927 - accuracy: 0.9720\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 8s 59ms/step - loss: 0.0740 - accuracy: 0.9788\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 8s 53ms/step - loss: 0.0545 - accuracy: 0.9850\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 7s 52ms/step - loss: 0.0399 - accuracy: 0.9910\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 7s 51ms/step - loss: 0.0323 - accuracy: 0.9932\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 7s 52ms/step - loss: 0.0260 - accuracy: 0.9936\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 8s 55ms/step - loss: 0.0237 - accuracy: 0.9943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.53      0.67       373\n",
      "        True       0.19      0.69      0.30        59\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.61      0.49       432\n",
      "weighted avg       0.82      0.55      0.62       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 19ms/step - loss: 2.7402 - accuracy: 0.5532\n",
      "Accuracy for this run is: 0.5532407164573669\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_80 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_44 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 18s 91ms/step - loss: 0.6683 - accuracy: 0.8534\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 13s 91ms/step - loss: 0.6218 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 13s 90ms/step - loss: 0.5822 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 13s 91ms/step - loss: 0.5483 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 14s 96ms/step - loss: 0.5193 - accuracy: 0.8765\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 14s 99ms/step - loss: 0.4946 - accuracy: 0.8765\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 14s 97ms/step - loss: 0.4737 - accuracy: 0.8765\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 14s 96ms/step - loss: 0.4562 - accuracy: 0.87650s - loss: 0.458\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 14s 97ms/step - loss: 0.4414 - accuracy: 0.8765\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 14s 95ms/step - loss: 0.4291 - accuracy: 0.8765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhang/Documents/MIDS/W266/w266-final-project/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       432\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.25      0.33       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 39ms/step - loss: 0.8368 - accuracy: 0.5000\n",
      "Accuracy for this run is: 0.5\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_81 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_45 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 17s 91ms/step - loss: 0.4489 - accuracy: 0.8743\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 13s 90ms/step - loss: 0.3738 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 13s 92ms/step - loss: 0.3719 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 13s 93ms/step - loss: 0.3694 - accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 14s 101ms/step - loss: 0.3657 - accuracy: 0.8763\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 16s 114ms/step - loss: 0.3570 - accuracy: 0.8765\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 13s 95ms/step - loss: 0.3451 - accuracy: 0.8779\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 13s 93ms/step - loss: 0.3238 - accuracy: 0.8814\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 13s 90ms/step - loss: 0.3119 - accuracy: 0.8836\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 12s 85ms/step - loss: 0.3012 - accuracy: 0.8891\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 12s 83ms/step - loss: 0.2884 - accuracy: 0.8926\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 12s 82ms/step - loss: 0.2704 - accuracy: 0.9012\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 12s 83ms/step - loss: 0.2557 - accuracy: 0.9063\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 11s 80ms/step - loss: 0.2378 - accuracy: 0.9125\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 11s 81ms/step - loss: 0.2232 - accuracy: 0.9184\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 13s 88ms/step - loss: 0.2136 - accuracy: 0.9261\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 14s 101ms/step - loss: 0.1947 - accuracy: 0.9381\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 14s 96ms/step - loss: 0.1789 - accuracy: 0.9398\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 13s 91ms/step - loss: 0.1649 - accuracy: 0.9478\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 13s 90ms/step - loss: 0.1462 - accuracy: 0.9546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.52      0.66       385\n",
      "        True       0.14      0.64      0.23        47\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.58      0.45       432\n",
      "weighted avg       0.84      0.53      0.62       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 36ms/step - loss: 1.4939 - accuracy: 0.5301\n",
      "Accuracy for this run is: 0.5300925970077515\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_82 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_46 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 24s 140ms/step - loss: 0.4192 - accuracy: 0.8757\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 20s 138ms/step - loss: 0.3733 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 21s 145ms/step - loss: 0.3694 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 21s 145ms/step - loss: 0.3645 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 21s 147ms/step - loss: 0.3539 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 21s 148ms/step - loss: 0.3414 - accuracy: 0.8763\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 22s 154ms/step - loss: 0.3298 - accuracy: 0.8768\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 22s 153ms/step - loss: 0.3184 - accuracy: 0.8785\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 22s 156ms/step - loss: 0.3040 - accuracy: 0.8818\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 21s 150ms/step - loss: 0.2866 - accuracy: 0.8873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67       430\n",
      "        True       0.01      1.00      0.02         2\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.50      0.75      0.34       432\n",
      "weighted avg       1.00      0.50      0.67       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 58ms/step - loss: 0.9961 - accuracy: 0.5046\n",
      "Accuracy for this run is: 0.5046296119689941\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_83 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_47 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 23s 130ms/step - loss: 0.3973 - accuracy: 0.8743\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 20s 138ms/step - loss: 0.3680 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 20s 141ms/step - loss: 0.3607 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 23s 163ms/step - loss: 0.3489 - accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 25s 178ms/step - loss: 0.3352 - accuracy: 0.8770\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 22s 157ms/step - loss: 0.3182 - accuracy: 0.8792\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 26s 185ms/step - loss: 0.3047 - accuracy: 0.8814\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 25s 173ms/step - loss: 0.2882 - accuracy: 0.8902\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 24s 170ms/step - loss: 0.2690 - accuracy: 0.8962\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 23s 159ms/step - loss: 0.2506 - accuracy: 0.9050\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 22s 157ms/step - loss: 0.2316 - accuracy: 0.9118\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 24s 172ms/step - loss: 0.2128 - accuracy: 0.9187\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 24s 171ms/step - loss: 0.1932 - accuracy: 0.9220\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 25s 173ms/step - loss: 0.1710 - accuracy: 0.9336\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 24s 167ms/step - loss: 0.1563 - accuracy: 0.9389\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 0.1342 - accuracy: 0.9480\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 23s 159ms/step - loss: 0.1140 - accuracy: 0.9575\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 22s 155ms/step - loss: 0.1080 - accuracy: 0.9579\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 22s 157ms/step - loss: 0.0849 - accuracy: 0.9724\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 23s 165ms/step - loss: 0.0699 - accuracy: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.52      0.66       367\n",
      "        True       0.19      0.63      0.29        65\n",
      "\n",
      "    accuracy                           0.54       432\n",
      "   macro avg       0.54      0.58      0.48       432\n",
      "weighted avg       0.78      0.54      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 68ms/step - loss: 2.1031 - accuracy: 0.5394\n",
      "Accuracy for this run is: 0.5393518805503845\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_84 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_48 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 12s 51ms/step - loss: 0.3946 - accuracy: 0.8622\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 7s 49ms/step - loss: 0.3660 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 7s 49ms/step - loss: 0.3594 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 7s 52ms/step - loss: 0.3486 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 7s 52ms/step - loss: 0.3349 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 8s 55ms/step - loss: 0.3124 - accuracy: 0.8774\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 8s 59ms/step - loss: 0.2820 - accuracy: 0.8862\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.2438 - accuracy: 0.9050\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 9s 64ms/step - loss: 0.1961 - accuracy: 0.9235\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 9s 67ms/step - loss: 0.1494 - accuracy: 0.9436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.54      0.67       365\n",
      "        True       0.22      0.70      0.33        67\n",
      "\n",
      "    accuracy                           0.56       432\n",
      "   macro avg       0.56      0.62      0.50       432\n",
      "weighted avg       0.80      0.56      0.62       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 22ms/step - loss: 1.4505 - accuracy: 0.5625\n",
      "Accuracy for this run is: 0.5625\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_85 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_49 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 13s 61ms/step - loss: 0.3836 - accuracy: 0.8735\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 8s 58ms/step - loss: 0.3634 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 8s 59ms/step - loss: 0.3495 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.3319 - accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 8s 58ms/step - loss: 0.3058 - accuracy: 0.8790\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 9s 67ms/step - loss: 0.2749 - accuracy: 0.8920\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 9s 67ms/step - loss: 0.2335 - accuracy: 0.9085\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 9s 66ms/step - loss: 0.1726 - accuracy: 0.9295\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 10s 67ms/step - loss: 0.1210 - accuracy: 0.9539\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 10s 71ms/step - loss: 0.0806 - accuracy: 0.9718\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 10s 70ms/step - loss: 0.0531 - accuracy: 0.9826\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 10s 69ms/step - loss: 0.0319 - accuracy: 0.9925\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 10s 70ms/step - loss: 0.0208 - accuracy: 0.99470s - loss: 0.0206 - accuracy: \n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 10s 70ms/step - loss: 0.0161 - accuracy: 0.9960\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 10s 70ms/step - loss: 0.0271 - accuracy: 0.9910\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 10s 67ms/step - loss: 0.0166 - accuracy: 0.9951\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 10s 69ms/step - loss: 0.0129 - accuracy: 0.9963\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 10s 68ms/step - loss: 0.0064 - accuracy: 0.9991\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 10s 67ms/step - loss: 0.0058 - accuracy: 0.9991\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 9s 65ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.52      0.66       363\n",
      "        True       0.20      0.62      0.30        69\n",
      "\n",
      "    accuracy                           0.54       432\n",
      "   macro avg       0.54      0.57      0.48       432\n",
      "weighted avg       0.77      0.54      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 20ms/step - loss: 3.8362 - accuracy: 0.5394\n",
      "Accuracy for this run is: 0.5393518805503845\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_86 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_50 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 17s 87ms/step - loss: 0.4038 - accuracy: 0.8715\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 12s 87ms/step - loss: 0.3693 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 14s 96ms/step - loss: 0.3645 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 13s 92ms/step - loss: 0.3566 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 14s 96ms/step - loss: 0.3429 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 13s 95ms/step - loss: 0.3238 - accuracy: 0.8785\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 13s 94ms/step - loss: 0.2987 - accuracy: 0.8856\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 13s 95ms/step - loss: 0.2753 - accuracy: 0.8962\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 14s 96ms/step - loss: 0.2394 - accuracy: 0.9109\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 13s 93ms/step - loss: 0.2018 - accuracy: 0.9217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.52      0.67       397\n",
      "        True       0.12      0.71      0.20        35\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.62      0.44       432\n",
      "weighted avg       0.89      0.53      0.63       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 37ms/step - loss: 1.4434 - accuracy: 0.5347\n",
      "Accuracy for this run is: 0.5347222089767456\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_87 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_51 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 17s 90ms/step - loss: 0.3826 - accuracy: 0.8763\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 13s 91ms/step - loss: 0.3650 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 14s 97ms/step - loss: 0.3533 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 16s 112ms/step - loss: 0.3372 - accuracy: 0.8765\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 15s 106ms/step - loss: 0.3150 - accuracy: 0.8807\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 17s 121ms/step - loss: 0.2828 - accuracy: 0.8926\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 16s 114ms/step - loss: 0.2508 - accuracy: 0.9017\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 16s 113ms/step - loss: 0.2098 - accuracy: 0.9171\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 15s 103ms/step - loss: 0.1741 - accuracy: 0.9314\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 14s 97ms/step - loss: 0.1482 - accuracy: 0.9436\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 15s 104ms/step - loss: 0.1194 - accuracy: 0.9546\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 15s 102ms/step - loss: 0.1030 - accuracy: 0.9616\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 13s 95ms/step - loss: 0.0718 - accuracy: 0.9744\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 13s 92ms/step - loss: 0.0559 - accuracy: 0.9810\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 13s 93ms/step - loss: 0.0400 - accuracy: 0.9870\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 13s 92ms/step - loss: 0.0251 - accuracy: 0.9929\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 15s 105ms/step - loss: 0.0521 - accuracy: 0.9848\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 14s 100ms/step - loss: 0.0295 - accuracy: 0.9923\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 14s 97ms/step - loss: 0.0136 - accuracy: 0.9971\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 14s 101ms/step - loss: 0.0043 - accuracy: 0.9989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.53      0.66       358\n",
      "        True       0.22      0.64      0.32        74\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.58      0.49       432\n",
      "weighted avg       0.76      0.55      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 39ms/step - loss: 4.3400 - accuracy: 0.5463\n",
      "Accuracy for this run is: 0.5462962985038757\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_88 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_52 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 24s 142ms/step - loss: 0.3890 - accuracy: 0.8763\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 25s 177ms/step - loss: 0.3691 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 26s 184ms/step - loss: 0.3597 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 25s 177ms/step - loss: 0.3436 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 26s 182ms/step - loss: 0.3261 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 26s 181ms/step - loss: 0.3051 - accuracy: 0.8776\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 27s 190ms/step - loss: 0.2855 - accuracy: 0.8884\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 29s 206ms/step - loss: 0.2657 - accuracy: 0.8944\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 30s 208ms/step - loss: 0.2397 - accuracy: 0.9050\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 31s 219ms/step - loss: 0.2148 - accuracy: 0.9142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.51      0.68       412\n",
      "        True       0.07      0.80      0.14        20\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.66      0.41       432\n",
      "weighted avg       0.94      0.53      0.65       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 68ms/step - loss: 1.3579 - accuracy: 0.5278\n",
      "Accuracy for this run is: 0.5277777910232544\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_89 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_53 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 26s 152ms/step - loss: 0.3802 - accuracy: 0.8763\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 22s 158ms/step - loss: 0.3666 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 26s 185ms/step - loss: 0.3590 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 28s 194ms/step - loss: 0.3452 - accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 28s 198ms/step - loss: 0.3280 - accuracy: 0.8801\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 26s 184ms/step - loss: 0.3119 - accuracy: 0.8845\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 25s 173ms/step - loss: 0.2888 - accuracy: 0.8911\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 25s 178ms/step - loss: 0.2656 - accuracy: 0.8979\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 26s 180ms/step - loss: 0.2452 - accuracy: 0.9052\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 27s 189ms/step - loss: 0.2109 - accuracy: 0.9175\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 31s 215ms/step - loss: 0.1975 - accuracy: 0.9217\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 28s 199ms/step - loss: 0.1527 - accuracy: 0.9431\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 27s 186ms/step - loss: 0.1277 - accuracy: 0.9511\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 25s 179ms/step - loss: 0.0985 - accuracy: 0.9616\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 25s 174ms/step - loss: 0.0730 - accuracy: 0.9744\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 25s 179ms/step - loss: 0.0544 - accuracy: 0.9797\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 28s 198ms/step - loss: 0.0425 - accuracy: 0.9870\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 28s 194ms/step - loss: 0.0266 - accuracy: 0.9910\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 27s 191ms/step - loss: 0.0228 - accuracy: 0.9927\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 24s 168ms/step - loss: 0.0177 - accuracy: 0.9949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.53      0.66       363\n",
      "        True       0.21      0.65      0.32        69\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.59      0.49       432\n",
      "weighted avg       0.78      0.55      0.61       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 64ms/step - loss: 4.0219 - accuracy: 0.5486\n",
      "Accuracy for this run is: 0.5486111044883728\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_90 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_54 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,900,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 13s 60ms/step - loss: 0.3931 - accuracy: 0.8607\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 9s 63ms/step - loss: 0.3640 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 9s 66ms/step - loss: 0.3545 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 10s 68ms/step - loss: 0.3399 - accuracy: 0.8763\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 10s 72ms/step - loss: 0.3156 - accuracy: 0.8785\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 10s 72ms/step - loss: 0.2757 - accuracy: 0.8924\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 11s 81ms/step - loss: 0.2232 - accuracy: 0.9162\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 11s 77ms/step - loss: 0.1685 - accuracy: 0.9361\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 11s 77ms/step - loss: 0.1133 - accuracy: 0.9541\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 11s 76ms/step - loss: 0.0824 - accuracy: 0.9669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.52      0.66       384\n",
      "        True       0.14      0.65      0.23        48\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.58      0.45       432\n",
      "weighted avg       0.83      0.53      0.62       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 33ms/step - loss: 2.0241 - accuracy: 0.5324\n",
      "Accuracy for this run is: 0.5324074029922485\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_91 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_55 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,900,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 14s 69ms/step - loss: 0.3772 - accuracy: 0.8763\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 10s 71ms/step - loss: 0.3618 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 10s 69ms/step - loss: 0.3484 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 10s 69ms/step - loss: 0.3259 - accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 10s 72ms/step - loss: 0.2940 - accuracy: 0.8821\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 0.2396 - accuracy: 0.9072\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 11s 75ms/step - loss: 0.1752 - accuracy: 0.9292\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 11s 75ms/step - loss: 0.1174 - accuracy: 0.9550\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 11s 76ms/step - loss: 0.0821 - accuracy: 0.9674\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 11s 77ms/step - loss: 0.0515 - accuracy: 0.9810\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 11s 76ms/step - loss: 0.0357 - accuracy: 0.9863\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 11s 76ms/step - loss: 0.0282 - accuracy: 0.9905\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 11s 76ms/step - loss: 0.0192 - accuracy: 0.9936\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 10s 71ms/step - loss: 0.0429 - accuracy: 0.9826\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 10s 71ms/step - loss: 0.0171 - accuracy: 0.9954\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 0.0054 - accuracy: 0.9991\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 10s 72ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 10s 71ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 10s 72ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 10s 71ms/step - loss: 6.5822e-04 - accuracy: 0.9998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.52      0.66       383\n",
      "        True       0.15      0.65      0.24        49\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.59      0.45       432\n",
      "weighted avg       0.83      0.53      0.62       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 32ms/step - loss: 4.5591 - accuracy: 0.5347\n",
      "Accuracy for this run is: 0.5347222089767456\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_92 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_56 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,900,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 22s 126ms/step - loss: 0.3944 - accuracy: 0.8627\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 18s 130ms/step - loss: 0.3674 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 19s 136ms/step - loss: 0.3577 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 20s 144ms/step - loss: 0.3478 - accuracy: 0.8761\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 21s 146ms/step - loss: 0.3283 - accuracy: 0.8785\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 21s 146ms/step - loss: 0.3003 - accuracy: 0.8904\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 20s 142ms/step - loss: 0.2594 - accuracy: 0.8986\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 20s 139ms/step - loss: 0.2127 - accuracy: 0.9151\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 20s 141ms/step - loss: 0.1701 - accuracy: 0.9303\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 21s 151ms/step - loss: 0.1243 - accuracy: 0.9466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.52      0.66       383\n",
      "        True       0.15      0.65      0.24        49\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.59      0.45       432\n",
      "weighted avg       0.83      0.53      0.62       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 69ms/step - loss: 1.7312 - accuracy: 0.5347\n",
      "Accuracy for this run is: 0.5347222089767456\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_93 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_57 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,900,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 26s 143ms/step - loss: 0.3808 - accuracy: 0.8763\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 22s 152ms/step - loss: 0.3655 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 23s 159ms/step - loss: 0.3557 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 24s 166ms/step - loss: 0.3353 - accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 24s 170ms/step - loss: 0.3127 - accuracy: 0.8785\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 23s 164ms/step - loss: 0.2823 - accuracy: 0.8860\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 23s 160ms/step - loss: 0.2369 - accuracy: 0.9045\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 0.1888 - accuracy: 0.9224\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 23s 159ms/step - loss: 0.1514 - accuracy: 0.9405\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 23s 160ms/step - loss: 0.1006 - accuracy: 0.9605\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 23s 159ms/step - loss: 0.0742 - accuracy: 0.9711\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 23s 159ms/step - loss: 0.0456 - accuracy: 0.9843\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 0.0501 - accuracy: 0.9817\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 23s 160ms/step - loss: 0.0238 - accuracy: 0.9932\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 23s 160ms/step - loss: 0.0185 - accuracy: 0.9951\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 23s 160ms/step - loss: 0.0132 - accuracy: 0.9958\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 0.0078 - accuracy: 0.9982\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 0.0040 - accuracy: 0.9991\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 23s 160ms/step - loss: 0.0220 - accuracy: 0.9927\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 23s 163ms/step - loss: 0.0221 - accuracy: 0.9914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.51      0.65       378\n",
      "        True       0.14      0.56      0.22        54\n",
      "\n",
      "    accuracy                           0.51       432\n",
      "   macro avg       0.51      0.53      0.43       432\n",
      "weighted avg       0.80      0.51      0.59       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 72ms/step - loss: 4.4183 - accuracy: 0.5139\n",
      "Accuracy for this run is: 0.5138888955116272\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_94 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_58 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,900,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 40s 251ms/step - loss: 0.3881 - accuracy: 0.8746\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 37s 260ms/step - loss: 0.3700 - accuracy: 0.8763\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 37s 263ms/step - loss: 0.3622 - accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 39s 274ms/step - loss: 0.3495 - accuracy: 0.8768\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 38s 267ms/step - loss: 0.3308 - accuracy: 0.8814\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 38s 265ms/step - loss: 0.3077 - accuracy: 0.8854\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 38s 264ms/step - loss: 0.2877 - accuracy: 0.8907\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 37s 257ms/step - loss: 0.2582 - accuracy: 0.9043\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 36s 252ms/step - loss: 0.2212 - accuracy: 0.9156\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 38s 265ms/step - loss: 0.1921 - accuracy: 0.9292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.50      0.65       397\n",
      "        True       0.09      0.54      0.15        35\n",
      "\n",
      "    accuracy                           0.51       432\n",
      "   macro avg       0.51      0.52      0.40       432\n",
      "weighted avg       0.86      0.51      0.61       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 3s 113ms/step - loss: 1.3557 - accuracy: 0.5069\n",
      "Accuracy for this run is: 0.5069444179534912\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (4536, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_95 (Embedding)    (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_59 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,900,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 37s 228ms/step - loss: 0.3880 - accuracy: 0.8739\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 36s 255ms/step - loss: 0.3689 - accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 37s 261ms/step - loss: 0.3645 - accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 37s 260ms/step - loss: 0.3516 - accuracy: 0.8774\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 36s 252ms/step - loss: 0.3386 - accuracy: 0.8807\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 35s 246ms/step - loss: 0.3159 - accuracy: 0.8843\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 36s 256ms/step - loss: 0.2953 - accuracy: 0.8896\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 37s 261ms/step - loss: 0.2653 - accuracy: 0.9010\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 37s 262ms/step - loss: 0.2397 - accuracy: 0.9120\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 36s 253ms/step - loss: 0.2066 - accuracy: 0.9248\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 37s 263ms/step - loss: 0.1761 - accuracy: 0.9323\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 36s 256ms/step - loss: 0.1343 - accuracy: 0.9504\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 35s 248ms/step - loss: 0.1039 - accuracy: 0.9610\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 37s 261ms/step - loss: 0.0696 - accuracy: 0.9751\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 36s 254ms/step - loss: 0.0501 - accuracy: 0.9815\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 35s 249ms/step - loss: 0.0427 - accuracy: 0.9843\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 37s 259ms/step - loss: 0.0454 - accuracy: 0.9868\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 38s 268ms/step - loss: 0.0188 - accuracy: 0.9934\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 36s 251ms/step - loss: 0.0130 - accuracy: 0.9974\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 35s 248ms/step - loss: 0.0039 - accuracy: 0.9991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.52      0.66       366\n",
      "        True       0.19      0.64      0.30        66\n",
      "\n",
      "    accuracy                           0.54       432\n",
      "   macro avg       0.54      0.58      0.48       432\n",
      "weighted avg       0.78      0.54      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 3s 113ms/step - loss: 3.7358 - accuracy: 0.5417\n",
      "Accuracy for this run is: 0.5416666865348816\n",
      "!!!!!!!!!! Best result for data set 1 is 0.5625\n",
      "+++++++++++training on data set 2+++++++++++++\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=100\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_96 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_60 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,213,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 7s 45ms/step - loss: 0.6914 - accuracy: 0.5196\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.6858 - accuracy: 0.5677\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.6797 - accuracy: 0.5802\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.6715 - accuracy: 0.6123\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 0.6627 - accuracy: 0.6328\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 0.6470 - accuracy: 0.6747\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.6220 - accuracy: 0.6996\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 0.6016 - accuracy: 0.6872\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.5630 - accuracy: 0.7406\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 0.5255 - accuracy: 0.7701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.44      0.58      0.50       163\n",
      "        True       0.69      0.55      0.61       269\n",
      "\n",
      "    accuracy                           0.56       432\n",
      "   macro avg       0.56      0.57      0.56       432\n",
      "weighted avg       0.59      0.56      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 15ms/step - loss: 0.7259 - accuracy: 0.5625\n",
      "Accuracy for this run is: 0.5625\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=100\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_97 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_61 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,213,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 5s 37ms/step - loss: 0.6909 - accuracy: 0.5125\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.6829 - accuracy: 0.5713\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.6727 - accuracy: 0.6034\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.6634 - accuracy: 0.6266\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.6505 - accuracy: 0.6390\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.6343 - accuracy: 0.6640\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.6149 - accuracy: 0.7032\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.6060 - accuracy: 0.7032\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.6063 - accuracy: 0.7210\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.5711 - accuracy: 0.7522\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.5486 - accuracy: 0.7629\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.5189 - accuracy: 0.8039\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 38ms/step - loss: 0.4939 - accuracy: 0.8137\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.4766 - accuracy: 0.8342\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.4665 - accuracy: 0.8235\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.4310 - accuracy: 0.8725\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.4084 - accuracy: 0.8913\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.3990 - accuracy: 0.8877\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.3690 - accuracy: 0.9082\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.3560 - accuracy: 0.9091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.57      0.59       231\n",
      "        True       0.54      0.58      0.56       201\n",
      "\n",
      "    accuracy                           0.57       432\n",
      "   macro avg       0.57      0.57      0.57       432\n",
      "weighted avg       0.57      0.57      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 16ms/step - loss: 0.9084 - accuracy: 0.5718\n",
      "Accuracy for this run is: 0.5717592835426331\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=200\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_98 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_62 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,213,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 6s 74ms/step - loss: 0.6926 - accuracy: 0.5160\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 0.6899 - accuracy: 0.5267\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.6878 - accuracy: 0.5446\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 0.6799 - accuracy: 0.5695\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 3s 72ms/step - loss: 0.6663 - accuracy: 0.5856\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.6511 - accuracy: 0.6123\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.6341 - accuracy: 0.6346\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.6028 - accuracy: 0.6613\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.5795 - accuracy: 0.6898\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.5646 - accuracy: 0.6872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.41      0.51      0.45       173\n",
      "        True       0.61      0.51      0.55       259\n",
      "\n",
      "    accuracy                           0.51       432\n",
      "   macro avg       0.51      0.51      0.50       432\n",
      "weighted avg       0.53      0.51      0.51       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 31ms/step - loss: 0.7745 - accuracy: 0.5069\n",
      "Accuracy for this run is: 0.5069444179534912\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=200\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_99 (Embedding)    (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_63 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,213,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 7s 73ms/step - loss: 0.6934 - accuracy: 0.4991\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.6895 - accuracy: 0.5428\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.6862 - accuracy: 0.5553\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.6816 - accuracy: 0.5633\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.6738 - accuracy: 0.6096\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.6653 - accuracy: 0.5900\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 3s 77ms/step - loss: 0.6544 - accuracy: 0.6693\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.6425 - accuracy: 0.6569\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.6286 - accuracy: 0.6952\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.6156 - accuracy: 0.6836\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.5925 - accuracy: 0.7291\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.5723 - accuracy: 0.7513\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.5572 - accuracy: 0.7460\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.5322 - accuracy: 0.8004\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.5155 - accuracy: 0.8066\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.4865 - accuracy: 0.8262\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.4589 - accuracy: 0.8431\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.4383 - accuracy: 0.8583\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.4177 - accuracy: 0.8699\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.3944 - accuracy: 0.8930\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.48      0.52      0.50       197\n",
      "        True       0.56      0.52      0.54       235\n",
      "\n",
      "    accuracy                           0.52       432\n",
      "   macro avg       0.52      0.52      0.52       432\n",
      "weighted avg       0.52      0.52      0.52       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 31ms/step - loss: 0.8854 - accuracy: 0.5208\n",
      "Accuracy for this run is: 0.5208333134651184\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_100 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_64 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,213,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 9s 138ms/step - loss: 0.6930 - accuracy: 0.5116\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.6930 - accuracy: 0.5312\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 5s 139ms/step - loss: 0.6856 - accuracy: 0.5704\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.6816 - accuracy: 0.5909\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 5s 139ms/step - loss: 0.6735 - accuracy: 0.5900\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.6674 - accuracy: 0.6105\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.6502 - accuracy: 0.6569\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.6394 - accuracy: 0.6729\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.6205 - accuracy: 0.6809\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.5911 - accuracy: 0.7094\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.57      0.56       214\n",
      "        True       0.57      0.56      0.57       218\n",
      "\n",
      "    accuracy                           0.56       432\n",
      "   macro avg       0.56      0.56      0.56       432\n",
      "weighted avg       0.56      0.56      0.56       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 54ms/step - loss: 0.7039 - accuracy: 0.5648\n",
      "Accuracy for this run is: 0.5648148059844971\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=350\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_101 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_65 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,213,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 8s 125ms/step - loss: 0.6939 - accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.6899 - accuracy: 0.5089\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 5s 128ms/step - loss: 0.6867 - accuracy: 0.5250\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 5s 129ms/step - loss: 0.6822 - accuracy: 0.5303\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 5s 132ms/step - loss: 0.6765 - accuracy: 0.5499\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.6692 - accuracy: 0.5588\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 5s 139ms/step - loss: 0.6597 - accuracy: 0.5713\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.6527 - accuracy: 0.5873\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.6648 - accuracy: 0.5561\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.6498 - accuracy: 0.5856\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.6351 - accuracy: 0.6052\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.6215 - accuracy: 0.6194\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.6066 - accuracy: 0.6310\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.6004 - accuracy: 0.6462\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.5832 - accuracy: 0.6533\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.5631 - accuracy: 0.6845\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.5445 - accuracy: 0.6988\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.5271 - accuracy: 0.6979\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.5004 - accuracy: 0.7246\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.4873 - accuracy: 0.7344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.47      0.57      0.52       180\n",
      "        True       0.64      0.55      0.59       252\n",
      "\n",
      "    accuracy                           0.56       432\n",
      "   macro avg       0.56      0.56      0.55       432\n",
      "weighted avg       0.57      0.56      0.56       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 58ms/step - loss: 0.7868 - accuracy: 0.5556\n",
      "Accuracy for this run is: 0.5555555820465088\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=100\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_102 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_66 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,234,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 6s 39ms/step - loss: 0.6968 - accuracy: 0.5071\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.6805 - accuracy: 0.5775\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.6698 - accuracy: 0.5954\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.6547 - accuracy: 0.6212\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.6364 - accuracy: 0.6578\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.6011 - accuracy: 0.6970\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.5715 - accuracy: 0.7273\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.5257 - accuracy: 0.7611\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.4848 - accuracy: 0.7888\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.4341 - accuracy: 0.8235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.44      0.65      0.52       145\n",
      "        True       0.76      0.57      0.66       287\n",
      "\n",
      "    accuracy                           0.60       432\n",
      "   macro avg       0.60      0.61      0.59       432\n",
      "weighted avg       0.65      0.60      0.61       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 16ms/step - loss: 0.8143 - accuracy: 0.5995\n",
      "Accuracy for this run is: 0.5995370149612427\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=100\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_103 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_67 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,234,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 5s 39ms/step - loss: 0.6901 - accuracy: 0.5437\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 0.6890 - accuracy: 0.5294\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 0.6807 - accuracy: 0.6061\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 0.6691 - accuracy: 0.6025\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 0.6527 - accuracy: 0.6462\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 0.6310 - accuracy: 0.6640\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 0.5973 - accuracy: 0.7068\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 0.5740 - accuracy: 0.7148\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.5368 - accuracy: 0.7558\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.4924 - accuracy: 0.7906\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.4372 - accuracy: 0.8146\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.4023 - accuracy: 0.8405\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.3334 - accuracy: 0.8841\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.2617 - accuracy: 0.9171\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.2328 - accuracy: 0.9269\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 1s 42ms/step - loss: 0.1945 - accuracy: 0.9501\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.1712 - accuracy: 0.9483\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.1137 - accuracy: 0.9813\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.0818 - accuracy: 0.9875\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.0615 - accuracy: 0.9929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.58      0.57       208\n",
      "        True       0.59      0.57      0.58       224\n",
      "\n",
      "    accuracy                           0.57       432\n",
      "   macro avg       0.57      0.57      0.57       432\n",
      "weighted avg       0.57      0.57      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 16ms/step - loss: 1.3434 - accuracy: 0.5741\n",
      "Accuracy for this run is: 0.5740740895271301\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=200\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_104 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_68 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,234,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 7s 77ms/step - loss: 0.6930 - accuracy: 0.5116\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.6851 - accuracy: 0.5570\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.6790 - accuracy: 0.5838\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 3s 77ms/step - loss: 0.6717 - accuracy: 0.5971\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.6606 - accuracy: 0.6542\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.6591 - accuracy: 0.6578\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.6480 - accuracy: 0.6684\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.6233 - accuracy: 0.7068\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.6138 - accuracy: 0.7184\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.5833 - accuracy: 0.7451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.39      0.63      0.49       134\n",
      "        True       0.77      0.56      0.65       298\n",
      "\n",
      "    accuracy                           0.58       432\n",
      "   macro avg       0.58      0.60      0.57       432\n",
      "weighted avg       0.66      0.58      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 34ms/step - loss: 0.7636 - accuracy: 0.5833\n",
      "Accuracy for this run is: 0.5833333134651184\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=200\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_105 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_69 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,234,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 7s 78ms/step - loss: 0.6927 - accuracy: 0.5116\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.6866 - accuracy: 0.5766\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.6792 - accuracy: 0.5695\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.6723 - accuracy: 0.6105\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 77ms/step - loss: 0.6628 - accuracy: 0.6292\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 77ms/step - loss: 0.6505 - accuracy: 0.6417\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 3s 77ms/step - loss: 0.6343 - accuracy: 0.6569\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.6171 - accuracy: 0.7014\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.5991 - accuracy: 0.7201\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.5736 - accuracy: 0.7531\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.5563 - accuracy: 0.7674\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.5256 - accuracy: 0.7879\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 82ms/step - loss: 0.5280 - accuracy: 0.7941\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 82ms/step - loss: 0.5013 - accuracy: 0.8182\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.4601 - accuracy: 0.8467\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.4339 - accuracy: 0.8725\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4127 - accuracy: 0.8859\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.3882 - accuracy: 0.9011\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.3533 - accuracy: 0.9260\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.3346 - accuracy: 0.9376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.47      0.39       150\n",
      "        True       0.63      0.49      0.55       282\n",
      "\n",
      "    accuracy                           0.48       432\n",
      "   macro avg       0.48      0.48      0.47       432\n",
      "weighted avg       0.53      0.48      0.49       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 35ms/step - loss: 1.1140 - accuracy: 0.4815\n",
      "Accuracy for this run is: 0.48148149251937866\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=350\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_106 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_70 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,234,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 9s 148ms/step - loss: 0.6952 - accuracy: 0.4822\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.6925 - accuracy: 0.4911\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.6897 - accuracy: 0.5374\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.6834 - accuracy: 0.5597\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 5s 139ms/step - loss: 0.6752 - accuracy: 0.5989\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 0.6656 - accuracy: 0.6123\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 0.6575 - accuracy: 0.6381\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.6423 - accuracy: 0.6640\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6223 - accuracy: 0.6827\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 0.6050 - accuracy: 0.7219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.44      0.54      0.48       174\n",
      "        True       0.63      0.53      0.57       258\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.53      0.53       432\n",
      "weighted avg       0.55      0.53      0.54       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 62ms/step - loss: 0.7209 - accuracy: 0.5324\n",
      "Accuracy for this run is: 0.5324074029922485\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=350\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_107 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_71 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,234,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 9s 152ms/step - loss: 0.6935 - accuracy: 0.4973\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.6920 - accuracy: 0.5071\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.6895 - accuracy: 0.5508\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.6871 - accuracy: 0.5499\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 5s 139ms/step - loss: 0.6832 - accuracy: 0.5365\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 5s 139ms/step - loss: 0.6730 - accuracy: 0.5900\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6636 - accuracy: 0.5998\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6565 - accuracy: 0.6230\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.6402 - accuracy: 0.6506\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.6252 - accuracy: 0.6578\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.6013 - accuracy: 0.7219\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 5s 151ms/step - loss: 0.5725 - accuracy: 0.7451\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.5540 - accuracy: 0.7567\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.5213 - accuracy: 0.7843\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 6s 153ms/step - loss: 0.4957 - accuracy: 0.8021\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 6s 155ms/step - loss: 0.4610 - accuracy: 0.8369\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 6s 154ms/step - loss: 0.4279 - accuracy: 0.8645\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 6s 158ms/step - loss: 0.4007 - accuracy: 0.8761\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 6s 153ms/step - loss: 0.3947 - accuracy: 0.8779\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.3740 - accuracy: 0.8957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.53      0.58       257\n",
      "        True       0.44      0.54      0.49       175\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.54      0.53       432\n",
      "weighted avg       0.55      0.53      0.54       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 57ms/step - loss: 1.1789 - accuracy: 0.5347\n",
      "Accuracy for this run is: 0.5347222089767456\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=100\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_108 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_72 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,279,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 6s 41ms/step - loss: 0.6904 - accuracy: 0.5321\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.6790 - accuracy: 0.5695\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.6648 - accuracy: 0.5945\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.6396 - accuracy: 0.6435\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.5996 - accuracy: 0.6845\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.5600 - accuracy: 0.7264\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.5005 - accuracy: 0.7549\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.4558 - accuracy: 0.8039\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 0.3529 - accuracy: 0.8529\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.2682 - accuracy: 0.9029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.56      0.59       241\n",
      "        True       0.51      0.58      0.54       191\n",
      "\n",
      "    accuracy                           0.57       432\n",
      "   macro avg       0.57      0.57      0.57       432\n",
      "weighted avg       0.57      0.57      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 17ms/step - loss: 0.9326 - accuracy: 0.5671\n",
      "Accuracy for this run is: 0.5671296119689941\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=100\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_109 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_73 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_255 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_256 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,279,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 5s 41ms/step - loss: 0.6884 - accuracy: 0.5437\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.6758 - accuracy: 0.5838\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.6605 - accuracy: 0.6239\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.6351 - accuracy: 0.6586\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.5966 - accuracy: 0.6907\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 0.5521 - accuracy: 0.7255\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.4928 - accuracy: 0.7861\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.4550 - accuracy: 0.8021\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.3758 - accuracy: 0.8512\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.2984 - accuracy: 0.8930\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.3332 - accuracy: 0.8592\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.2539 - accuracy: 0.9162\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.2104 - accuracy: 0.9278\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 2s 45ms/step - loss: 0.1439 - accuracy: 0.9608\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.1039 - accuracy: 0.9750\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.0777 - accuracy: 0.9777\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.0675 - accuracy: 0.9840\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.1277 - accuracy: 0.9563\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.0589 - accuracy: 0.9857\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.0281 - accuracy: 0.9955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.58      0.54       187\n",
      "        True       0.64      0.56      0.60       245\n",
      "\n",
      "    accuracy                           0.57       432\n",
      "   macro avg       0.57      0.57      0.57       432\n",
      "weighted avg       0.58      0.57      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 19ms/step - loss: 1.6499 - accuracy: 0.5718\n",
      "Accuracy for this run is: 0.5717592835426331\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=200\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_110 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_74 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_260 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,279,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 8s 94ms/step - loss: 0.6910 - accuracy: 0.5125\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.6832 - accuracy: 0.5455\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.6733 - accuracy: 0.5677\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.6656 - accuracy: 0.5775\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.6449 - accuracy: 0.6141\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 3s 97ms/step - loss: 0.6324 - accuracy: 0.6381\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5968 - accuracy: 0.6898\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5814 - accuracy: 0.6720\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.5250 - accuracy: 0.7558\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.4947 - accuracy: 0.7549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.34      0.53      0.42       139\n",
      "        True       0.70      0.52      0.59       293\n",
      "\n",
      "    accuracy                           0.52       432\n",
      "   macro avg       0.52      0.52      0.51       432\n",
      "weighted avg       0.58      0.52      0.54       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 38ms/step - loss: 0.8041 - accuracy: 0.5208\n",
      "Accuracy for this run is: 0.5208333134651184\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=200\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_111 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_75 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,279,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 8s 89ms/step - loss: 0.6935 - accuracy: 0.5205\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.6840 - accuracy: 0.5535\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.6724 - accuracy: 0.5758\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.6474 - accuracy: 0.5998\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.6326 - accuracy: 0.6194\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5891 - accuracy: 0.6800\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5580 - accuracy: 0.7184\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5014 - accuracy: 0.7620\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.4593 - accuracy: 0.7701\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.4152 - accuracy: 0.8119\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.3644 - accuracy: 0.8414\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.3418 - accuracy: 0.8565\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.2879 - accuracy: 0.8868\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.2623 - accuracy: 0.8966\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.1731 - accuracy: 0.9492\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 3s 97ms/step - loss: 0.2041 - accuracy: 0.9171\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.1103 - accuracy: 0.9679\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0683 - accuracy: 0.9866\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0435 - accuracy: 0.9938\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0243 - accuracy: 0.9991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.46      0.56      0.51       177\n",
      "        True       0.64      0.55      0.59       255\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.56      0.55       432\n",
      "weighted avg       0.57      0.55      0.56       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 39ms/step - loss: 1.9657 - accuracy: 0.5532\n",
      "Accuracy for this run is: 0.5532407164573669\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=350\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 350)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_112 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_76 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_264 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_265 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,279,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 10s 152ms/step - loss: 0.6934 - accuracy: 0.4938\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 5s 151ms/step - loss: 0.6888 - accuracy: 0.5472\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.6754 - accuracy: 0.5704\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.6636 - accuracy: 0.5954\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.6377 - accuracy: 0.6283\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 6s 156ms/step - loss: 0.6050 - accuracy: 0.6640\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.5655 - accuracy: 0.7157\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 6s 159ms/step - loss: 0.5094 - accuracy: 0.7496\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.4790 - accuracy: 0.7861\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.4188 - accuracy: 0.8182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.59      0.54       180\n",
      "        True       0.66      0.57      0.61       252\n",
      "\n",
      "    accuracy                           0.58       432\n",
      "   macro avg       0.58      0.58      0.58       432\n",
      "weighted avg       0.59      0.58      0.58       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 71ms/step - loss: 0.8612 - accuracy: 0.5787\n",
      "Accuracy for this run is: 0.5787037014961243\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=350\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_113 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_77 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,279,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 10s 151ms/step - loss: 0.6927 - accuracy: 0.5178\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.6849 - accuracy: 0.5758\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.6743 - accuracy: 0.5971\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.6542 - accuracy: 0.6319\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 5s 152ms/step - loss: 0.6441 - accuracy: 0.6453\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.6071 - accuracy: 0.6854\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 6s 159ms/step - loss: 0.5761 - accuracy: 0.7023\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.5353 - accuracy: 0.7299\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.4849 - accuracy: 0.7781\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.4487 - accuracy: 0.7986\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 6s 176ms/step - loss: 0.4179 - accuracy: 0.8182\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.3446 - accuracy: 0.8663\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.3212 - accuracy: 0.8627\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.2478 - accuracy: 0.8993\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 6s 176ms/step - loss: 0.2093 - accuracy: 0.9323\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.4322 - accuracy: 0.7959\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 7s 182ms/step - loss: 0.2805 - accuracy: 0.8922\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.2411 - accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.1522 - accuracy: 0.9510\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.0922 - accuracy: 0.9822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.56      0.53       193\n",
      "        True       0.61      0.55      0.58       239\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.55      0.55       432\n",
      "weighted avg       0.56      0.55      0.55       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 66ms/step - loss: 1.4368 - accuracy: 0.5532\n",
      "Accuracy for this run is: 0.5532407164573669\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=100\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_114 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_78 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_270 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,384,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 7s 76ms/step - loss: 0.6914 - accuracy: 0.5339\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 2s 62ms/step - loss: 0.6770 - accuracy: 0.5838\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 61ms/step - loss: 0.6534 - accuracy: 0.6292\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.6186 - accuracy: 0.6720\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 0.5759 - accuracy: 0.7032\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 2s 63ms/step - loss: 0.5463 - accuracy: 0.7068\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 0.4648 - accuracy: 0.7941\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 2s 65ms/step - loss: 0.4059 - accuracy: 0.8173\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 2s 65ms/step - loss: 0.3098 - accuracy: 0.8708\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 2s 66ms/step - loss: 0.2479 - accuracy: 0.8993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.46      0.58      0.52       172\n",
      "        True       0.67      0.55      0.61       260\n",
      "\n",
      "    accuracy                           0.56       432\n",
      "   macro avg       0.56      0.57      0.56       432\n",
      "weighted avg       0.59      0.56      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 31ms/step - loss: 1.0316 - accuracy: 0.5648\n",
      "Accuracy for this run is: 0.5648148059844971\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=100\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_115 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_79 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,384,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 7s 66ms/step - loss: 0.6927 - accuracy: 0.5045\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 2s 66ms/step - loss: 0.6702 - accuracy: 0.6043\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 2s 65ms/step - loss: 0.6409 - accuracy: 0.6435\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 2s 66ms/step - loss: 0.5933 - accuracy: 0.6845\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 2s 66ms/step - loss: 0.5392 - accuracy: 0.7317\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 2s 67ms/step - loss: 0.5201 - accuracy: 0.7344\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 2s 66ms/step - loss: 0.4041 - accuracy: 0.8253\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 2s 66ms/step - loss: 0.3121 - accuracy: 0.8717\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 2s 68ms/step - loss: 0.2036 - accuracy: 0.9314\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 0.1739 - accuracy: 0.9367\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.2644 - accuracy: 0.8922\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.0892 - accuracy: 0.9750\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 2s 69ms/step - loss: 0.0383 - accuracy: 0.9920\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 70ms/step - loss: 0.0384 - accuracy: 0.9893\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 0.0161 - accuracy: 0.9947\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 3s 77ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      0.54      0.54       212\n",
      "        True       0.55      0.54      0.55       220\n",
      "\n",
      "    accuracy                           0.54       432\n",
      "   macro avg       0.54      0.54      0.54       432\n",
      "weighted avg       0.54      0.54      0.54       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 34ms/step - loss: 2.7902 - accuracy: 0.5417\n",
      "Accuracy for this run is: 0.5416666865348816\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=200\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_116 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_80 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,384,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 9s 134ms/step - loss: 0.6924 - accuracy: 0.5196\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 5s 133ms/step - loss: 0.6822 - accuracy: 0.5686\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 5s 131ms/step - loss: 0.6674 - accuracy: 0.5829\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.6443 - accuracy: 0.6337\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.6050 - accuracy: 0.6747\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.5445 - accuracy: 0.7237\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.5018 - accuracy: 0.7469\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.4145 - accuracy: 0.8226\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 5s 139ms/step - loss: 0.3510 - accuracy: 0.8485\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.2757 - accuracy: 0.8806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.37      0.59      0.45       135\n",
      "        True       0.74      0.54      0.62       297\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.56      0.54       432\n",
      "weighted avg       0.62      0.55      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 62ms/step - loss: 1.1801 - accuracy: 0.5532\n",
      "Accuracy for this run is: 0.5532407164573669\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=200\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_117 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_81 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_280 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,384,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 10s 125ms/step - loss: 0.6927 - accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 5s 130ms/step - loss: 0.6809 - accuracy: 0.5624\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 5s 126ms/step - loss: 0.6625 - accuracy: 0.5882\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 5s 132ms/step - loss: 0.6374 - accuracy: 0.6301\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.5921 - accuracy: 0.6774\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.5443 - accuracy: 0.7041\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 5s 139ms/step - loss: 0.4786 - accuracy: 0.7701\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 0.4202 - accuracy: 0.8021\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.4189 - accuracy: 0.7914\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.3325 - accuracy: 0.8494\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.2526 - accuracy: 0.8930\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 6s 153ms/step - loss: 0.2084 - accuracy: 0.9207\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.1508 - accuracy: 0.9421\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0770 - accuracy: 0.9715\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0567 - accuracy: 0.9840\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 5s 152ms/step - loss: 0.0291 - accuracy: 0.9920\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.0457 - accuracy: 0.9840\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.0518 - accuracy: 0.9786\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.0337 - accuracy: 0.9884\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.0219 - accuracy: 0.9955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      0.56      0.54       205\n",
      "        True       0.58      0.55      0.56       227\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.55      0.55       432\n",
      "weighted avg       0.55      0.55      0.55       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 67ms/step - loss: 2.2152 - accuracy: 0.5532\n",
      "Accuracy for this run is: 0.5532407164573669\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=350\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_118 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_82 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,384,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 12s 223ms/step - loss: 0.6971 - accuracy: 0.5027\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 8s 221ms/step - loss: 0.6888 - accuracy: 0.5285\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 8s 222ms/step - loss: 0.6804 - accuracy: 0.5660\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 8s 233ms/step - loss: 0.6646 - accuracy: 0.6087\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 9s 238ms/step - loss: 0.6388 - accuracy: 0.6328\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 9s 251ms/step - loss: 0.6163 - accuracy: 0.6542\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 9s 245ms/step - loss: 0.5698 - accuracy: 0.6970\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 9s 256ms/step - loss: 0.5171 - accuracy: 0.7567\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 9s 260ms/step - loss: 0.4666 - accuracy: 0.7897\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 9s 262ms/step - loss: 0.4062 - accuracy: 0.8191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.30      0.57      0.39       113\n",
      "        True       0.77      0.52      0.62       319\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.54      0.51       432\n",
      "weighted avg       0.65      0.53      0.56       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 3s 114ms/step - loss: 1.0169 - accuracy: 0.5347\n",
      "Accuracy for this run is: 0.5347222089767456\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=64 sequence_length=350\n",
      "Model 2: vocabulary size is 10644\n",
      "Converted 8710 words (1934 misses)\n",
      "training set shape: (1122, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_119 (Embedding)   (None, None, 300)         3193200   \n",
      "                                                                 \n",
      " bidirectional_83 (Bidirecti  (None, 128)              186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,384,753\n",
      "Trainable params: 191,553\n",
      "Non-trainable params: 3,193,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 12s 225ms/step - loss: 0.6950 - accuracy: 0.4875\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 8s 225ms/step - loss: 0.6838 - accuracy: 0.5713\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 8s 226ms/step - loss: 0.6708 - accuracy: 0.5784\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 8s 234ms/step - loss: 0.6527 - accuracy: 0.6176\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 8s 233ms/step - loss: 0.6218 - accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 9s 240ms/step - loss: 0.5908 - accuracy: 0.6827\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 9s 252ms/step - loss: 0.5533 - accuracy: 0.7246\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 9s 253ms/step - loss: 0.5277 - accuracy: 0.7308\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 9s 259ms/step - loss: 0.4723 - accuracy: 0.7718\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 10s 268ms/step - loss: 0.4205 - accuracy: 0.8102\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 10s 267ms/step - loss: 0.3711 - accuracy: 0.8244\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 9s 262ms/step - loss: 0.3279 - accuracy: 0.8636\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 9s 263ms/step - loss: 0.2295 - accuracy: 0.9055\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 9s 261ms/step - loss: 0.1768 - accuracy: 0.9358\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 9s 259ms/step - loss: 0.1281 - accuracy: 0.9626\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 9s 251ms/step - loss: 0.0785 - accuracy: 0.9768\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 9s 246ms/step - loss: 0.0535 - accuracy: 0.9804\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 9s 246ms/step - loss: 0.0438 - accuracy: 0.9875\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 9s 244ms/step - loss: 0.0276 - accuracy: 0.9938\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 0.0107 - accuracy: 0.9982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.47      0.54      0.50       186\n",
      "        True       0.61      0.53      0.57       246\n",
      "\n",
      "    accuracy                           0.54       432\n",
      "   macro avg       0.54      0.54      0.53       432\n",
      "weighted avg       0.55      0.54      0.54       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 3s 108ms/step - loss: 2.6049 - accuracy: 0.5370\n",
      "Accuracy for this run is: 0.5370370149612427\n",
      "!!!!!!!!!! Best result for data set 2 is 0.5995370149612427\n",
      "+++++++++++training on data set 3+++++++++++++\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_120 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_84 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 15s 41ms/step - loss: 0.6789 - accuracy: 0.5713\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.6274 - accuracy: 0.6784\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 0.5586 - accuracy: 0.7453\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.4884 - accuracy: 0.7971\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.4287 - accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.3895 - accuracy: 0.8516\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 0.3575 - accuracy: 0.8662\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.3429 - accuracy: 0.8688\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.3264 - accuracy: 0.8758\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 0.3213 - accuracy: 0.8766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.52      0.64       359\n",
      "        True       0.19      0.58      0.29        73\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.55      0.47       432\n",
      "weighted avg       0.74      0.53      0.58       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 16ms/step - loss: 0.8937 - accuracy: 0.5255\n",
      "Accuracy for this run is: 0.5254629850387573\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_121 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_85 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 14s 39ms/step - loss: 0.6773 - accuracy: 0.5911\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 0.6278 - accuracy: 0.6853\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 0.5586 - accuracy: 0.7453\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.4349 - accuracy: 0.8145\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 0.3417 - accuracy: 0.8506\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.2691 - accuracy: 0.8747\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 0.2274 - accuracy: 0.8830\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 0.1803 - accuracy: 0.8930\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 0.1541 - accuracy: 0.8966\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 0.1253 - accuracy: 0.9413\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 0.1094 - accuracy: 0.9704\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 11s 43ms/step - loss: 0.1068 - accuracy: 0.9702\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 0.0767 - accuracy: 0.9859\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 0.0647 - accuracy: 0.9904\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.0556 - accuracy: 0.9932\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.0719 - accuracy: 0.9859\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 0.0853 - accuracy: 0.9790\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 0.0454 - accuracy: 0.9942\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 0.0384 - accuracy: 0.9951\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 0.0380 - accuracy: 0.9947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.53      0.67       360\n",
      "        True       0.22      0.67      0.33        72\n",
      "\n",
      "    accuracy                           0.56       432\n",
      "   macro avg       0.56      0.60      0.50       432\n",
      "weighted avg       0.78      0.56      0.61       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 14ms/step - loss: 2.8653 - accuracy: 0.5556\n",
      "Accuracy for this run is: 0.5555555820465088\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_122 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_86 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 21s 70ms/step - loss: 0.6829 - accuracy: 0.5455\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 19s 75ms/step - loss: 0.6281 - accuracy: 0.6668\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 19s 78ms/step - loss: 0.5440 - accuracy: 0.7580\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 20s 82ms/step - loss: 0.4651 - accuracy: 0.8179\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 23s 92ms/step - loss: 0.3905 - accuracy: 0.8628\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 25s 99ms/step - loss: 0.3156 - accuracy: 0.8828\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 23s 92ms/step - loss: 0.2496 - accuracy: 0.9108\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 24s 95ms/step - loss: 0.2073 - accuracy: 0.9294\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 23s 91ms/step - loss: 0.1645 - accuracy: 0.9503\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 22s 87ms/step - loss: 0.1451 - accuracy: 0.9546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.53      0.66       356\n",
      "        True       0.23      0.64      0.34        76\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.59      0.50       432\n",
      "weighted avg       0.76      0.55      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 33ms/step - loss: 2.5214 - accuracy: 0.5509\n",
      "Accuracy for this run is: 0.5509259104728699\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_123 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_87 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 24s 79ms/step - loss: 0.6736 - accuracy: 0.5930\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 21s 83ms/step - loss: 0.5869 - accuracy: 0.6958\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 21s 86ms/step - loss: 0.4648 - accuracy: 0.7860\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 22s 89ms/step - loss: 0.3596 - accuracy: 0.8443\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 23s 91ms/step - loss: 0.2853 - accuracy: 0.8869\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 22s 89ms/step - loss: 0.2340 - accuracy: 0.9123\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 22s 88ms/step - loss: 0.1901 - accuracy: 0.9281\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 22s 87ms/step - loss: 0.1521 - accuracy: 0.9487\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 22s 87ms/step - loss: 0.1256 - accuracy: 0.9590\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 22s 88ms/step - loss: 0.1087 - accuracy: 0.9629\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 21s 85ms/step - loss: 0.0891 - accuracy: 0.9711\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 23s 91ms/step - loss: 0.0840 - accuracy: 0.9725\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 22s 88ms/step - loss: 0.0655 - accuracy: 0.9803\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 22s 90ms/step - loss: 0.0518 - accuracy: 0.9859\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 24s 94ms/step - loss: 0.0475 - accuracy: 0.9868\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 22s 90ms/step - loss: 0.0454 - accuracy: 0.9878\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 22s 88ms/step - loss: 0.0502 - accuracy: 0.9849\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 22s 89ms/step - loss: 0.0327 - accuracy: 0.9911\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 22s 87ms/step - loss: 0.0224 - accuracy: 0.9947\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 22s 88ms/step - loss: 0.0232 - accuracy: 0.9936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.51      0.64       356\n",
      "        True       0.19      0.55      0.29        76\n",
      "\n",
      "    accuracy                           0.52       432\n",
      "   macro avg       0.52      0.53      0.46       432\n",
      "weighted avg       0.73      0.52      0.58       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 39ms/step - loss: 3.5491 - accuracy: 0.5185\n",
      "Accuracy for this run is: 0.5185185074806213\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_124 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_88 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_300 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 40s 143ms/step - loss: 0.6898 - accuracy: 0.5112\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 38s 152ms/step - loss: 0.6487 - accuracy: 0.6248\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 40s 159ms/step - loss: 0.5525 - accuracy: 0.7511\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 38s 153ms/step - loss: 0.4486 - accuracy: 0.8328\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 38s 153ms/step - loss: 0.3752 - accuracy: 0.8712\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 37s 150ms/step - loss: 0.3160 - accuracy: 0.9034\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 40s 159ms/step - loss: 0.2715 - accuracy: 0.9215\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 39s 155ms/step - loss: 0.2442 - accuracy: 0.9314\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 38s 153ms/step - loss: 0.2089 - accuracy: 0.9453\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 38s 154ms/step - loss: 0.1947 - accuracy: 0.9477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.55      0.65       311\n",
      "        True       0.36      0.64      0.46       121\n",
      "\n",
      "    accuracy                           0.58       432\n",
      "   macro avg       0.58      0.59      0.55       432\n",
      "weighted avg       0.67      0.58      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 63ms/step - loss: 2.3053 - accuracy: 0.5764\n",
      "Accuracy for this run is: 0.5763888955116272\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=8 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_125 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_89 (Bidirecti  (None, 16)               19776     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dense_304 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_305 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,729,057\n",
      "Trainable params: 19,857\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 40s 145ms/step - loss: 0.6885 - accuracy: 0.5332\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 37s 149ms/step - loss: 0.6596 - accuracy: 0.6249\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 39s 158ms/step - loss: 0.6177 - accuracy: 0.6782\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 40s 160ms/step - loss: 0.5491 - accuracy: 0.7369\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 38s 153ms/step - loss: 0.4857 - accuracy: 0.7818\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 39s 158ms/step - loss: 0.4123 - accuracy: 0.8323\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 40s 161ms/step - loss: 0.3499 - accuracy: 0.8645\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 40s 159ms/step - loss: 0.2933 - accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 39s 157ms/step - loss: 0.2553 - accuracy: 0.9130\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 39s 156ms/step - loss: 0.2171 - accuracy: 0.9316\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 39s 156ms/step - loss: 0.1852 - accuracy: 0.9460\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 42s 169ms/step - loss: 0.1660 - accuracy: 0.9535\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 40s 160ms/step - loss: 0.1469 - accuracy: 0.9609\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 37s 150ms/step - loss: 0.1201 - accuracy: 0.9709\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 38s 152ms/step - loss: 0.1054 - accuracy: 0.9746\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 43s 172ms/step - loss: 0.1703 - accuracy: 0.9488\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 47s 188ms/step - loss: 0.0938 - accuracy: 0.9787\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 43s 174ms/step - loss: 0.0798 - accuracy: 0.9834\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 45s 179ms/step - loss: 0.1046 - accuracy: 0.9741\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 42s 169ms/step - loss: 0.0876 - accuracy: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.52      0.64       353\n",
      "        True       0.21      0.57      0.31        79\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.54      0.47       432\n",
      "weighted avg       0.73      0.53      0.58       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 65ms/step - loss: 1.7612 - accuracy: 0.5255\n",
      "Accuracy for this run is: 0.5254629850387573\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_126 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_90 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 16s 45ms/step - loss: 0.6568 - accuracy: 0.6038\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 0.5295 - accuracy: 0.7455\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 0.3620 - accuracy: 0.8504\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 0.2244 - accuracy: 0.9182\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 0.1387 - accuracy: 0.9561\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.0844 - accuracy: 0.9753\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.0531 - accuracy: 0.9862\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.0364 - accuracy: 0.9912\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 0.0322 - accuracy: 0.9922\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 0.0337 - accuracy: 0.9917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.52      0.65       368\n",
      "        True       0.18      0.61      0.28        64\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.56      0.47       432\n",
      "weighted avg       0.78      0.53      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 19ms/step - loss: 3.3827 - accuracy: 0.5324\n",
      "Accuracy for this run is: 0.5324074029922485\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_127 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_91 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_310 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 16s 47ms/step - loss: 0.6483 - accuracy: 0.6108\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 0.5048 - accuracy: 0.7512\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 0.3434 - accuracy: 0.8553\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 0.2153 - accuracy: 0.9191\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 0.1222 - accuracy: 0.9594\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 0.0771 - accuracy: 0.9762\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.0466 - accuracy: 0.9868\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 0.0372 - accuracy: 0.9894\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 0.0291 - accuracy: 0.9917\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 0.0123 - accuracy: 0.9974\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 0.0093 - accuracy: 0.9979\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 0.0076 - accuracy: 0.9981\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 0.0475 - accuracy: 0.9843\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 0.0152 - accuracy: 0.9970\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 0.0090 - accuracy: 0.9984\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 0.0051 - accuracy: 0.9994\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 0.0035 - accuracy: 0.9995\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 0.0026 - accuracy: 0.9996\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 0.0026 - accuracy: 0.9996\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 12s 46ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.51      0.65       379\n",
      "        True       0.13      0.55      0.22        53\n",
      "\n",
      "    accuracy                           0.51       432\n",
      "   macro avg       0.51      0.53      0.43       432\n",
      "weighted avg       0.80      0.51      0.59       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 18ms/step - loss: 4.2186 - accuracy: 0.5116\n",
      "Accuracy for this run is: 0.5115740895271301\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_128 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_92 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_312 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 23s 77ms/step - loss: 0.6712 - accuracy: 0.5742\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 20s 80ms/step - loss: 0.5521 - accuracy: 0.7297\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 21s 84ms/step - loss: 0.4182 - accuracy: 0.8191\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 22s 90ms/step - loss: 0.3035 - accuracy: 0.8814\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 22s 89ms/step - loss: 0.2236 - accuracy: 0.9210\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 22s 89ms/step - loss: 0.1488 - accuracy: 0.9545\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 22s 86ms/step - loss: 0.1111 - accuracy: 0.9660\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 21s 85ms/step - loss: 0.0894 - accuracy: 0.9736\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 23s 92ms/step - loss: 0.0558 - accuracy: 0.9863\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 23s 92ms/step - loss: 0.0427 - accuracy: 0.9894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.53      0.68       385\n",
      "        True       0.16      0.72      0.26        47\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.63      0.47       432\n",
      "weighted avg       0.85      0.55      0.63       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 38ms/step - loss: 2.6394 - accuracy: 0.5486\n",
      "Accuracy for this run is: 0.5486111044883728\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_129 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_93 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_315 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 27s 89ms/step - loss: 0.6812 - accuracy: 0.5548\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 23s 92ms/step - loss: 0.5994 - accuracy: 0.6896\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 23s 93ms/step - loss: 0.4914 - accuracy: 0.7952\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 24s 98ms/step - loss: 0.4052 - accuracy: 0.8519\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 23s 92ms/step - loss: 0.3311 - accuracy: 0.8904\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 22s 90ms/step - loss: 0.2752 - accuracy: 0.9214\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 22s 88ms/step - loss: 0.2405 - accuracy: 0.9341\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 21s 85ms/step - loss: 0.2059 - accuracy: 0.9474\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 22s 86ms/step - loss: 0.1822 - accuracy: 0.9550\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 22s 87ms/step - loss: 0.1592 - accuracy: 0.9620\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 22s 88ms/step - loss: 0.1540 - accuracy: 0.9611\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 23s 91ms/step - loss: 0.1344 - accuracy: 0.9679\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 22s 89ms/step - loss: 0.1135 - accuracy: 0.9766\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 22s 87ms/step - loss: 0.1074 - accuracy: 0.9769\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 21s 86ms/step - loss: 0.0974 - accuracy: 0.9794\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 21s 86ms/step - loss: 0.0901 - accuracy: 0.9806\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 23s 92ms/step - loss: 0.0897 - accuracy: 0.9790\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 23s 91ms/step - loss: 0.0814 - accuracy: 0.9816\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 23s 93ms/step - loss: 0.0829 - accuracy: 0.9796\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 22s 90ms/step - loss: 0.0717 - accuracy: 0.9843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.51      0.65       384\n",
      "        True       0.12      0.54      0.20        48\n",
      "\n",
      "    accuracy                           0.51       432\n",
      "   macro avg       0.51      0.52      0.42       432\n",
      "weighted avg       0.81      0.51      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 36ms/step - loss: 6.8536 - accuracy: 0.5093\n",
      "Accuracy for this run is: 0.5092592835426331\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_130 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_94 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_320 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 39s 142ms/step - loss: 0.6766 - accuracy: 0.5624\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 39s 158ms/step - loss: 0.5845 - accuracy: 0.6938\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 41s 164ms/step - loss: 0.4400 - accuracy: 0.7976\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 39s 158ms/step - loss: 0.3170 - accuracy: 0.8687\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 36s 146ms/step - loss: 0.2239 - accuracy: 0.9184\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 35s 142ms/step - loss: 0.1482 - accuracy: 0.9526\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 36s 145ms/step - loss: 0.1020 - accuracy: 0.9709\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 37s 147ms/step - loss: 0.0692 - accuracy: 0.9816\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 37s 148ms/step - loss: 0.0634 - accuracy: 0.9823\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 37s 149ms/step - loss: 0.0390 - accuracy: 0.9906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.53      0.66       366\n",
      "        True       0.20      0.65      0.30        66\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.59      0.48       432\n",
      "weighted avg       0.79      0.55      0.61       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 58ms/step - loss: 4.4709 - accuracy: 0.5463\n",
      "Accuracy for this run is: 0.5462962985038757\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=16 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_131 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_95 (Bidirecti  (None, 32)               40576     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,750,081\n",
      "Trainable params: 40,881\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 38s 137ms/step - loss: 0.6802 - accuracy: 0.5669\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 36s 145ms/step - loss: 0.6063 - accuracy: 0.6717\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 37s 147ms/step - loss: 0.4720 - accuracy: 0.7794\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 36s 144ms/step - loss: 0.3385 - accuracy: 0.8592\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 35s 142ms/step - loss: 0.2207 - accuracy: 0.9175\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 36s 144ms/step - loss: 0.1430 - accuracy: 0.9553\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 36s 145ms/step - loss: 0.0894 - accuracy: 0.9747\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 35s 139ms/step - loss: 0.0572 - accuracy: 0.9850\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 35s 141ms/step - loss: 0.0389 - accuracy: 0.9906\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 36s 145ms/step - loss: 0.0394 - accuracy: 0.9908\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 36s 146ms/step - loss: 0.0398 - accuracy: 0.9883\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 38s 154ms/step - loss: 0.0299 - accuracy: 0.9918\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 39s 155ms/step - loss: 0.0181 - accuracy: 0.9964\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 39s 156ms/step - loss: 0.0095 - accuracy: 0.9984\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 39s 156ms/step - loss: 0.0059 - accuracy: 0.9992\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 39s 156ms/step - loss: 0.0045 - accuracy: 0.9991\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 39s 155ms/step - loss: 0.0082 - accuracy: 0.9986\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 37s 149ms/step - loss: 0.0499 - accuracy: 0.9842\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 37s 147ms/step - loss: 0.0107 - accuracy: 0.9970\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 36s 145ms/step - loss: 0.0073 - accuracy: 0.9981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.53      0.66       368\n",
      "        True       0.19      0.66      0.30        64\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.59      0.48       432\n",
      "weighted avg       0.79      0.55      0.61       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 59ms/step - loss: 4.9403 - accuracy: 0.5463\n",
      "Accuracy for this run is: 0.5462962985038757\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_132 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_96 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 15s 42ms/step - loss: 0.6369 - accuracy: 0.6298\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 0.4459 - accuracy: 0.7972\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 0.2484 - accuracy: 0.9065\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 12s 46ms/step - loss: 0.1381 - accuracy: 0.9541\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 0.0742 - accuracy: 0.9769\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 0.0393 - accuracy: 0.9892\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 0.0211 - accuracy: 0.9952\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 0.0136 - accuracy: 0.9969\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 0.0426 - accuracy: 0.9872\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 0.0153 - accuracy: 0.9966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.52      0.66       371\n",
      "        True       0.18      0.64      0.28        61\n",
      "\n",
      "    accuracy                           0.54       432\n",
      "   macro avg       0.54      0.58      0.47       432\n",
      "weighted avg       0.80      0.54      0.61       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 18ms/step - loss: 4.6177 - accuracy: 0.5394\n",
      "Accuracy for this run is: 0.5393518805503845\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=100\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 100)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_133 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_97 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 14s 42ms/step - loss: 0.6490 - accuracy: 0.6200\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 0.4438 - accuracy: 0.7997\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 0.2476 - accuracy: 0.9097\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 0.1337 - accuracy: 0.9558\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 0.0674 - accuracy: 0.9804\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 0.0454 - accuracy: 0.9867\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 0.0224 - accuracy: 0.9948\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 0.0225 - accuracy: 0.9935\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 13s 50ms/step - loss: 0.0314 - accuracy: 0.9903\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 0.0171 - accuracy: 0.9957\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 13s 50ms/step - loss: 0.0040 - accuracy: 0.9995\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 0.0033 - accuracy: 0.9997\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 11s 46ms/step - loss: 0.0055 - accuracy: 0.9994\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 12s 46ms/step - loss: 9.8701e-04 - accuracy: 0.9999\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 8.2166e-04 - accuracy: 0.9999\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 0.0752 - accuracy: 0.9737\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 0.0135 - accuracy: 0.9964\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 0.0025 - accuracy: 0.9996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.52      0.66       378\n",
      "        True       0.16      0.63      0.25        54\n",
      "\n",
      "    accuracy                           0.53       432\n",
      "   macro avg       0.53      0.57      0.46       432\n",
      "weighted avg       0.81      0.53      0.61       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 1s 20ms/step - loss: 4.6648 - accuracy: 0.5324\n",
      "Accuracy for this run is: 0.5324074029922485\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_134 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_98 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 25s 85ms/step - loss: 0.6582 - accuracy: 0.6018\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 22s 88ms/step - loss: 0.5155 - accuracy: 0.7452\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 22s 87ms/step - loss: 0.3181 - accuracy: 0.8723\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 22s 90ms/step - loss: 0.1943 - accuracy: 0.9282\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 25s 98ms/step - loss: 0.1079 - accuracy: 0.9659\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 25s 98ms/step - loss: 0.0572 - accuracy: 0.9836\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 23s 91ms/step - loss: 0.0385 - accuracy: 0.9898\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 23s 93ms/step - loss: 0.0366 - accuracy: 0.9902\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 23s 91ms/step - loss: 0.0154 - accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 23s 92ms/step - loss: 0.0085 - accuracy: 0.9982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.51      0.65       382\n",
      "        True       0.13      0.56      0.21        50\n",
      "\n",
      "    accuracy                           0.51       432\n",
      "   macro avg       0.51      0.53      0.43       432\n",
      "weighted avg       0.81      0.51      0.60       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 37ms/step - loss: 5.2871 - accuracy: 0.5139\n",
      "Accuracy for this run is: 0.5138888955116272\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=200\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 200)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_135 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_99 (Bidirecti  (None, 64)               85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 27s 90ms/step - loss: 0.6534 - accuracy: 0.6093\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 22s 87ms/step - loss: 0.4954 - accuracy: 0.7648\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 22s 90ms/step - loss: 0.3135 - accuracy: 0.8767\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 22s 86ms/step - loss: 0.1718 - accuracy: 0.9399\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 25s 100ms/step - loss: 0.0902 - accuracy: 0.9706\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 24s 95ms/step - loss: 0.0471 - accuracy: 0.9855\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 23s 91ms/step - loss: 0.0233 - accuracy: 0.9948\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 22s 89ms/step - loss: 0.0287 - accuracy: 0.9914\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 22s 88ms/step - loss: 0.0078 - accuracy: 0.9987\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 22s 88ms/step - loss: 0.0294 - accuracy: 0.9899\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 23s 93ms/step - loss: 0.0130 - accuracy: 0.9972\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 22s 87ms/step - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 22s 88ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 22s 90ms/step - loss: 0.0055 - accuracy: 0.9985\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 25s 99ms/step - loss: 0.0277 - accuracy: 0.9897\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 23s 92ms/step - loss: 0.0192 - accuracy: 0.9936\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 23s 92ms/step - loss: 0.0068 - accuracy: 0.9985\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 24s 98ms/step - loss: 0.0054 - accuracy: 0.9989\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 23s 94ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 24s 94ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.53      0.67       383\n",
      "        True       0.16      0.71      0.26        49\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.55      0.62      0.47       432\n",
      "weighted avg       0.85      0.55      0.63       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 37ms/step - loss: 4.5334 - accuracy: 0.5486\n",
      "Accuracy for this run is: 0.5486111044883728\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_136 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_100 (Bidirect  (None, 64)               85248     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "249/249 [==============================] - 39s 141ms/step - loss: 0.6809 - accuracy: 0.5493\n",
      "Epoch 2/10\n",
      "249/249 [==============================] - 38s 152ms/step - loss: 0.5502 - accuracy: 0.7216\n",
      "Epoch 3/10\n",
      "249/249 [==============================] - 40s 161ms/step - loss: 0.3939 - accuracy: 0.8286\n",
      "Epoch 4/10\n",
      "249/249 [==============================] - 39s 158ms/step - loss: 0.2423 - accuracy: 0.9084\n",
      "Epoch 5/10\n",
      "249/249 [==============================] - 40s 160ms/step - loss: 0.1414 - accuracy: 0.9498\n",
      "Epoch 6/10\n",
      "249/249 [==============================] - 39s 155ms/step - loss: 0.0807 - accuracy: 0.9748\n",
      "Epoch 7/10\n",
      "249/249 [==============================] - 40s 160ms/step - loss: 0.0434 - accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "249/249 [==============================] - 39s 157ms/step - loss: 0.0368 - accuracy: 0.9889\n",
      "Epoch 9/10\n",
      "249/249 [==============================] - 39s 157ms/step - loss: 0.0208 - accuracy: 0.9941\n",
      "Epoch 10/10\n",
      "249/249 [==============================] - 39s 157ms/step - loss: 0.0044 - accuracy: 0.9994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.51      0.63       348\n",
      "        True       0.22      0.56      0.31        84\n",
      "\n",
      "    accuracy                           0.52       432\n",
      "   macro avg       0.52      0.54      0.47       432\n",
      "weighted avg       0.71      0.52      0.57       432\n",
      "\n",
      "Test set class distribution\n",
      "N    0.5\n",
      "Y    0.5\n",
      "Name: flagged, dtype: float64\n",
      "14/14 [==============================] - 2s 62ms/step - loss: 3.3779 - accuracy: 0.5231\n",
      "Accuracy for this run is: 0.5231481194496155\n",
      "---------------------------------------------------------------------------\n",
      "Start training with num_units=32 sequence_length=350\n",
      "Model 2: vocabulary size is 22364\n",
      "Converted 16507 words (5857 misses)\n",
      "training set shape: (7950, 350)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_137 (Embedding)   (None, None, 300)         6709200   \n",
      "                                                                 \n",
      " bidirectional_101 (Bidirect  (None, 64)               85248     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_340 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,795,633\n",
      "Trainable params: 86,433\n",
      "Non-trainable params: 6,709,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "249/249 [==============================] - 39s 143ms/step - loss: 0.6702 - accuracy: 0.5813\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 39s 155ms/step - loss: 0.5578 - accuracy: 0.7169\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 40s 159ms/step - loss: 0.3893 - accuracy: 0.8307\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 40s 162ms/step - loss: 0.2304 - accuracy: 0.9147\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 39s 157ms/step - loss: 0.1222 - accuracy: 0.9608\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 39s 158ms/step - loss: 0.0556 - accuracy: 0.9840\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 40s 160ms/step - loss: 0.0435 - accuracy: 0.9875\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 39s 155ms/step - loss: 0.0248 - accuracy: 0.9941\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 41s 163ms/step - loss: 0.0098 - accuracy: 0.9977\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 41s 163ms/step - loss: 0.0040 - accuracy: 0.9994\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 47s 190ms/step - loss: 0.0156 - accuracy: 0.9947\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 46s 184ms/step - loss: 0.0492 - accuracy: 0.9828\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 43s 173ms/step - loss: 0.0104 - accuracy: 0.9974\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 42s 169ms/step - loss: 0.0022 - accuracy: 0.9997\n",
      "Epoch 15/20\n",
      "201/249 [=======================>......] - ETA: 9s - loss: 0.0020 - accuracy: 0.9997"
     ]
    }
   ],
   "source": [
    "# Grid search for evaluation\n",
    "for i in [1,2,3,4]:\n",
    "    print(f\"+++++++++++training on data set {i}+++++++++++++\")\n",
    "    X_train = eval(f'hotel_X_train_{i}')\n",
    "    y_train = eval(f'hotel_y_train_{i}')\n",
    "    best = 0\n",
    "    for num_units in [8, 16, 32, 64]:\n",
    "        for sequence_length in [100, 200, 350]:\n",
    "            for epochs in [10, 20]:\n",
    "                print('---------------------------------------------------------------------------')\n",
    "                print(f\"Start training with num_units={num_units} sequence_length={sequence_length}\")\n",
    "                acc = build_model_2(X_train, y_train, hotel_X_test, hotel_y_test, num_units, epochs, sequence_length)['accuracy']\n",
    "                print(f\"Accuracy for this run is: {acc}\")\n",
    "                best = max(best, acc)\n",
    "                \n",
    "    print(f\"!!!!!!!!!! Best result for data set {i} is {best}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(X_train, y_train, X_test, y_test, num_units, num_epochs):\n",
    "    # BERT has its own input and preprocessing\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "    preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/albert_en_preprocess/3\")\n",
    "    encoder_inputs = preprocessor(text_input)\n",
    "    encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1\", trainable=True)\n",
    "    outputs = encoder(encoder_inputs)\n",
    "\n",
    "    net = outputs['pooled_output']\n",
    "    net = Dropout(0.2)(net)\n",
    "    net = Dense(num_units, activation='relu')(net)\n",
    "    net = Dense(1, activation='sigmoid')(net)\n",
    "    model = tf.keras.Model(text_input, net)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    model.fit(X_train['reviewContent'], y_train, epochs=num_epochs)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_predicted = model.predict(X_test['reviewContent'])\n",
    "    print(classification_report(y_predicted > 0.5, y_test))\n",
    "    print('Test set class distribution')\n",
    "    print(X_test['flagged'].value_counts() / len(X_test))\n",
    "    return model.evaluate(X_test['reviewContent'], y_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for evaluation\n",
    "for i in [1,2,3,4]:\n",
    "    print(f\"+++++++++++training on data set {i}+++++++++++++\")\n",
    "    X_train = eval(f'hotel_X_train_{i}')\n",
    "    y_train = eval(f'hotel_y_train_{i}')\n",
    "    best = 0\n",
    "    for num_units in [8, 16, 32]:\n",
    "        for epochs in [10, 20]:\n",
    "            print('---------------------------------------------------------------------------')\n",
    "            print(f\"Start training with num_units={num_units} sequence_length={sequence_length}\")\n",
    "            acc = build_model_3(X_train, y_train, hotel_X_test, hotel_y_test, num_units, epochs)['accuracy']\n",
    "            print(f\"Accuracy for this run is: {acc}\")\n",
    "            best = max(best, acc)\n",
    "\n",
    "    print(f\"!!!!!!!!!! Best result for data set {i} is {best}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: LSTM with Elmo embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model_4(X_train, y_train, X_test, y_test, num_units, num_epochs, sequence_length):\n",
    "    m4_vectorizer = TextVectorization(output_sequence_length=sequence_length)\n",
    "    m4_vectorizer.adapt(X_train['reviewContent'].to_numpy())\n",
    "    m4_voc = m4_vectorizer.get_vocabulary()\n",
    "    print(f\"Model 4: vocabulary size is {len(m4_voc)}\")\n",
    "\n",
    "    elmo_embeddings = get_elmo_embedding(m4_voc)\n",
    "\n",
    "    # Building the embedding layer using Elmo results\n",
    "    elmo_embedding_dim = 1024\n",
    "    num_words = len(m4_voc)\n",
    "\n",
    "    m4_embedding_matrix = np.zeros((num_words, elmo_embedding_dim))\n",
    "    for i, word in enumerate(m4_voc):\n",
    "        m4_embedding_matrix[i] = elmo_embeddings[i][0]\n",
    "\n",
    "    m4_embedding_layer = Embedding(\n",
    "        num_words,\n",
    "        elmo_embedding_dim,\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(m4_embedding_matrix),\n",
    "        trainable=False,\n",
    "    )\n",
    "\n",
    "    # Vectorize the input\n",
    "    X_train_ready = m4_vectorizer(X_train['reviewContent']).numpy()\n",
    "    X_test_ready = m4_vectorizer(X_test['reviewContent']).numpy()\n",
    "    print(f'training set shape: {X_train_ready.shape}')\n",
    "\n",
    "    # Build and train the model with \n",
    "    model = Sequential(name='model_4')\n",
    "    model.add(m4_embedding_layer)\n",
    "    model.add(Bidirectional(LSTM(num_units)))\n",
    "    model.add(Dense(num_units//2, activation='relu'))\n",
    "    model.add(Dense(num_units//4, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    model.fit(X_train_ready, y_train, epochs=num_epochs)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_predicted = model.predict(X_test_ready)\n",
    "    print(classification_report(y_predicted > 0.5, y_test))\n",
    "    print('Test set class distribution')\n",
    "    print(X_test['flagged'].value_counts() / len(X_test))\n",
    "    return model.evaluate(X_test_ready, y_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for evaluation\n",
    "for i in [1,2,3,4]:\n",
    "    print(f\"+++++++++++training on data set {i}+++++++++++++\")\n",
    "    X_train = eval(f'hotel_X_train_{i}')\n",
    "    y_train = eval(f'hotel_y_train_{i}')\n",
    "    best = 0\n",
    "    for num_units in [8, 16]:\n",
    "        for sequence_length in [100, 200, 350]:\n",
    "            print('---------------------------------------------------------------------------')\n",
    "            print(f\"Start training with num_units={num_units} sequence_length={sequence_length}\")\n",
    "            acc = build_model_4(X_train, y_train, hotel_X_test, hotel_y_test, num_units, 10, sequence_length)['accuracy']\n",
    "            print(f\"Accuracy for this run is: {acc}\")\n",
    "            best = max(best, acc)\n",
    "                \n",
    "    print(f\"!!!!!!!!!! Best result for data set {i} is {best}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
